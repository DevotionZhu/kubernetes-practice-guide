[
{
	"uri": "https://k8s.imroc.io/deploy/manual/prepare/",
	"title": "部署前的准备工作",
	"tags": [],
	"description": "",
	"content": "准备节点 操作系统 使用 Linux 发行版，本教程主要以 Ubuntu 18.04 为例\nMaster 节点 部署 K8S 控制面组件，推荐三台以上数量的机器\nETCD 节点 部署 ETCD，可以跟 Master 节点用相同的机器，也可以用单独的机器，推荐三台以上数量的机器\nWorker 节点 实际运行工作负载的节点，Master 节点也可以作为 Worker 节点，可以通过 kubelet 参数 --kube-reserved 多预留一些资源给系统组件。\n通常会给 Master 节点打标签，让关键的 Pod 跑在 Master 节点上，比如集群 DNS 服务。\n准备客户端工具 我们需要用 cfssl 和 kubectl 来为各个组件生成证书和 kubeconfig，所以先将这两个工具在某个机器下载安装好。\n安装 cfssl  curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o cfssl curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o cfssljson curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o cfssl-certinfo chmod +x cfssl cfssljson cfssl-certinfo sudo mv cfssl cfssljson cfssl-certinfo /usr/local/bin/ 安装 kubectl wget -q --show-progress --https-only --timestamping \\  https://storage.googleapis.com/kubernetes-release/release/v1.16.1/bin/linux/amd64/kubectl chmod +x kubectl mv kubectl /usr/local/bin/ 生成 CA 证书  由于各个组件都需要配置证书，并且依赖 CA 证书来签发证书，所以我们首先要生成好 CA 证书以及后续的签发配置文件:\ncat \u0026gt; ca-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;Kubernetes\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;ChengDu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;Kubernetes\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;CA\u0026#34; } ] } EOF cfssl gencert -initca ca-csr.json | cfssljson -bare ca cat \u0026gt; ca-config.json \u0026lt;\u0026lt;EOF { \u0026#34;signing\u0026#34;: { \u0026#34;default\u0026#34;: { \u0026#34;expiry\u0026#34;: \u0026#34;8760h\u0026#34; }, \u0026#34;profiles\u0026#34;: { \u0026#34;kubernetes\u0026#34;: { \u0026#34;usages\u0026#34;: [\u0026#34;signing\u0026#34;, \u0026#34;key encipherment\u0026#34;, \u0026#34;server auth\u0026#34;, \u0026#34;client auth\u0026#34;], \u0026#34;expiry\u0026#34;: \u0026#34;8760h\u0026#34; } } } } EOF 生成的文件中有下面三个后面会用到:\n ca-key.pem: CA 证书密钥 ca.pem: CA 证书 ca-config.json: 证书签发配置  csr 文件字段解释:\n CN: Common Name，apiserver 从证书中提取该字段作为请求的用户名 (User Name) Organization，apiserver 从证书中提取该字段作为请求用户所属的组 (Group)   由于这里是 CA 证书，是签发其它证书的根证书，这个证书密钥不会分发出去作为 client 证书，所有组件使用的 client 证书都是由 CA 证书签发而来，所以 CA 证书的 CN 和 O 的名称并不重要，后续其它签发出来的证书的 CN 和 O 的名称才是有用的\n "
},
{
	"uri": "https://k8s.imroc.io/configuration/helm/install-helm/",
	"title": "安装 Helm",
	"tags": [],
	"description": "",
	"content": "Helm 是 Kubernetes 的包管理器，可以帮我们简化 kubernetes 的操作，一键部署应用。假如你的机器上已经安装了 kubectl 并且能够操作集群，那么你就可以安装 Helm 了。当前最新稳定版是 V2，Helm V3 还未正式发布，下面分别说下安装方法。\n安装 Helm V2 执行脚本安装 helm 客户端:\n$ curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 6737 100 6737 0 0 12491 0 --:--:-- --:--:-- --:--:-- 12475 Downloading https://kubernetes-helm.storage.googleapis.com/helm-v2.9.1-linux-amd64.tar.gz Preparing to install into /usr/local/bin helm installed into /usr/local/bin/helm Run \u0026#39;helm init\u0026#39; to configure helm. 查看客户端版本：\n$ helm version Client: \u0026amp;version.Version{SemVer:\u0026#34;v2.9.1\u0026#34;, GitCommit:\u0026#34;20adb27c7c5868466912eebdf6664e7390ebe710\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;} 安装 tiller 服务端到 kubernetes 集群：\n$ helm init Creating /root/.helm Creating /root/.helm/repository Creating /root/.helm/repository/cache Creating /root/.helm/repository/local Creating /root/.helm/plugins Creating /root/.helm/starters Creating /root/.helm/cache/archive Creating /root/.helm/repository/repositories.yaml Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com Adding local repo with URL: http://127.0.0.1:8879/charts $HELM_HOME has been configured at /root/.helm. Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster. Please note: by default, Tiller is deployed with an insecure \u0026#39;allow unauthenticated users\u0026#39; policy. For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation Happy Helming! 查看 tiller 是否启动成功:\n$ kubectl get pods --namespace=kube-system | grep tiller tiller-deploy-dccdb6fd9-2df4r 0/1 ImagePullBackOff 0 14h 如果状态是 ImagePullBackOff ，说明是镜像问题，一般是未拉取到镜像（国内机器拉取不到 gcr.io 下的镜像) 可以查看下是什么镜像:\n$ kubectl describe pod tiller-deploy-dccdb6fd9-2df4r --namespace=kube-system Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning Failed 36m (x5 over 12h) kubelet, k8s-node1 Failed to pull image \u0026#34;gcr.io/kubernetes-helm/tiller:v2.9.1\u0026#34;: rpc error: code = Unknown desc = Get https://gcr.io/v1/_ping: dial tcp 64.233.189.82:443: i/o timeout Normal BackOff 11m (x3221 over 14h) kubelet, k8s-node1 Back-off pulling image \u0026#34;gcr.io/kubernetes-helm/tiller:v2.9.1\u0026#34; Warning Failed 6m (x3237 over 14h) kubelet, k8s-node1 Error: ImagePullBackOff Warning Failed 1m (x15 over 14h) kubelet, k8s-node1 Failed to pull image \u0026#34;gcr.io/kubernetes-helm/tiller:v2.9.1\u0026#34;: rpc error: code = Unknown desc = Get https://gcr.io/v1/_ping: dial tcp 64.233.188.82:443: i/o timeout 把这个没拉取到镜像想办法下载到这台机器上。当我们看到状态为 Running 说明 tiller 已经成功运行了:\n$ kubectl get pods -n kube-system | grep tiller tiller-deploy-dccdb6fd9-2df4r 1/1 Running 1 41d 默认安装的 tiller 权限很小，我们执行下面的脚本给它加最大权限，这样方便我们可以用 helm 部署应用到任意 namespace 下:\nkubectl create serviceaccount --namespace=kube-system tiller kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller kubectl patch deploy --namespace=kube-system tiller-deploy -p \u0026#39;{\u0026#34;spec\u0026#34;:{\u0026#34;template\u0026#34;:{\u0026#34;spec\u0026#34;:{\u0026#34;serviceAccount\u0026#34;:\u0026#34;tiller\u0026#34;}}}}\u0026#39; 更多参考官方文档: https://helm.sh/docs/using_helm/#quickstart-guide\n安装 Helm V3 在 https://github.com/helm/helm/releases 找到对应系统的二进制包下载，比如下载 v3.0.0-beta.3 的 linux amd64 版:\n$ wget https://get.helm.sh/helm-v3.0.0-beta.3-linux-amd64.tar.gz 解压并移动到 PATH 下面:\n$ tar -zxvf helm-v3.0.0-beta.3-linux-amd64.tar.gz linux-amd64/ linux-amd64/LICENSE linux-amd64/helm linux-amd64/README.md $ cd linux-amd64/ $ ls LICENSE README.md helm $ mv helm /usr/local/bin/helm3 "
},
{
	"uri": "https://k8s.imroc.io/deploy/manual/bootstrapping-etcd/",
	"title": "部署 ETCD",
	"tags": [],
	"description": "",
	"content": "为 ETCD 签发证书 这里证书可以只创建一次，所有 etcd 实例都公用这里创建的证书:\ncat \u0026gt; etcd-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;etcd\u0026#34;, \u0026#34;hosts\u0026#34;: [ \u0026#34;127.0.0.1\u0026#34;, \u0026#34;10.200.16.79\u0026#34;, \u0026#34;10.200.17.6\u0026#34;, \u0026#34;10.200.16.70\u0026#34; ], \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;etcd\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;etcd\u0026#34; } ] } EOF cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  etcd-csr.json | cfssljson -bare etcd  hosts 需要包含 etcd 每个实例所在节点的内网 IP\n 会生成下面两个重要的文件:\n etcd-key.pem: kube-apiserver 证书密钥 etcd.pem: kube-apiserver 证书  下载安装 ETCD 下载 release 包:\nwget -q --show-progress --https-only --timestamping \\  \u0026#34;https://github.com/etcd-io/etcd/releases/download/v3.4.1/etcd-v3.4.1-linux-amd64.tar.gz\u0026#34; 解压安装 etcd 和 etcdctl 到 PATH:\ntar -xvf etcd-v3.4.1-linux-amd64.tar.gz sudo mv etcd-v3.4.1-linux-amd64/etcd* /usr/local/bin/ 配置 创建配置相关目录，放入证书文件:\nsudo mkdir -p /etc/etcd /var/lib/etcd sudo cp ca.pem etcd-key.pem etcd.pem /etc/etcd/ etcd 集群每个成员都需要一个名字，这里第一个成员名字用 infra0，第二个可以用 infra1，以此类推，你也可以直接用节点的 hostname:\nNAME=infra0 记当前部署 ETCD 的节点的内网 IP 为 INTERNAL_IP:\nINTERNAL_IP=10.200.16.79 记所有 ETCD 成员的名称和成员间通信的 https 监听地址为 ETCD_SERVERS (注意是 2380 端口，不是 2379):\nETCD_SERVERS=\u0026#34;infra0=https://10.200.16.79:2380,infra1=https://10.200.17.6:2380,infra2=https://10.200.16.70:2380\u0026#34; 创建 systemd 配置:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/etcd.service [Unit] Description=etcd Documentation=https://github.com/coreos [Service] Type=notify ExecStart=/usr/local/bin/etcd \\\\ --name ${NAME} \\\\ --cert-file=/etc/etcd/etcd.pem \\\\ --key-file=/etc/etcd/etcd-key.pem \\\\ --peer-cert-file=/etc/etcd/etcd.pem \\\\ --peer-key-file=/etc/etcd/etcd-key.pem \\\\ --trusted-ca-file=/etc/etcd/ca.pem \\\\ --peer-trusted-ca-file=/etc/etcd/ca.pem \\\\ --peer-client-cert-auth \\\\ --client-cert-auth \\\\ --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\\\ --listen-peer-urls https://${INTERNAL_IP}:2380 \\\\ --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\\\ --advertise-client-urls https://${INTERNAL_IP}:2379 \\\\ --initial-cluster-token etcd-cluster-0 \\\\ --initial-cluster ${ETCD_SERVERS} \\\\ --initial-cluster-state new \\\\ --data-dir=/var/lib/etcd Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF 启动 sudo systemctl daemon-reload sudo systemctl enable etcd sudo systemctl start etcd 验证 等所有 etcd 成员安装启动成功后，来验证下是否可用:\nsudo ETCDCTL_API=3 etcdctl member list \\  --endpoints=https://127.0.0.1:2379 \\  --cacert=/etc/etcd/ca.pem \\  --cert=/etc/etcd/etcd.pem \\  --key=/etc/etcd/etcd-key.pem 输出:\na7f995caeeaf7a59, started, infra1, https://10.200.17.6:2380, https://10.200.17.6:2379, false b90901a06e9aec53, started, infra2, https://10.200.16.70:2380, https://10.200.16.70:2379, false ba126eb695f5ba71, started, infra0, https://10.200.16.79:2380, https://10.200.16.79:2379, false "
},
{
	"uri": "https://k8s.imroc.io/configuration/helm/upgrade-helm-v2-to-v3/",
	"title": "Helm V2 迁移到 V3",
	"tags": [],
	"description": "",
	"content": "Helm V3 与 V2 版本架构变化较大，数据迁移比较麻烦，官方提供了一个名为 helm-2to3 的插件来简化迁移工作，本文将介绍如何利用此插件迁移 Helm V2 到 V3 版本。这里前提是 Helm V3 已安装，安装方法请参考 这里。\n安装 2to3 插件 一键安装:\n$ helm3 plugin install https://github.com/helm/helm-2to3 Downloading and installing helm-2to3 v0.1.1 ... https://github.com/helm/helm-2to3/releases/download/v0.1.1/helm-2to3_0.1.1_linux_amd64.tar.gz Installed plugin: 2to3 检查插件是否安装成功:\n$ helm3 plugin list NAME VERSION DESCRIPTION 2to3 0.1.1 migrate Helm v2 configuration and releases in-place to Helm v3 迁移 Helm V2 配置 $ helm3 2to3 move config [Helm 2] Home directory: /root/.helm [Helm 3] Config directory: /root/.config/helm [Helm 3] Data directory: /root/.local/share/helm [Helm 3] Create config folder \u0026#34;/root/.config/helm\u0026#34; . [Helm 3] Config folder \u0026#34;/root/.config/helm\u0026#34; created. [Helm 2] repositories file \u0026#34;/root/.helm/repository/repositories.yaml\u0026#34; will copy to [Helm 3] config folder \u0026#34;/root/.config/helm/repositories.yaml\u0026#34; . [Helm 2] repositories file \u0026#34;/root/.helm/repository/repositories.yaml\u0026#34; copied successfully to [Helm 3] config folder \u0026#34;/root/.config/helm/repositories.yaml\u0026#34; . [Helm 3] Create data folder \u0026#34;/root/.local/share/helm\u0026#34; . [Helm 3] data folder \u0026#34;/root/.local/share/helm\u0026#34; created. [Helm 2] plugins \u0026#34;/root/.helm/plugins\u0026#34; will copy to [Helm 3] data folder \u0026#34;/root/.local/share/helm/plugins\u0026#34; . [Helm 2] plugins \u0026#34;/root/.helm/plugins\u0026#34; copied successfully to [Helm 3] data folder \u0026#34;/root/.local/share/helm/plugins\u0026#34; . [Helm 2] starters \u0026#34;/root/.helm/starters\u0026#34; will copy to [Helm 3] data folder \u0026#34;/root/.local/share/helm/starters\u0026#34; . [Helm 2] starters \u0026#34;/root/.helm/starters\u0026#34; copied successfully to [Helm 3] data folder \u0026#34;/root/.local/share/helm/starters\u0026#34; . 上面的操作主要是迁移:\n Chart 仓库 Helm 插件 Chart starters  检查下 repo 和 plugin:\n$ helm3 repo list NAME URL stable https://kubernetes-charts.storage.googleapis.com local http://127.0.0.1:8879/charts $ $ $ helm3 plugin list NAME VERSION DESCRIPTION 2to3 0.1.1 migrate Helm v2 configuration and releases in-place to Helm v3 push 0.1.1 Push chart package to TencentHub 迁移 Heml V2 Release 已经用 Helm V2 部署的应用也可以使用 2to3 的 convert 子命令迁移到 V3，先看下有哪些选项:\n$ helm3 2to3 convert --help migrate Helm v2 release in-place to Helm v3 Usage: 2to3 convert [flags] RELEASE Flags: --delete-v2-releases v2 releases are deleted after migration. By default, the v2 releases are retained --dry-run simulate a convert -h, --help help for convert -l, --label string label to select tiller resources by (default \u0026#34;OWNER=TILLER\u0026#34;) -s, --release-storage string v2 release storage type/object. It can be \u0026#39;secrets\u0026#39; or \u0026#39;configmaps\u0026#39;. This is only used with the \u0026#39;tiller-out-cluster\u0026#39; flag (default \u0026#34;secrets\u0026#34;) -t, --tiller-ns string namespace of Tiller (default \u0026#34;kube-system\u0026#34;) --tiller-out-cluster when Tiller is not running in the cluster e.g. Tillerless  --tiller-out-cluster: 如果你的 Helm V2 是 tiller 在集群外面 (tillerless) 的安装方式，请带上这个参数 --dry-run: 模拟迁移但不做真实迁移操作，建议每次迁移都先带上这个参数测试下效果，没问题的话再去掉这个参数做真实迁移 --tiller-ns: 通常 tiller 如果部署在集群中，并且不在 kube-system 命名空间才指定  看下目前有哪些 helm v2 的 release:\n$ helm ls NAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACE redis 1 Mon Sep 16 14:46:58 2019 DEPLOYED redis-9.1.3 5.0.5 default 选一个用 --dry-run 试下效果:\n$ helm3 2to3 convert redis --dry-run NOTE: This is in dry-run mode, the following actions will not be executed. Run without --dry-run to take the actions described below: Release \u0026#34;redis\u0026#34; will be converted from Helm 2 to Helm 3. [Helm 3] Release \u0026#34;redis\u0026#34; will be created. [Helm 3] ReleaseVersion \u0026#34;redis.v1\u0026#34; will be created. 没有报错，去掉 --dry-run 执行迁移:\n$ helm3 2to3 convert redis Release \u0026#34;redis\u0026#34; will be converted from Helm 2 to Helm 3. [Helm 3] Release \u0026#34;redis\u0026#34; will be created. [Helm 3] ReleaseVersion \u0026#34;redis.v1\u0026#34; will be created. [Helm 3] ReleaseVersion \u0026#34;redis.v1\u0026#34; created. [Helm 3] Release \u0026#34;redis\u0026#34; created. Release \u0026#34;redis\u0026#34; was converted successfully from Helm 2 to Helm 3. Note: the v2 releases still remain and should be removed to avoid conflicts with the migrated v3 releases. 检查迁移结果:\n$ helm ls NAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACE redis 1 Mon Sep 16 14:46:58 2019 DEPLOYED redis-9.1.3 5.0.5 default $ $ $ helm3 ls -a NAME NAMESPACE REVISION UPDATED STATUS CHART redis default 1 2019-09-16 06:46:58.541391356 +0000 UTC deployed redis-9.1.3  helm 3 的 release 区分了命名空间，带上 -a 参数展示所有命名空间的 release  参考资料  How to migrate from Helm v2 to Helm v3: https://helm.sh/blog/migrate-from-helm-v2-to-helm-v3/  "
},
{
	"uri": "https://k8s.imroc.io/deploy/manual/bootstrapping-master/",
	"title": "部署 Master",
	"tags": [],
	"description": "",
	"content": "准备证书  Master 节点的准备证书操作只需要做一次，将生成的证书拷到每个 Master 节点上以复用。\n前提条件:\n 签发证书需要用到 生成 CA 证书 时创建的 CA 证书及其密钥文件，确保它们在当前目录 确保 cfssl 在当前环境已安装，安装方法参考 这里  为 kube-apiserver 签发证书  kube-apiserver 是 k8s 的访问核心，所有 K8S 组件和用户 kubectl 操作都会请求 kube-apiserver，通常启用 tls 证书认证，证书里面需要包含 kube-apiserver 可能被访问的地址，这样 client 校验 kube-apiserver 证书时才会通过，集群内的 Pod 一般通过 kube-apiserver 的 Service 名称访问，可能的 Service 名称有:\n kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster kubernetes.default.svc.cluster.local  通过集群外也可能访问 kube-apiserver，比如使用 kubectl，或者部署在集群外的服务会连 kube-apiserver (比如部署在集群外的 Promethues 采集集群指标做监控)，这里列一下通过集群外连 kube-apiserver 有哪些可能地址:\n 127.0.0.1: 在 Master 所在机器通过 127.0.0.1 访问本机 kube-apiserver Service CIDR 的第一个 IP，比如 flanneld 以 daemonset 部署在每个节点，使用 hostNetwork 而不是集群网络，这时无法通过 service 名称访问 apiserver，因为使用 hostNetwork 无法解析 service 名称 (使用的 DNS 不是集群 DNS)，它会使用 apiserver 内部的 CLUSTER IP 去请求 apiserver。 kube-controller-manager 的 --service-cluster-ip-range 启动参数是 10.32.0.0/16，那么第一个 IP 就是 10.32.0.1 自定义域名: 配了 DNS，通过域名访问 kube-apiserver，也要将域名写入证书 LB IP: 如果 Master 节点前面挂了一个负载均衡器，外界可以通过 LB IP 来访问 kube-apiserver Master 节点 IP: 如果没有 Master 负载均衡器，管理员在节点上执行 kubectl 通常使用 Master 节点 IP 访问 kube-apiserver  准备 CSR 文件:\ncat \u0026gt; apiserver-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;kubernetes\u0026#34;, \u0026#34;hosts\u0026#34;: [ \u0026#34;127.0.0.1\u0026#34;, \u0026#34;10.32.0.1\u0026#34;, \u0026#34;10.200.16.79\u0026#34;, \u0026#34;kubernetes\u0026#34;, \u0026#34;kubernetes.default\u0026#34;, \u0026#34;kubernetes.default.svc\u0026#34;, \u0026#34;kubernetes.default.svc.cluster\u0026#34;, \u0026#34;kubernetes.default.svc.cluster.local\u0026#34; ], \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;Kubernetes\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;Kube API Server\u0026#34; } ] } EOF  hosts 这里只准备了必要的，根据需求可增加，通常 Master 节点 IP 也都要加进去，你可以执行了上面的命令后再编辑一下 apiserver-csr.json，将需要 hosts 都加进去。\n cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  apiserver-csr.json | cfssljson -bare apiserver 会生成下面两个重要的文件:\n apiserver-key.pem: kube-apiserver 证书密钥 apiserver.pem: kube-apiserver 证书  为 kube-controller-manager 签发证书  cat \u0026gt; kube-controller-manager-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;system:kube-controller-manager\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;system:kube-controller-manager\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;Kube Controller Manager\u0026#34; } ] } EOF cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager 生成以下两个文件:\n kube-controller-manager-key.pem: kube-controller-manager 证书密钥 kube-controller-manager.pem: kube-controller-manager 证书  为 kube-scheduler 签发证书  cat \u0026gt; kube-scheduler-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;system:kube-scheduler\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;system:kube-scheduler\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;Kube Scheduler\u0026#34; } ] } EOF cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  kube-scheduler-csr.json | cfssljson -bare kube-scheduler 生成以下两个文件:\n kube-scheduler-key.pem: kube-scheduler 证书密钥 kube-scheduler.pem: kube-scheduler 证书公钥  签发 Service Account 密钥对  kube-controller-manager 会使用此密钥对来给 service account 签发 token，更多详情参考官方文档: https://kubernetes.io/docs/reference/access-authn-authz/service-accounts-admin/\ncat \u0026gt; service-account-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;service-accounts\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;Kubernetes\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;Service Account\u0026#34; } ] } EOF cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  service-account-csr.json | cfssljson -bare service-account 生成以下两个文件:\n service-account-key.pem: service account 证书公钥 service-account.pem: service account 证书私钥  为管理员签发证书  为最高权限管理员证书:\ncat \u0026gt; admin-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;system:masters\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;System\u0026#34; } ] } EOF cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  admin-csr.json | cfssljson -bare admin 生成一下两个文件:\n admin-key.pem: 管理员证书密钥 admin.pem: 管理员证书  给用户签发证书后，用户访问 kube-apiserver 的请求就带上此证书，kube-apiserver 校验成功后表示认证成功，但还需要授权才允许访问，kube-apiserver 会提取证书中字段 CN 作为用户名，这里用户名叫 admin，但这只是个名称标识，它有什么权限呢？admin 是预置最高权限的用户名吗？不是的！不过 kube-apiserver 确实预置了一个最高权限的 ClusterRole，叫做 cluster-admin，还有个预置的 ClusterRoleBinding 将 cluster-admin 这个 ClusterRole 与 system:masters 这个用户组关联起来了，所以说我们给用户签发证书只要在 system:masters 这个用户组就拥有了最高权限。\n以此类推，我们签发证书时也可以将用户设置到其它用户组，然后为其创建 RBAC 规则来细粒度的控制权限，减少安全隐患。\n更多 K8S 预置的 Role 与 RoleBinding 请参考: https://kubernetes.io/docs/reference/access-authn-authz/rbac/#default-roles-and-role-bindings\n准备 kubeconfig  部署 Master 的准备 kubeconfig 操作只需要做一次，将生成的 kubeconfig 拷到每个 Master 节点上以复用。\nkubeconfig 主要是各组件以及用户访问 apiserver 的必要配置，包含 apiserver 地址、client 证书与 CA 证书等信息。下面介绍为各个组件生成 kubeconfig 的方法。\n前提条件:\n 我们使用 kubectl 来辅助生成 kubeconfig，确保 kubectl 已安装。 生成 kubeconfig 会用到之前准备证书时创建的证书与密钥，确保这些生成的文件在当前目录。  确定 apiserver 访问入口 所有组件都会去连 apiserver，所以首先需要确定你的 apiserver 访问入口的地址:\n 如果所有 master 组件都部署在一个节点，它们可以通过 127.0.0.1 这个 IP访问 apiserver。 如果 master 有多个节点，但 apiserver 只有一个实例，可以直接写 apiserver 所在机器的内网 IP 访问地址。 如果做了高可用，有多个 apiserver 实例，前面挂了负载均衡器，就可以写负载均衡器的访问地址。 入口地址的域名或IP必须是在之前 为 kube-apiserver 签发证书 的 hosts 列表里。  这里我们用 APISERVER 这个变量表示 apiserver 的访问地址，其它组件都需要配置这个地址，根据自身情况改下这个变量的值:\nAPISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; 为 kube-controller-manager 创建 kubeconfig  APISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; kubectl config set-cluster roc \\  --certificate-authority=ca.pem \\  --embed-certs=true \\  --server=${APISERVER} \\  --kubeconfig=kube-controller-manager.kubeconfig kubectl config set-credentials system:kube-controller-manager \\  --client-certificate=kube-controller-manager.pem \\  --client-key=kube-controller-manager-key.pem \\  --embed-certs=true \\  --kubeconfig=kube-controller-manager.kubeconfig kubectl config set-context default \\  --cluster=roc \\  --user=system:kube-controller-manager \\  --kubeconfig=kube-controller-manager.kubeconfig kubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig 生成文件:\nkube-controller-manager.kubeconfig 为 kube-scheduler 创建 kubeconfig  APISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; kubectl config set-cluster roc \\  --certificate-authority=ca.pem \\  --embed-certs=true \\  --server=${APISERVER} \\  --kubeconfig=kube-scheduler.kubeconfig kubectl config set-credentials system:kube-scheduler \\  --client-certificate=kube-scheduler.pem \\  --client-key=kube-scheduler-key.pem \\  --embed-certs=true \\  --kubeconfig=kube-scheduler.kubeconfig kubectl config set-context default \\  --cluster=roc \\  --user=system:kube-scheduler \\  --kubeconfig=kube-scheduler.kubeconfig kubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig 生成文件:\nkube-scheduler.kubeconfig 为管理员创建 kubeconfig  这里为管理员生成 kubeconfig，方便使用 kubectl 来管理集群:\nAPISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; kubectl config set-cluster roc \\  --certificate-authority=ca.pem \\  --embed-certs=true \\  --server=${APISERVER} \\  --kubeconfig=admin.kubeconfig kubectl config set-credentials admin \\  --client-certificate=admin.pem \\  --client-key=admin-key.pem \\  --embed-certs=true \\  --kubeconfig=admin.kubeconfig kubectl config set-context default \\  --cluster=roc \\  --user=admin \\  --kubeconfig=admin.kubeconfig kubectl config use-context default --kubeconfig=admin.kubeconfig 生成文件:\nadmin.kubeconfig 将 admin.kubeconfig 放到需要执行 kubectl 的机器的 ~/.kube/config 这个目录，这是 kubectl 读取 kubeconfig 的默认路径，执行 kubectl 时就不需要指定 kubeconfig 路径了:\nmv admin.kubeconfig ~/.kube/config 下载安装控制面组件 wget -q --show-progress --https-only --timestamping \\  https://storage.googleapis.com/kubernetes-release/release/v1.16.1/bin/linux/amd64/kube-apiserver \\  https://storage.googleapis.com/kubernetes-release/release/v1.16.1/bin/linux/amd64/kube-controller-manager \\  https://storage.googleapis.com/kubernetes-release/release/v1.16.1/bin/linux/amd64/kube-scheduler chmod +x kube-apiserver kube-controller-manager kube-scheduler mv kube-apiserver kube-controller-manager kube-scheduler /usr/local/bin/ 配置控制面组件  准备配置相关目录:\nsudo mkdir -p /etc/kubernetes/config sudo mkdir -p /var/lib/kubernetes 确定集群的集群网段 (Pod IP 占用网段)和 serivce 网段 (service 的 cluster ip 占用网段)，它们可以没有交集。\n记集群网段为 CLUSTER_CIDR:\nCLUSTER_CIDR=10.10.0.0/16 记 service 网段为 SERVICE_CIDR:\nSERVICE_CIDR=10.32.0.0/16 配置 kube-apiserver  放入证书文件:\nsudo cp ca.pem ca-key.pem apiserver-key.pem apiserver.pem \\  service-account-key.pem service-account.pem /var/lib/kubernetes/ 记所有 ETCD 实例的访问地址为 ETCD_SERVERS (替换 IP 为所有 ETCD 节点内网 IP):\nETCD_SERVERS=\u0026#34;https://10.200.16.79:2379,https://10.200.17.6:2379,https://10.200.16.70:2379\u0026#34; 记当前节点内网 IP 为 INTERNAL_IP:\nINTERNAL_IP=10.200.16.79 配置 systemd:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kube-apiserver.service [Unit] Description=Kubernetes API Server Documentation=https://github.com/kubernetes/kubernetes [Service] ExecStart=/usr/local/bin/kube-apiserver \\\\ --enable-bootstrap-token-auth=true \\\\ --advertise-address=${INTERNAL_IP} \\\\ --allow-privileged=true \\\\ --apiserver-count=3 \\\\ --audit-log-maxage=30 \\\\ --audit-log-maxbackup=3 \\\\ --audit-log-maxsize=100 \\\\ --audit-log-path=/var/log/audit.log \\\\ --authorization-mode=Node,RBAC \\\\ --bind-address=0.0.0.0 \\\\ --client-ca-file=/var/lib/kubernetes/ca.pem \\\\ --enable-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \\\\ --etcd-cafile=/var/lib/kubernetes/ca.pem \\\\ --etcd-certfile=/var/lib/kubernetes/apiserver.pem \\\\ --etcd-keyfile=/var/lib/kubernetes/apiserver-key.pem \\\\ --etcd-servers=${ETCD_SERVERS} \\\\ --event-ttl=1h \\\\ --kubelet-certificate-authority=/var/lib/kubernetes/ca.pem \\\\ --kubelet-client-certificate=/var/lib/kubernetes/apiserver.pem \\\\ --kubelet-client-key=/var/lib/kubernetes/apiserver-key.pem \\\\ --kubelet-https=true \\\\ --runtime-config=api/all \\\\ --service-account-key-file=/var/lib/kubernetes/service-account.pem \\\\ --service-cluster-ip-range=${SERVICE_CIDR} \\\\ --service-node-port-range=30000-32767 \\\\ --tls-cert-file=/var/lib/kubernetes/apiserver.pem \\\\ --tls-private-key-file=/var/lib/kubernetes/apiserver-key.pem \\\\ --v=2 Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF  --enable-bootstrap-token-auth=true 启用 bootstrap token 方式为 kubelet 签发证书  配置 kube-controller-manager  放入 kubeconfig:\nsudo cp kube-controller-manager.kubeconfig /var/lib/kubernetes/ 准备 systemd 配置 kube-controller-manager.service:\nCLUSTER_CIDR=10.10.0.0/16 SERVICE_CIDR=10.32.0.0/16 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kube-controller-manager.service [Unit] Description=Kubernetes Controller Manager Documentation=https://github.com/kubernetes/kubernetes [Service] ExecStart=/usr/local/bin/kube-controller-manager \\\\ --address=0.0.0.0 \\\\ --cluster-cidr=${CLUSTER_CIDR} \\\\ --allocate-node-cidrs \\\\ --cluster-name=kubernetes \\\\ --cluster-signing-cert-file=/var/lib/kubernetes/ca.pem \\\\ --cluster-signing-key-file=/var/lib/kubernetes/ca-key.pem \\\\ --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \\\\ --leader-elect=true \\\\ --root-ca-file=/var/lib/kubernetes/ca.pem \\\\ --service-account-private-key-file=/var/lib/kubernetes/service-account-key.pem \\\\ --service-cluster-ip-range=${SERVICE_CIDR} \\\\ --use-service-account-credentials=true \\\\ --v=2 Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF  所有 kube-controller-manager 实例都使用相同的 systemd service 文件，可以直接将这里创建好的拷贝给其它 Master 节点\n 配置 kube-scheduler  放入 kubeconfig:\nsudo cp kube-scheduler.kubeconfig /var/lib/kubernetes/ 准备启动配置文件 kube-scheduler.yaml:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/kubernetes/config/kube-scheduler.yaml apiVersion: kubescheduler.config.k8s.io/v1alpha1 kind: KubeSchedulerConfiguration clientConnection: kubeconfig: \u0026#34;/var/lib/kubernetes/kube-scheduler.kubeconfig\u0026#34; leaderElection: leaderElect: true EOF 准备 systemd 配置 kube-scheduler.service:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kube-scheduler.service [Unit] Description=Kubernetes Scheduler Documentation=https://github.com/kubernetes/kubernetes [Service] ExecStart=/usr/local/bin/kube-scheduler \\\\ --config=/etc/kubernetes/config/kube-scheduler.yaml \\\\ --v=2 Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF 启动 sudo systemctl daemon-reload sudo systemctl enable kube-apiserver kube-controller-manager kube-scheduler sudo systemctl start kube-apiserver kube-controller-manager kube-scheduler RBAC 授权 kube-apiserver 访问 kubelet kube-apiserver 有些情况也会访问 kubelet，比如获取 metrics、查看容器日志或登录容器，这是 kubelet 作为 server， kube-apiserver 作为 client，kubelet 监听的 https，kube-apiserver 经过证书认证访问 kubelet，但还需要经过授权才能成功调用接口，我们通过创建 RBAC 规则授权 kube-apiserver 访问 kubelet:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRole metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \u0026#34;true\u0026#34; labels: kubernetes.io/bootstrapping: rbac-defaults name: system:kube-apiserver-to-kubelet rules: - apiGroups: - \u0026#34;\u0026#34; resources: - nodes/proxy - nodes/stats - nodes/log - nodes/spec - nodes/metrics verbs: - \u0026#34;*\u0026#34; EOF cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: system:kube-apiserver namespace: \u0026#34;\u0026#34; roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-apiserver-to-kubelet subjects: - apiGroup: rbac.authorization.k8s.io kind: User name: kubernetes EOF RBAC 授权 kubelet 创建 CSR 与自动签发和更新证书  节点 kubelet 通过 Bootstrap Token 调用 apiserver CSR API 请求签发证书，kubelet 通过 bootstrap token 认证后会在 system:bootstrappers 用户组里，我们还需要给它授权调用 CSR API，为这个用户组绑定预定义的 system:node-bootstrapper 这个 ClusterRole 就可以:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - # enable bootstrapping nodes to create CSR apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: create-csrs-for-bootstrapping subjects: - kind: Group name: system:bootstrappers apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: system:node-bootstrapper apiGroup: rbac.authorization.k8s.io EOF  这里的 CSR API 主要用于 kubelet 发起 client 和 server 证书签发请求\n 给 kubelet 授权自动审批通过 client 证书的 CSR 请求权限以实现自动创建新的 client 证书 (之前没创建过 client 证书，通过 bootstrap token 认证后在 system:bootstrappers 用户组里):\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - # Approve all CSRs for the group \u0026#34;system:bootstrappers\u0026#34; apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: auto-approve-csrs-for-group subjects: - kind: Group name: system:bootstrappers apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: system:certificates.k8s.io:certificatesigningrequests:nodeclient apiGroup: rbac.authorization.k8s.io EOF 给已启动过的 kubelet 授权自动审批通过 server 证书的 CSR 请求权限以实现自动轮转 client 证书 (之前创建过证书，在证书还未过期前通过证书认证后在 system:nodes 用户组里):\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - # Approve renewal CSRs for the group \u0026#34;system:nodes\u0026#34; apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: auto-approve-renewals-for-nodes subjects: - kind: Group name: system:nodes apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient apiGroup: rbac.authorization.k8s.io EOF  注意上面两个授权都只是针对于 client 证书签发的自动审批权限，server 证书目前不支持自动审批，需要管理员通过 kubectl certificate approve \u0026lt;csr name\u0026gt; 来人工审批或者自己写外部 controller 来实现自动审批 (kubelet 访问 apiserver 使用 client 证书, apiserver 主动访问 kubelet 时才会用到 server 证书，通常用于获取 metrics 的场景)\n 创建 Bootstrap Token 与 bootstrap-kubeconfig  bootstrap token 用于 kubelet 自动请求签发证书，以 Secret 形式存储，不需要事先给 apiserver 配置静态 token，这样也易于管理。\n创建了 bootstrap token 后我们利用它使用它来创建 bootstrap-kubeconfig 以供后面部署 Worker 节点用 (kubelet 使用 bootstrap-kubeconfig 自动创建证书)，下面是创建方法:\nAPISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; # token id should match regex: [a-z0-9]{6} TOKEN_ID=$(head -c 16 /dev/urandom | od -An -t x | tr -d \u0026#39; \u0026#39; | head -c 6) # token secret should match regex: [a-z0-9]{16} TOKEN_SECRET=$(head -c 16 /dev/urandom | od -An -t x | tr -d \u0026#39; \u0026#39; | head -c 16) cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: Secret metadata: # Name MUST be of form \u0026#34;bootstrap-token-\u0026lt;token id\u0026gt;\u0026#34;, name: bootstrap-token-${TOKEN_ID} namespace: kube-system # Type MUST be \u0026#39;bootstrap.kubernetes.io/token\u0026#39; type: bootstrap.kubernetes.io/token stringData: # Human readable description. Optional. description: \u0026#34;The default bootstrap token used for signing certificates\u0026#34; # Token ID and secret. Required. token-id: \u0026#34;${TOKEN_ID}\u0026#34; token-secret: \u0026#34;${TOKEN_SECRET}\u0026#34; # Expiration. Optional. # expiration: 2020-03-10T03:22:11Z # Allowed usages. usage-bootstrap-authentication: \u0026#34;true\u0026#34; usage-bootstrap-signing: \u0026#34;true\u0026#34; # Extra groups to authenticate the token as. Must start with \u0026#34;system:bootstrappers:\u0026#34; # auth-extra-groups: system:bootstrappers:worker,system:bootstrappers:ingress EOF kubectl config --kubeconfig=bootstrap-kubeconfig set-cluster bootstrap --server=\u0026#34;${APISERVER}\u0026#34; --certificate-authority=ca.pem --embed-certs=true kubectl config --kubeconfig=bootstrap-kubeconfig set-credentials kubelet-bootstrap --token=${TOKEN_ID}.${TOKEN_SECRET} kubectl config --kubeconfig=bootstrap-kubeconfig set-context bootstrap --user=kubelet-bootstrap --cluster=bootstrap kubectl config --kubeconfig=bootstrap-kubeconfig use-context bootstrap  bootstrap token 的 secret 格式参考: https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/#bootstrap-token-secret-format\n 生成文件:\nbootstrap-kubeconfig "
},
{
	"uri": "https://k8s.imroc.io/cluster/",
	"title": "集群方案",
	"tags": [],
	"description": "",
	"content": "  Ingress 方案    Nginx Ingress    大规模场景下 Prometheus 的优化手段   Thanos 架构详解   Thanos 部署与实践    Traefik Ingress    安装 traefik ingress controller     Metrics 方案    安装 metrics server      网络方案    Flannel    部署 Flannel    彻底理解集群网络      运行时方案    Containerd    安装 containerd     "
},
{
	"uri": "https://k8s.imroc.io/configuration/helm/helm-faq/",
	"title": "Helm 常见问题",
	"tags": [],
	"description": "",
	"content": "helm 3 没有内置 stable repo 默认没有，可以手动添加:\nhelm repo add stable https://kubernetes-charts.storage.googleapis.com 国内环境的可以用国内的 mirror:\nhelm repo add stable https://apphub.aliyuncs.com/stable "
},
{
	"uri": "https://k8s.imroc.io/deploy/manual/bootstrapping-worker-nodes/",
	"title": "部署 Worker 节点",
	"tags": [],
	"description": "",
	"content": "Worker 节点主要安装 kubelet 来管理、运行工作负载 (Master 节点也可以部署为特殊 Worker 节点来部署关键服务)\n安装依赖 sudo apt-get update sudo apt-get -y install socat conntrack ipset 禁用 Swap 默认情况下，如果开启了 swap，kubelet 会启动失败，k8s 节点推荐禁用 swap。\n验证一下是否开启:\nsudo swapon --show 如果输出不是空的说明开启了 swap，使用下面的命令禁用 swap:\nsudo swapoff -a 为了防止开机自动挂载 swap 分区，可以注释 /etc/fstab 中相应的条目:\nsudo sed -i \u0026#39;/ swap / s/^\\(.*\\)$/#\\1/g\u0026#39; /etc/fstab 关闭 SELinux 关闭 SELinux，否则后续 K8S 挂载目录时可能报错 Permission denied：\nsudo setenforce 0 修改配置文件，永久生效:\nsudo sed -i \u0026#34;s/SELINUX=enforcing/SELINUX=disabled/g\u0026#34; /etc/selinux/config 准备目录 sudo mkdir -p \\  /etc/cni/net.d \\  /opt/cni/bin \\  /var/lib/kubelet \\  /var/lib/kubernetes \\  /var/run/kubernetes 下载安装二进制 下载二进制:\nwget -q --show-progress --https-only --timestamping \\  https://github.com/opencontainers/runc/releases/download/v1.0.0-rc8/runc.amd64 \\  https://github.com/containerd/containerd/releases/download/v1.3.0/containerd-1.3.0.linux-amd64.tar.gz \\  https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.16.1/crictl-v1.16.1-linux-amd64.tar.gz \\  https://github.com/containernetworking/plugins/releases/download/v0.8.2/cni-plugins-linux-amd64-v0.8.2.tgz \\  https://storage.googleapis.com/kubernetes-release/release/v1.16.1/bin/linux/amd64/kubelet sudo mv runc.amd64 runc 安装二进制:\nchmod +x crictl kubelet runc tar -xvf crictl-v1.16.1-linux-amd64.tar.gz mkdir containerd tar -xvf containerd-1.3.0.linux-amd64.tar.gz -C containerd sudo cp crictl kubelet runc /usr/local/bin/ sudo cp containerd/bin/* /bin/ sudo tar -xvf cni-plugins-linux-amd64-v0.8.2.tgz -C /opt/cni/bin/ 配置 配置 containerd 创建 containerd 启动配置 config.toml:\nsudo mkdir -p /etc/containerd/ cat \u0026lt;\u0026lt; EOF | sudo tee /etc/containerd/config.toml [plugins] [plugins.cri.containerd] snapshotter = \u0026#34;overlayfs\u0026#34; [plugins.cri.containerd.default_runtime] runtime_type = \u0026#34;io.containerd.runtime.v1.linux\u0026#34; runtime_engine = \u0026#34;/usr/local/bin/runc\u0026#34; runtime_root = \u0026#34;\u0026#34; EOF 创建 systemd 配置 containerd.service:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/containerd.service [Unit] Description=containerd container runtime Documentation=https://containerd.io After=network.target [Service] ExecStartPre=/sbin/modprobe overlay ExecStart=/bin/containerd Restart=always RestartSec=5 Delegate=yes KillMode=process OOMScoreAdjust=-999 LimitNOFILE=1048576 LimitNPROC=infinity LimitCORE=infinity [Install] WantedBy=multi-user.target EOF 配置 kubelet 放入 这里 创建好的 CA 证书与 这里 创建好的 bootstrap-kubeconfig:\nsudo cp ca.pem /var/lib/kubernetes/ sudo cp bootstrap-kubeconfig /var/lib/kubelet/ 事先确定好集群 DNS 的 CLUSTER IP 地址，通常可以用 service 网段的最后一个可用 IP 地址:\nDNS=10.32.0.255 创建 kubelet 启动配置 config.yaml:\ncat \u0026lt;\u0026lt;EOF | sudo tee /var/lib/kubelet/config.yaml kind: KubeletConfiguration apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false webhook: enabled: true x509: clientCAFile: \u0026#34;/var/lib/kubernetes/ca.pem\u0026#34; authorization: mode: Webhook clusterDomain: \u0026#34;cluster.local\u0026#34; clusterDNS: - \u0026#34;${DNS}\u0026#34; resolvConf: \u0026#34;/run/systemd/resolve/resolv.conf\u0026#34; runtimeRequestTimeout: \u0026#34;15m\u0026#34; rotateCertificates: true serverTLSBootstrap: true EOF 用 NODE 变量表示节点名称，kube-apiserver 所在节点需要能够通过这个名称访问到节点，这里推荐直接使用节点内网 IP，不需要配 hosts 就能访问:\nNODE=\u0026#34;10.200.16.79\u0026#34; 创建 systemd 配置 kubelet.service:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kubelet.service [Unit] Description=Kubernetes Kubelet Documentation=https://github.com/kubernetes/kubernetes After=containerd.service Requires=containerd.service [Service] ExecStart=/usr/local/bin/kubelet \\\\ --config=/var/lib/kubelet/config.yaml \\\\ --container-runtime=remote \\\\ --container-runtime-endpoint=unix:///var/run/containerd/containerd.sock \\\\ --image-pull-progress-deadline=2m \\\\ --bootstrap-kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig \\\\ --kubeconfig=/var/lib/kubelet/kubeconfig \\\\ --network-plugin=cni \\\\ --register-node=true \\\\ --hostname-override=${NODE} \\\\ --v=2 Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF 启动 sudo systemctl daemon-reload sudo systemctl enable containerd kubelet sudo systemctl start containerd kubelet 验证 配置好 kubectl，执行下 kubectl:\n$ kubectl get node NAME STATUS ROLES AGE VERSION 10.200.16.79 NotReady \u0026lt;none\u0026gt; 11m v1.16.1 没有装网络插件，节点状态会是 NotReady，带 node.kubernetes.io/not-ready:NoSchedule 这个污点，默认是无法调度普通 Pod，这个是正常的。后面会装网络插件，通常以 Daemonset 部署，使用 hostNetwork，并且容忍这个污点。\n签发 kubelet server 证书 由于之前做过 RBAC 授权 kubelet 创建 CSR 与自动签发和更新证书，kubelet 启动时可以发起 client 与 server 证书的 CSR 请求，并自动审批通过 client 证书的 CSR 请求，kube-controller-manager 在自动执行证书签发，最后 kubelet 可以获取到 client 证书并加入集群，我们可以在 /var/lib/kubelet/pki 下面看到签发出来的 client 证书:\nls -l /var/lib/kubelet/pki total 4 -rw------- 1 root root 1277 Oct 10 20:46 kubelet-client-2019-10-10-20-46-23.pem lrwxrwxrwx 1 root root 59 Oct 10 20:46 kubelet-client-current.pem -\u0026gt; /var/lib/kubelet/pki/kubelet-client-2019-10-10-20-46-23.pem  kubeconfig 中引用这里的 kubelet-client-current.pem 这个证书，是一个指向证书 bundle 的软连接，包含证书公钥与私钥\n 但 server 证书默认无法自动审批，需要管理员人工审批，下面是审批方法，首先看下未审批的 CSR:\n$ kubectl get csr NAME AGE REQUESTOR CONDITION csr-6gkn6 2m4s system:bootstrap:360483 Approved,Issued csr-vf285 103s system:node:10.200.17.6 Pending  可以看到 system:bootstrap 开头的用户的 CSR 请求已经自动 approve 并签发证书了，这就是因为 kubelet 使用 bootstrap token 认证后在 system:bootstrappers 用户组，而我们创建了对应 RBAC 为此用户组授权自动 approve CSR 的权限。下面 system:node 开头的用户的 CSR 请求状态是 Pending，需要管理员来 approve。\n $ kubectl certificate approve csr-vf285 certificatesigningrequest.certificates.k8s.io/csr-vf285 approved $ ls -l /var/lib/kubelet/pki total 8 -rw------- 1 root root 1277 Oct 10 20:46 kubelet-client-2019-10-10-20-46-23.pem lrwxrwxrwx 1 root root 59 Oct 10 20:46 kubelet-client-current.pem -\u0026gt; /var/lib/kubelet/pki/kubelet-client-2019-10-10-20-46-23.pem -rw------- 1 root root 1301 Oct 10 21:09 kubelet-server-2019-10-10-21-09-15.pem lrwxrwxrwx 1 root root 59 Oct 10 21:09 kubelet-server-current.pem -\u0026gt; /var/lib/kubelet/pki/kubelet-server-2019-10-10-21-09-15.pem  和 client 证书一样，kubelet-server-current.pem 也是一个指向证书 bundle 的软连接，包含证书公钥与私钥，用与 kubelet 监听 10250 端口\n "
},
{
	"uri": "https://k8s.imroc.io/deploy/manual/deploy-critical-addons/",
	"title": "部署关键组件",
	"tags": [],
	"description": "",
	"content": "部署 kube-proxy kube-proxy 会请求 apiserver 获取 Service 及其 Endpoint，将 Service 的 ClUSTER IP 与对应 Endpoint 的 Pod IP 映射关系转换成 iptables 或 ipvs 规则写到节点上，实现 Service 转发。\n部署方法参考 以 Daemonset 方式部署 kube-proxy\n部署网络插件 参考 部署 Flannel\n部署集群 DNS 集群 DNS 是 Kubernetes 的核心功能之一，被许多服务所依赖，用于解析集群内 Pod 的 DNS 请求，包括:\n 解析 service 名称成对应的 CLUSTER IP 解析 headless service 名称成对应 Pod IP (选取一个 endpoint 的 Pod IP 返回) 解析外部域名(代理 Pod 请求上游 DNS)  可以通过部署 kube-dns 或 CoreDNS 作为集群的必备扩展来提供命名服务，推荐使用 CoreDNS，效率更高，资源占用率更小，部署方法参考 部署 CoreDNS\n"
},
{
	"uri": "https://k8s.imroc.io/monitoring/build-cloud-native-large-scale-distributed-monitoring-system/optimize-prometheus-in-large-scale/",
	"title": "大规模场景下 Prometheus 的优化手段",
	"tags": [],
	"description": "",
	"content": "概述 Prometheus 几乎已成为监控领域的事实标准，它自带高效的时序数据库存储，可以让单台 Prometheus 能够高效的处理大量的数据，还有友好并且强大的 PromQL 语法，可以用来灵活的查询各种监控数据以及配置告警规则，同时它的 pull 模型指标采集方式被广泛采纳，非常多的应用都实现了 Prometheus 的 metrics 接口以暴露自身各项数据指标让 Prometheus 去采集，很多没有适配的应用也会有第三方 exporter 帮它去适配 Prometheus，所以监控系统我们通常首选用 Prometheus，本系列文章也将基于 Prometheus 来打造云原生环境下的大型分布式监控系统。\n大规模场景下 Prometheus 的痛点 Prometheus 本身只支持单机部署，没有自带支持集群部署，也就不支持高可用以及水平扩容，在大规模场景下，最让人关心的问题是它的存储空间也受限于单机磁盘容量，磁盘容量决定了单个 Prometheus 所能存储的数据量，数据量大小又取决于被采集服务的指标数量、服务数量、采集速率以及数据过期时间。在数据量大的情况下，我们可能就需要做很多取舍，比如丢弃不重要的指标、降低采集速率、设置较短的数据过期时间(默认只保留15天的数据，看不到比较久远的监控数据)。\n这些痛点实际也是可以通过一些优化手段来改善的，下面我们来细讲一下。\n从服务维度拆分 Prometheus Prometheus 主张根据功能或服务维度进行拆分，即如果要采集的服务比较多，一个 Prometheus 实例就配置成仅采集和存储某一个或某一部分服务的指标，这样根据要采集的服务将 Prometheus 拆分成多个实例分别去采集，也能一定程度上达到水平扩容的目的。\n通常这样的扩容方式已经能满足大部分场景的需求了，毕竟单机 Prometheus 就能采集和处理很多数据了，很少有 Prometheus 撑不住单个服务的场景。不过在超大规模集群下，有些单个服务的体量也很大，就需要进一步拆分了，我们下面来继续讲下如何再拆分。\n对超大规模的服务做分片 想象一下，如果集群节点数量达到上千甚至几千的规模，对于一些节点级服务暴露的指标，比如 kubelet 内置的 cadvisor 暴露的容器相关的指标，又或者部署的 DeamonSet node-exporter 暴露的节点相关的指标，在集群规模大的情况下，它们这种单个服务背后的指标数据体量就非常大；还有一些用户量超大的业务，单个服务的 pod 副本数就可能过千，这种服务背后的指标数据也非常大，当然这是最罕见的场景，对于绝大多数的人来说这种场景都只敢 YY 一下，实际很少有单个服务就达到这么大规模的业务。\n针对上面这些大规模场景，一个 Prometheus 实例可能连这单个服务的采集任务都扛不住。Prometheus 需要向这个服务所有后端实例发请求采集数据，由于后端实例数量规模太大，采集并发量就会很高，一方面对节点的带宽、CPU、磁盘 IO 都有一定的压力，另一方面 Prometheus 使用的磁盘空间有限，采集的数据量过大很容易就将磁盘塞满了，通常要做一些取舍才能将数据量控制在一定范围，但这种取舍也会降低数据完整和精确程度，不推荐这样做。\n那么如何优化呢？我们可以给这种大规模类型的服务做一下分片(Sharding)，将其拆分成多个 group，让一个 Prometheus 实例仅采集这个服务背后的某一个 group 的数据，这样就可以将这个大体量服务的监控数据拆分到多个 Prometheus 实例上。\n如何将一个服务拆成多个 group 呢？下面介绍两种方案，以对 kubelet cadvisor 数据做分片为例。\n第一，我们可以不用 Kubernetes 的服务发现，自行实现一下 sharding 算法，比如针对节点级的服务，可以将某个节点 shard 到某个 group 里，然后再将其注册到 Prometheus 所支持的服务发现注册中心，推荐 consul，最后在 Prometheus 配置文件加上 consul_sd_config 的配置，指定每个 Prometheus 实例要采集的 group。\n- job_name: \u0026#39;cadvisor-1\u0026#39; consul_sd_configs: - server: 10.0.0.3:8500 services: - cadvisor-1 # This is the 2nd slave 在未来，你甚至可以直接利用 Kubernetes 的 EndpointSlice 特性来做服务发现和分片处理，在超大规模服务场景下就可以不需要其它的服务发现和分片机制。不过暂时此特性还不够成熟，没有默认启用，不推荐用(当前 Kubernentes 最新版本为 1.18)。\n第二，用 Kubernetes 的 node 服务发现，再利用 Prometheus relabel 配置的 hashmod 来对 node 做分片，每个 Prometheus 实例仅抓其中一个分片中的数据:\n- job_name: \u0026#39;cadvisor-1\u0026#39; metrics_path: /metrics/cadvisor scheme: https # 请求 kubelet metrics 接口也需要认证和授权，通常会用 webhook 方式让 apiserver 代理进行 RBAC 校验，所以还是用 ServiceAccount 的 token bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node # 通常不校验 kubelet 的 server 证书，避免报 x509: certificate signed by unknown authority tls_config: insecure_skip_verify: true relabel_configs: - source_labels: [__address__] modulus: 4 # 将节点分片成 4 个 group target_label: __tmp_hash action: hashmod - source_labels: [__tmp_hash] regex: ^1$ # 只抓第 2 个 group 中节点的数据(序号 0 为第 1 个 group) action: keep 拆分引入的新问题 前面我们通过不通层面对 Prometheus 进行了拆分部署，一方面使得 Prometheus 能够实现水平扩容，另一方面也加剧了监控数据落盘的分散程度，使用 Grafana 查询监控数据时我们也需要添加许多数据源，而且不同数据源之间的数据还不能聚合查询，监控页面也看不到全局的视图，造成查询混乱的局面。\n要解决这个问题，我们可以从下面的两方面入手，任选其中一种方案。\n集中数据存储 我们可以让 Prometheus 不负责存储，仅采集数据并通过 remote write 方式写入远程存储的 adapter，远程存储使用 OpenTSDB 或 InfluxDB 这些支持集群部署的时序数据库，Prometheus 配置:\nremote_write: - url: http://10.0.0.2:8888/write 然后 Grafana 添加我们使用的时序数据库作为数据源来查询监控数据来展示，架构图:\n这种方式相当于更换了存储引擎，由其它支持存储水平扩容的时序数据库来存储庞大的数据量，这样我们就可以将数据集中到一起。OpenTSDB 支持 HBase, BigTable 作为存储后端，InfluxDB 企业版支持集群部署和水平扩容(开源版不支持)。不过这样的话，我们就无法使用友好且强大的 PromQL 来查询监控数据了，必须使用我们存储数据的时序数据库所支持的语法来查询。\nPrometheus 联邦 除了上面更换存储引擎的方式，还可以将 Prometheus 进行联邦部署。\n简单来说，就是将多个 Prometheus 实例采集的数据再用另一个 Prometheus 采集汇总到一起，这样也意味着需要消耗更多的资源。通常我们只把需要聚合的数据或者需要在一个地方展示的数据用这种方式采集汇总到一起，比如 Kubernetes 节点数过多，cadvisor 的数据分散在多个 Prometheus 实例上，我们就可以用这种方式将 cadvisor 暴露的容器指标汇总起来，以便于在一个地方就能查询到集群中任意一个容器的监控数据或者某个服务背后所有容器的监控数据的聚合汇总以及配置告警；又或者多个服务有关联，比如通常应用只暴露了它应用相关的指标，但它的资源使用情况(比如 cpu 和 内存) 由 cadvisor 来感知和暴露，这两部分指标由不同的 Prometheus 实例所采集，这时我们也可以用这种方式将数据汇总，在一个地方展示和配置告警。\n更多说明和配置示例请参考官方文档: https://prometheus.io/docs/prometheus/latest/federation/\nPrometheus 高可用 虽然上面我们通过一些列操作将 Prometheus 进行了分布式改造，但并没有解决 Prometheus 本身的高可用问题，即如果其中一个实例挂了，数据的查询和完整性都将受到影响。\n我们可以将所有 Prometheus 实例都使用两个相同副本，分别挂载数据盘，它们都采集相同的服务，所以它们的数据是一致的，查询它们之中任意一个都可以，所以可以在它们前面再挂一层负载均衡，所有查询都经过这个负载均衡分流到其中一台 Prometheus，如果其中一台挂掉就从负载列表里踢掉不再转发。\n这里的负载均衡可以根据实际环境选择合适的方案，可以用 Nginx 或 HAProxy，在 Kubernetes 环境，通常使用 Kubernentes 的 Service，由 kube-proxy 生成的 iptables/ipvs 规则转发，如果使用 Istio，还可以用 VirtualService，由 envoy sidecar 去转发。\n这样就实现了 Prometheus 的高可用，简单起见，上面的图仅展示单个 Prometheus 的高可用，当你可以将其拓展，代入应用到上面其它的优化手段中，实现整体的高可用。\n总结 通过本文一系列对 Prometheus 的优化手段，我们在一定程度上解决了单机 Prometheus 在大规模场景下的痛点，但操作和运维复杂度比较高，并且不能够很好的支持数据的长期存储(long term storage)。对于一些时间比较久远的监控数据，我们通常查看的频率很低，但也希望能够低成本的保留足够长的时间，数据如果全部落盘到磁盘成本是很高的，并且容量有限，即便利用水平扩容可以增加存储容量，但同时也增大了资源成本，不可能无限扩容，所以需要设置一个数据过期策略，也就会丢失时间比较久远的监控数据。\n对于这种不常用的冷数据，最理想的方式就是存到廉价的对象存储中，等需要查询的时候能够自动加载出来。Thanos 可以帮我们解决这些问题，它完全兼容 Prometheus API，提供统一查询聚合分布式部署的 Prometheus 数据的能力，同时也支持数据长期存储到各种对象存储(无限存储能力)以及降低采样率来加速大时间范围的数据查询。\n下一篇我们将会介绍 Thanos 的架构详解，敬请期待。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/trick/",
	"title": "排错技巧",
	"tags": [],
	"description": "",
	"content": "  分析 ExitCode 定位 Pod 异常退出原因   使用 Systemtap 定位疑难杂症   容器内抓包定位网络问题   "
},
{
	"uri": "https://k8s.imroc.io/bigdata-ai/flink-on-kubernetes/",
	"title": "Flink on Kubernetes",
	"tags": [],
	"description": "",
	"content": "介绍 Flink 在 Kubernetes 上的实践\n"
},
{
	"uri": "https://k8s.imroc.io/bigdata-ai/flink-on-kubernetes/intro/",
	"title": "Flink 介绍",
	"tags": [],
	"description": "",
	"content": "Flink 概述 Apache Flink 是一个面向数据流处理和批量数据处理的可分布式的开源计算框架，它基于同一个Flink流式执行模型（streaming execution model），能够同时支持流处理和批处理两种应用类型。\n由于流处理和批处理所提供的SLA(服务等级协议)是完全不相同，流处理一般需要支持低延迟、Exactly-once保证，而批处理需要支持高吞吐、高效处理。所以在实现的时候通常是分别给出两套实现方法，或者通过一个独立的开源框架来实现其中每一种处理方案； 比如：实现批处理的开源方案有MapReduce、Spark，实现流处理的开源方案有Storm，Spark的Streaming 其实本质上也是微批处理。\nFlink在实现流处理和批处理时，与传统的一些方案完全不同，它从另一个视角看待流处理和批处理，将二者统一起来：Flink是完全支持流处理，也就是说作为流处理看待时输入数据流是无界的；批处理被作为一种特殊的流处理，只是它的输入数据流被定义为有界的。\n流式框架的演进 Storm 是流式处理框架的先锋，实时处理能做到低延迟，但很难实现高吞吐，也不能保证精确一致性(exactly-once)，即保证执行一次并且只能执行一次。\n后基于批处理框架 Spark 推出 Spark Streaming，将批处理数据分割的足够小，也实现了流失处理，并且可以做到高吞吐，能实现 exactly-once，但难以做到低时延，因为分割的任务之间需要有间隔时间，无法做到真实时。\n最后 Flink 诞生了，同时做到了低延迟、高吞吐、exactly-once，并且还支持丰富的时间类型和窗口计算。\nFlink 基本架构 JobManager 与 TaskManager Flink 主要由两个部分组件构成：JobManager 和 TaskManager。如何理解这两个组件的作用？JobManager 负责资源申请和任务分发，TaskManager 负责任务的执行。跟 k8s 本身类比，JobManager 相当于 Master，TaskManager 相当于 Worker；跟 Spark 类比，JobManager 相当于 Driver，TaskManager 相当于 Executor。\nJobManager 负责整个 Flink 集群任务的调度以及资源的管理，从客户端获取提交的任务，然后根据集群中 TaskManager 上 TaskSlot 的使用情况，为提交的应用分配相应的 TaskSlot 资源并命令 TaskManager 启动从客户端中获取的应用。JobManager 是集群中的Master节点，整个集群有且仅有一个active的JobManager，负责整个集群的任务管理和资源管理。JobManager和TaskManager之间通过Actor System 进行通信，获取任务的执行情况并通过Actor System 将应用的任务的执行情况发送到客户端。同时在任务的执行过程中，Flink JobManager 会触发Checkpoints 操作，每个TaskManager 节点接受的到checkpoints触发命令后，完成checkpoints操作，所有的checkpoint协调过程都是在Flink JobManager中完成。当任务完成后，JobManager会将任务执行信息返回到客户端，并释放掉TaskManager中的资源以供下一次任务使用。\nTaskManager 相当于整个集群的slave 节点，负责具体的任务执行和对应任务在每个节点上的资源申请与管理。客户端通过将编写好的flink应用编译打包，提交到JobManager，然后JobManager会根据已经注册在jobmanger中TaskManager的资源情况，将任务分配到有资源的TaskManager节点，然后启动并运行任务。TaskManager从JobManager那接受需要部署的任务，然后使用slot资源启动task，建立数据接入网络连接，接受数据并处理。同时TaskManager之间的数据交互都是通过数据流的方式进行的。\n有界数据流和无界数据流 Flink用于处理有界和无界数据：\n 无界数据流：无界数据流有一个开始但是没有结束，它们不会在生成时终止并提供数据，必须连续处理无界流，也就是说必须在获取后立即处理event。对于无界数据流我们无法等待所有数据都到达，因为输入是无界的，并且在任何时间点都不会完成。处理无界数据通常要求以特定顺序（例如事件发生的顺序）获取event，以便能够推断结果完整性。 有界数据流：有界数据流有明确定义的开始和结束，可以在执行任何计算之前通过获取所有数据来处理有界流，处理有界流不需要有序获取，因为可以始终对有界数据集进行排序，有界流的处理也称为批处理。  编程模型 https://ci.apache.org/projects/flink/flink-docs-release-1.10/concepts/programming-model.html\n"
},
{
	"uri": "https://k8s.imroc.io/monitoring/kube-prometheus-quickstart/",
	"title": "使用 kube-promethues 快速上手集群监控",
	"tags": [],
	"description": "",
	"content": "kube-prometheus 介绍 kube-prometheus 包含了在 k8s 环境下各种主流的监控组件，将其安装到集群可以快速搭建我们自己的监控系统:\n prometheus-operator: 让 prometheus 更好的适配 k8s，可直接通过创建 k8s CRD 资源来创建 prometheus 与 alertmanager 实例及其监控告警规则 (默认安装时也会创建这些 CRD 资源，也就是会自动部署 prometheus 和 alertmanager，以及它们的配置) prometheus-adapter: 让 prometheus 采集的监控数据来适配 k8s 的 resource metrics API 和 custom metrics API，kubectl top 和 HPA 功能都依赖它们。 node-exporter: 以 DaemonSet 方式部署在每个节点，将节点的各项系统指标暴露成 prometheus 能识别的格式，以便让 prometheus 采集。 kube-state-metrics: 将 k8s 的资源对象转换成 prometheus 的 metrics 格式以便让 prometheus 采集，比如 Node/Pod 的各种状态。 grafana: 可视化展示监控数据的界面。  项目地址: https://github.com/coreos/kube-prometheus\n快速安装 如果只是想学习如何使用，可以参考 官方文档 一键部署到集群:\ngit clone https://github.com/coreos/kube-prometheus.git cd kube-prometheus # Create the namespace and CRDs, and then wait for them to be availble before creating the remaining resources kubectl create -f manifests/setup until kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo \u0026#34;\u0026#34;; done kubectl create -f manifests/ 进入 grafana 界面 你可以通过将 grafana 的 service 类型改为 NodePort 或 LoadBalancer，也可以用 Ingress 来暴露 grafana 的界面, 如果你本机能通过 kubectl 访问集群，那可以直接通过 kubectl port-forward 端口转发来暴露访问:\nkubectl port-forward service/grafana 3000:3000 -n monitoring 然后打开 http://localhost:3000 即可进入 grafana 的界面，初始用户名密码都是 admin，输入后会强制让改一下初始密码才允许进入。\n因为 kube-prometheus 为我们预配置了指标采集规则和 grafana 的 dashboard 展示配置，所以进入 grafana 界面后，点击左上角即可选择预配置好的监控面板:\n选择一些看下效果探索下吧:\n"
},
{
	"uri": "https://k8s.imroc.io/best-practice/deploy/resource-utilization/",
	"title": "如何合理利用资源",
	"tags": [],
	"description": "",
	"content": "引言 业务容器化后，如何将其部署在 K8S 上？如果仅仅是将它跑起来，很简单，但如果是上生产，我们有许多地方是需要结合业务场景和部署环境进行方案选型和配置调优的。比如，如何设置容器的 Request 与 Limit、如何让部署的服务做到高可用、如何配置健康检查、如何进行弹性伸缩、如何更好的进行资源调度、如何选择持久化存储、如何对外暴露服务等。\n对于这一系列高频问题，这里将会出一个 Kubernetes 服务部署最佳实践的系列的文章来为大家一一作答，本文将先围绕如何合理利用资源的主题来进行探讨。\nRequest 与 Limit 怎么设置才好 如何为容器配置 Request 与 Limit? 这是一个即常见又棘手的问题，这个根据服务类型，需求与场景的不同而不同，没有固定的答案，这里结合生产经验总结了一些最佳实践，可以作为参考。\n所有容器都应该设置 request request 的值并不是指给容器实际分配的资源大小，它仅仅是给调度器看的，调度器会 \u0026ldquo;观察\u0026rdquo; 每个节点可以用于分配的资源有多少，也知道每个节点已经被分配了多少资源。被分配资源的大小就是节点上所有 Pod 中定义的容器 request 之和，它可以计算出节点剩余多少资源可以被分配(可分配资源减去已分配的 request 之和)。如果发现节点剩余可分配资源大小比当前要被调度的 Pod 的 reuqest 还小，那么就不会考虑调度到这个节点，反之，才可能调度。所以，如果不配置 request，那么调度器就不能知道节点大概被分配了多少资源出去，调度器得不到准确信息，也就无法做出合理的调度决策，很容易造成调度不合理，有些节点可能很闲，而有些节点可能很忙，甚至 NotReady。\n所以，建议是给所有容器都设置 request，让调度器感知节点有多少资源被分配了，以便做出合理的调度决策，让集群节点的资源能够被合理的分配使用，避免陷入资源分配不均导致一些意外发生。\n老是忘记设置怎么办 有时候我们会忘记给部分容器设置 request 与 limit，其实我们可以使用 LimitRange 来设置 namespace 的默认 request 与 limit 值，同时它也可以用来限制最小和最大的 request 与 limit。 示例:\napiVersion: v1 kind: LimitRange metadata: name: mem-limit-range namespace: test spec: limits: - default: memory: 512Mi cpu: 500m defaultRequest: memory: 256Mi cpu: 100m type: Container 重要的线上应用改如何设置 节点资源不足时，会触发自动驱逐，将一些低优先级的 Pod 删除掉以释放资源让节点自愈。没有设置 request，limit 的 Pod 优先级最低，容易被驱逐；request 不等于 limit 的其次； request 等于 limit 的 Pod 优先级较高，不容易被驱逐。所以如果是重要的线上应用，不希望在节点故障时被驱逐导致线上业务受影响，就建议将 request 和 limit 设成一致。\n怎样设置才能提高资源利用率 如果给给你的应用设置较高的 request 值，而实际占用资源长期远小于它的 request 值，导致节点整体的资源利用率较低。当然这对时延非常敏感的业务除外，因为敏感的业务本身不期望节点利用率过高，影响网络包收发速度。所以对一些非核心，并且资源不长期占用的应用，可以适当减少 request 以提高资源利用率。\n如果你的服务支持水平扩容，单副本的 request 值一般可以设置到不大于 1 核，CPU 密集型应用除外。比如 coredns，设置到 0.1 核就可以，即 100m。\n尽量避免使用过大的 request 与 limit 如果你的服务使用单副本或者少量副本，给很大的 request 与 limit，让它分配到足够多的资源来支撑业务，那么某个副本故障对业务带来的影响可能就比较大，并且由于 request 较大，当集群内资源分配比较碎片化，如果这个 Pod 所在节点挂了，其它节点又没有一个有足够的剩余可分配资源能够满足这个 Pod 的 request 时，这个 Pod 就无法实现漂移，也就不能自愈，加重对业务的影响。\n相反，建议尽量减小 request 与 limit，通过增加副本的方式来对你的服务支撑能力进行水平扩容，让你的系统更加灵活可靠。\n避免测试 namespace 消耗过多资源影响生产业务 若生产集群有用于测试的 namespace，如果不加以限制，可能导致集群负载过高，从而影响生产业务。可以使用 ResourceQuota 来限制测试 namespace 的 request 与 limit 的总大小。 示例:\napiVersion: v1 kind: ResourceQuota metadata: name: quota-test namespace: test spec: hard: requests.cpu: \u0026#34;1\u0026#34; requests.memory: 1Gi limits.cpu: \u0026#34;2\u0026#34; limits.memory: 2Gi 如何让资源得到更合理的分配 设置 Request 能够解决让 Pod 调度到有足够资源的节点上，但无法做到更细致的控制。如何进一步让资源得到合理的使用？我们可以结合亲和性、污点与容忍等高级调度技巧，让 Pod 能够被合理调度到合适的节点上，让资源得到充分的利用。\n使用亲和性  对节点有特殊要求的服务可以用节点亲和性 (Node Affinity) 部署，以便调度到符合要求的节点，比如让 MySQL 调度到高 IO 的机型以提升数据读写效率。 可以将需要离得比较近的有关联的服务用 Pod 亲和性 (Pod Affinity) 部署，比如让 Web 服务跟它的 Redis 缓存服务都部署在同一可用区，实现低延时。 也可使用 Pod 反亲和 (Pod AntiAffinity) 将 Pod 进行打散调度，避免单点故障或者流量过于集中导致的一些问题。  使用污点与容忍 使用污点 (Taint) 与容忍 (Toleration) 可优化集群资源调度:\n 通过给节点打污点来给某些应用预留资源，避免其它 Pod 调度上来。 需要使用这些资源的 Pod 加上容忍，结合节点亲和性让它调度到预留节点，即可使用预留的资源。  弹性伸缩 如何支持流量突发型业务 通常业务都会有高峰和低谷，为了更合理的利用资源，我们为服务定义 HPA，实现根据 Pod 的资源实际使用情况来对服务进行自动扩缩容，在业务高峰时自动扩容 Pod 数量来支撑服务，在业务低谷时，自动缩容 Pod 释放资源，以供其它服务使用（比如在夜间，线上业务低峰，自动缩容释放资源以供大数据之类的离线任务运行) 。\n使用 HPA 前提是让 K8S 得知道你服务的实际资源占用情况(指标数据)，需要安装 resource metrics (metrics.k8s.io) 或 custom metrics (custom.metrics.k8s.io) 的实现，好让 hpa controller 查询这些 API 来获取到服务的资源占用情况。早期 HPA 用 resource metrics 获取指标数据，后来推出 custom metrics，可以实现更灵活的指标来控制扩缩容。官方有个叫 metrics-server 的实现，通常社区使用的更多的是基于 prometheus 的 实现 prometheus-adapter，而云厂商托管的 K8S 集群通常集成了自己的实现，比如 TKE，实现了 CPU、内存、硬盘、网络等维度的指标，可以在网页控制台可视化创建 HPA，但最终都会转成 K8S 的 yaml，示例:\napiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: nginx spec: scaleTargetRef: apiVersion: apps/v1beta2 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: Pods pods: metric: name: k8s_pod_rate_cpu_core_used_request target: averageValue: \u0026#34;100\u0026#34; type: AverageValue 如何节约成本 HPA 能实现 Pod 水平扩缩容，但如果节点资源不够用了，Pod 扩容出来还是会 Pending。如果我们提前准备好大量节点，做好资源冗余，提前准备好大量节点，通常不会有 Pod Pending 的问题，但也意味着需要付出更高的成本。通常云厂商托管的 K8S 集群都会实现 cluster-autoscaler，即根据资源使用情况，动态增删节点，让计算资源能够被最大化的弹性使用，按量付费，以节约成本。在 TKE 上的实现叫做伸缩组，以及一个包含伸缩功能组但更高级的特性：节点池(正在灰度)\n无法水平扩容的服务怎么办 对于无法适配水平伸缩的单体应用，或者不确定最佳 request 与 limit 超卖比的应用，可以尝用 VPA 来进行垂直伸缩，即自动更新 request 与 limit，然后重启 pod。不过这个特性容易导致你的服务出现短暂的不可用，不建议在生产环境中大规模使用。\n参考资料  Understanding Kubernetes limits and requests by example: https://sysdig.com/blog/kubernetes-limits-requests/ Understanding resource limits in kubernetes: cpu time: https://medium.com/@betz.mark/understanding-resource-limits-in-kubernetes-cpu-time-9eff74d3161b Understanding resource limits in kubernetes: memory: https://medium.com/@betz.mark/understanding-resource-limits-in-kubernetes-memory-6b41e9a955f9 Kubernetes best practices: Resource requests and limits: https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-resource-requests-and-limits Kubernetes 资源分配之 Request 和 Limit 解析: https://cloud.tencent.com/developer/article/1004976 Assign Pods to Nodes using Node Affinity: https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/ Taints and Tolerations: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/ metrics-server: https://github.com/kubernetes-sigs/metrics-server prometheus-adapter: https://github.com/DirectXMan12/k8s-prometheus-adapter cluster-autoscaler: https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler VPA: https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler  "
},
{
	"uri": "https://k8s.imroc.io/security/cert/install-cert-manger/",
	"title": "安装 cert-manager",
	"tags": [],
	"description": "",
	"content": "参考官方文档: https://docs.cert-manager.io/en/latest/getting-started/install/kubernetes.html\n介绍几种安装方式，不管是用哪种我们都先规划一下使用哪个命名空间，推荐使用 cert-manger 命名空间，如果使用其它的命名空间需要做些更改，会稍微有点麻烦，先创建好命名空间:\nkubectl create namespace cert-manager 使用原生 yaml 资源安装 直接执行 kubectl apply 来安装:\nkubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.13.1/cert-manager.yaml  使用 kubectl v1.15.4 及其以下的版本需要加上 --validate=false，否则会报错。\n 校验是否安装成功 检查 cert-manager 相关的 pod 是否启动成功:\n$ kubectl get pods --namespace cert-manager NAME READY STATUS RESTARTS AGE cert-manager-5c6866597-zw7kh 1/1 Running 0 2m cert-manager-cainjector-577f6d9fd7-tr77l 1/1 Running 0 2m cert-manager-webhook-787858fcdb-nlzsq 1/1 Running 0 2m "
},
{
	"uri": "https://k8s.imroc.io/ingress/understand/",
	"title": "彻底理解 Ingress",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/deploy/selection/",
	"title": "方案选型",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/best-practice/deploy/",
	"title": "服务部署最佳实践",
	"tags": [],
	"description": "",
	"content": "目录  如何合理利用资源     如何提高服务可用性     "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/manual/",
	"title": "网络排错手册",
	"tags": [],
	"description": "",
	"content": "连接队列溢出 查看是否全连接或半连接队列溢出导致丢包，造成部分连接异常 (timeout):\n$ netstat -s | grep -E \u0026#39;overflow|drop\u0026#39; 3327 times the listen queue of a socket overflowed 32631 SYNs to LISTEN sockets dropped 进入容器 netns 后，查看各状态的连接数统计:\nnetstat -n | awk \u0026#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}\u0026#39; 故障案例:\n 健康检查失败 网络时同时不通  解决方案:\n 调大 sommaxconn 调大 backlog 若是 nginx，还受 nginx 本身的 backlog 配置，也调大下  conntrack 表爆满 看内核日志:\n# demsg $ journalctl -k | grep \u0026#34;nf_conntrack: table full\u0026#34; nf_conntrack: nf_conntrack: table full, dropping packet 若有以上报错，证明 conntrack 表满了，需要调大 conntrack 表:\nsysctl -w net.netfilter.nf_conntrack_max=1000000 arp 表爆满 看内核日志:\n# demsg $ journalctl -k | grep \u0026#34;neighbor table overflow\u0026#34; arp_cache: neighbor table overflow! 若有以上报错，证明 arp 表满了，查看当前 arp 记录数:\n$ arp -an | wc -l 1335 查看 arp gc 阀值:\n$ sysctl -a | grep gc_thresh net.ipv4.neigh.default.gc_thresh1 = 128 net.ipv4.neigh.default.gc_thresh2 = 512 net.ipv4.neigh.default.gc_thresh3 = 1024 调大 arp 表:\nsysctl -w net.ipv4.neigh.default.gc_thresh1=80000 sysctl -w net.ipv4.neigh.default.gc_thresh2=90000 sysctl -w net.ipv4.neigh.default.gc_thresh3=100000 端口监听挂掉 如果容器内的端口已经没有进程监听了，内核就会返回 Reset 包，客户端就会报错连接被拒绝，可以进容器 netns 检查下端口是否存活:\nnetstat -tunlp tcp_tw_recycle 导致丢包 在低版本内核中(比如 3.10)，支持使用 tcp_tw_recycle 内核参数来开启 TIME_WAIT 的快速回收，但如果 client 也开启了 timestamp (一般默认开启)，同时也就会导致在 NAT 环境丢包，甚至没有 NAT 时，稍微高并发一点，也会导致 PAWS 校验失败，导致丢包:\n# 看 SYN 丢包是否全都是 PAWS 校验失败 $ cat /proc/net/netstat | grep TcpE| awk \u0026#39;{print $15, $22}\u0026#39; PAWSPassive ListenDrops 96305 96305 参考资料:\n https://github.com/torvalds/linux/blob/v3.10/net/ipv4/tcp_ipv4.c#L1465 https://www.freesoft.org/CIE/RFC/1323/13.htm https://zhuanlan.zhihu.com/p/35684094 https://my.oschina.net/u/4270811/blog/3473655/print  "
},
{
	"uri": "https://k8s.imroc.io/deploy/",
	"title": "部署指南",
	"tags": [],
	"description": "",
	"content": "  方案选型     使用 kubespray 部署     手工部署    部署前的准备工作     部署 ETCD     部署 Master     部署 Worker 节点     部署关键组件      附加组件    以 Daemonset 方式部署 kube-proxy     部署 CoreDNS      附录    安装 kubectl      "
},
{
	"uri": "https://k8s.imroc.io/ingress/",
	"title": "Ingress 指南",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/metrics/",
	"title": "Metrics 指南",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/configuration/",
	"title": "配置管理",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/monitoring/build-cloud-native-large-scale-distributed-monitoring-system/thanos-arch/",
	"title": "Thanos 架构详解",
	"tags": [],
	"description": "",
	"content": "概述 之前在 大规模场景下 Prometheus 的优化手段 中，我们想尽 \u0026ldquo;千方百计\u0026rdquo; 才好不容易把 Prometheus 优化到适配大规模场景，部署和后期维护麻烦且复杂不说，还有很多不完美的地方，并且还无法满足一些更高级的诉求，比如查看时间久远的监控数据，对于一些时间久远不常用的 \u0026ldquo;冷数据\u0026rdquo;，最理想的方式就是存到廉价的对象存储中，等需要查询的时候能够自动加载出来。\nThanos (没错，就是灭霸) 可以帮我们简化分布式 Prometheus 的部署与管理，并提供了一些的高级特性：全局视图，长期存储，高可用。下面我们来详细讲解一下。\nThanos 架构 这是官方给出的架构图：\n这张图中包含了 Thanos 的几个核心组件，但并不包括所有组件，为了便于理解，我们先不细讲，简单介绍下图中这几个组件的作用：\n Thanos Query: 实现了 Prometheus API，将来自下游组件提供的数据进行聚合最终返回给查询数据的 client (如 grafana)，类似数据库中间件。 Thanos Sidecar: 连接 Prometheus，将其数据提供给 Thanos Query 查询，并且/或者将其上传到对象存储，以供长期存储。 Thanos Store Gateway: 将对象存储的数据暴露给 Thanos Query 去查询。 Thanos Ruler: 对监控数据进行评估和告警，还可以计算出新的监控数据，将这些新数据提供给 Thanos Query 查询并且/或者上传到对象存储，以供长期存储。 Thanos Compact: 将对象存储中的数据进行压缩和降低采样率，加速大时间区间监控数据查询的速度。  架构设计剖析 如何理解 Thanos 的架构设计的？我们可以自己先 YY 一下，要是自己来设计一个分布式 Prometheus 管理应用，会怎么做？\nQuery 与 Sidecar 首先，监控数据的查询肯定不能直接查 Prometheus 了，因为会存在许多个 Prometheus 实例，每个 Prometheus 实例只能感知它自己所采集的数据。我们可以比较容易联想到数据库中间件，每个数据库都只存了一部分数据，中间件能感知到所有数据库，数据查询都经过数据库中间件来查，这个中间件收到查询请求再去查下游各个数据库中的数据，最后将这些数据聚合汇总返回给查询的客户端，这样就实现了将分布式存储的数据集中查询。\n实际上，Thanos 也是使用了类似的设计思想，Thanos Query 就是这个 \u0026ldquo;中间件\u0026rdquo; 的关键入口。它实现了 Prometheus 的 HTTP API，能够 \u0026ldquo;看懂\u0026rdquo; PromQL。这样，查询 Prometheus 监控数据的 client 就不直接查询 Prometheus 本身了，而是去查询 Thanos Query，Thanos Query 再去下游多个存储了数据的地方查数据，最后将这些数据聚合去重后返回给 client，也就实现了分布式 Prometheus 的数据查询。\n那么 Thanos Query 又如何去查下游分散的数据呢？Thanos 为此抽象了一套叫 Store API 的内部 gRPC 接口，其它一些组件通过这个接口来暴露数据给 Thanos Query，它自身也就可以做到完全无状态部署，实现高可用与动态扩展。\n这些分散的数据可能来自哪些地方呢？首先，Prometheus 会将采集的数据存到本机磁盘上，如果我们直接用这些分散在各个磁盘上的数据，可以给每个 Prometheus 附带部署一个 Sidecar，这个 Sidecar 实现 Thanos Store API，当 Thanos Query 对其发起查询时，Sidecar 就读取跟它绑定部署的 Prometheus 实例上的监控数据返回给 Thanos Query。\n由于 Thanos Query 可以对数据进行聚合与去重，所以可以很轻松实现高可用：相同的 Prometheus 部署多个副本(都附带 Sidecar)，然后 Thanos Query 去所有 Sidecar 查数据，即便有一个 Prometheus 实例挂掉过一段时间，数据聚合与去重后仍然能得到完整数据。\n这种高可用做法还弥补了我们上篇文章中用负载均衡去实现 Prometheus 高可用方法的缺陷：如果其中一个 Prometheus 实例挂了一段时间然后又恢复了，它的数据就不完整，当负载均衡转发到它上面去查数据时，返回的结果就可能会有部分缺失。\n不过因为磁盘空间有限，所以 Prometheus 存储监控数据的能力也是有限的，通常会给 Prometheus 设置一个数据过期时间 (默认15天) 或者最大数据量大小，不断清理旧数据以保证磁盘不被撑爆。因此，我们无法看到时间比较久远的监控数据，有时候这也给我们的问题排查和数据统计造成一些困难。\n对于需要长期存储的数据，并且使用频率不那么高，最理想的方式是存进对象存储，各大云厂商都有对象存储服务，特点是不限制容量，价格非常便宜。\nThanos 有几个组件都支持将数据上传到各种对象存储以供长期保存 (Prometheus TSDB 数据格式)，比如我们刚刚说的 Sidecar:\nStore Gateway 那么这些被上传到了对象存储里的监控数据该如何查询呢？理论上 Thanos Query 也可以直接去对象存储查，但会让 Thanos Query 的逻辑变的很重。我们刚才也看到了，Thanos 抽象出了 Store API，只要实现了该接口的组件都可以作为 Thanos Query 查询的数据源，Thanos Store Gateway 这个组件也实现了 Store API，向 Thanos Query 暴露对象存储的数据。Thanos Store Gateway 内部还做了一些加速数据获取的优化逻辑，一是缓存了 TSDB 索引，二是优化了对象存储的请求 (用尽可能少的请求量拿到所有需要的数据)。\n这样就实现了监控数据的长期储存，由于对象存储容量无限，所以理论上我们可以存任意时长的数据，监控历史数据也就变得可追溯查询，便于问题排查与统计分析。\nRuler 有一个问题，Prometheus 不仅仅只支持将采集的数据进行存储和查询的功能，还可以配置一些 rules:\n 根据配置不断计算出新指标数据并存储，后续查询时直接使用计算好的新指标，这样可以减轻查询时的计算压力，加快查询速度。 不断计算和评估是否达到告警阀值，当达到阀值时就通知 AlertManager 来触发告警。  由于我们将 Prometheus 进行分布式部署，每个 Prometheus 实例本地并没有完整数据，有些有关联的数据可能存在多个 Prometheus 实例中，单机 Prometheus 看不到数据的全局视图，这种情况我们就不能依赖 Prometheus 来做这些工作，Thanos Ruler 应运而生，它通过查询 Thanos Query 获取全局数据，然后根据 rules 配置计算新指标并存储，同时也通过 Store API 将数据暴露给 Thanos Query，同样还可以将数据上传到对象存储以供长期保存 (这里上传到对象存储中的数据一样也是通过 Thanos Store Gateway 暴露给 Thanos Query)。\n看起来 Thanos Query 跟 Thanos Ruler 之间会相互查询，不过这个不冲突，Thanos Ruler 为 Thanos Query 提供计算出的新指标数据，而 Thanos Query 为 Thanos Ruler 提供计算新指标所需要的全局原始指标数据。\n至此，Thanos 的核心能力基本实现了，完全兼容 Prometheus 的情况下提供数据查询的全局视图，高可用以及数据的长期保存。\n看下还可以怎么进一步做下优化呢？\nCompact 由于我们有数据长期存储的能力，也就可以实现查询较大时间范围的监控数据，当时间范围很大时，查询的数据量也会很大，这会导致查询速度非常慢。通常在查看较大时间范围的监控数据时，我们并不需要那么详细的数据，只需要看到大致就行。Thanos Compact 这个组件应运而生，它读取对象存储的数据，对其进行压缩以及降采样再上传到对象存储，这样在查询大时间范围数据时就可以只读取压缩和降采样后的数据，极大地减少了查询的数据量，从而加速查询。\n再看架构图 上面我们剖析了官方架构图中各个组件的设计，现在再来回味一下这张图:\n理解是否更加深刻了？\n另外还有 Thanos Bucket 和 Thanos Checker 两个辅助性的工具组件没画出来，它们不是核心组件，这里也就不再赘述。\nSidecar 模式与 Receiver 模式 前面我们理解了官方的架构图，但其中还缺失一个核心组件 Thanos Receiver，因为它是一个还未完全发布的组件。这是它的设计文档: https://thanos.io/proposals/201812_thanos-remote-receive.md/\n这个组件可以完全消除 Sidecar，所以 Thanos 实际有两种架构图，只是因为没有完全发布，官方的架构图只给的 Sidecar 模式。\nReceiver 是做什么的呢？为什么需要 Receiver？它跟 Sidecar 有什么区别？\n它们都可以将数据上传到对象存储以供长期保存，区别在于最新数据的存储。\n由于数据上传不可能实时，Sidecar 模式将最新的监控数据存到 Prometheus 本机，Query 通过调所有 Sidecar 的 Store API 来获取最新数据，这就成一个问题：如果 Sidecar 数量非常多或者 Sidecar 跟 Query 离的比较远，每次查询 Query 都调所有 Sidecar 会消耗很多资源，并且速度很慢，而我们查看监控大多数情况都是看的最新数据。\n为了解决这个问题，Thanos Receiver 组件被提出，它适配了 Prometheus 的 remote write API，也就是所有 Prometheus 实例可以实时将数据 push 到 Thanos Receiver，最新数据也得以集中起来，然后 Thanos Query 也不用去所有 Sidecar 查最新数据了，直接查 Thanos Receiver 即可。另外，Thanos Receiver 也将数据上传到对象存储以供长期保存，当然，对象存储中的数据同样由 Thanos Store Gateway 暴露给 Thanos Query。\n有同学可能会问：如果规模很大，Receiver 压力会不会很大，成为性能瓶颈？当然设计这个组件时肯定会考虑这个问题，Receiver 实现了一致性哈希，支持集群部署，所以即使规模很大也不会成为性能瓶颈。\n总结 本文详细讲解了 Thanos 的架构设计，各个组件的作用以及为什么要这么设计。如果仔细看完，我相信你已经 get 到了 Thanos 的精髓，不过我们还没开始讲如何部署与实践，实际上在腾讯云容器服务的多个产品的内部监控已经在使用 Thanos 了，比如 TKE (公有云 k8s)、TKEStack (私有云 k8s)、EKS (Serverless k8s)。 下一篇我们将介绍 Thanos 的部署与最佳实践，敬请期待。\n"
},
{
	"uri": "https://k8s.imroc.io/log/loki-stack/",
	"title": "利用 Loki/Promtail/Grafana 收集分析日志",
	"tags": [],
	"description": "",
	"content": "Loki/Promtail/Grafana vs EFK Loki Stack 包含三个组件：\n Loki: 相当于 EFK 中的 ElasticSearch，用于存储和查询日志 Promtail: 相当于 EFK 中的 Filebeat/Fluentd，用于采集和发送日志 Grafana: 相当于 EFK 中的 Kibana，用于 UI 展示  使用 Helm 部署 Loki Stack 到 Kubernetes  参考官方文档: https://github.com/grafana/loki/blob/master/docs/installation/helm.md\n loki/loki-stack 这个 chart 包含 loki stack 涉及的各个组件:\n loki: 以 Statefulset 方式部署，可横向扩容 promtail: 以 Daemonset 方式部署，采集每个节点上容器日志并发送给 loki grafana: 默认不开启，如果集群中已经有 grafana 就可以不用在部署 grafana，如果没有，部署时可以选择也同时部署 grafana  首先添加 repo:\nhelm repo add loki https://grafana.github.io/loki/charts helm repo update 执行安装:\n Helm 2 Helm 3  helm upgrade --install loki loki/loki-stack # 安装到指定命名空间 # helm upgrade --install loki loki/loki-stack -n monitoring # 持久化 loki 的数据，避免 loki 重启后数据丢失 # helm upgrade --install loki loki/loki-stack --set=\u0026#34;loki.persistence.enabled=ture,loki.persistence.size=100G\u0026#34; # 部署 grafana # helm upgrade --install loki loki/loki-stack --set=\u0026#34;grafana=true\u0026#34;   helm install loki loki/loki-stack # 安装到指定命名空间 # helm install loki loki/loki-stack -n monitoring # 持久化 loki 的数据，避免 loki 重启后数据丢失 # helm install loki loki/loki-stack --set=\u0026#34;loki.persistence.enabled=ture,loki.persistence.size=100G\u0026#34; # 部署 grafana # helm install loki loki/loki-stack --set=\u0026#34;grafana.enabled=true\u0026#34;    $(function(){$(\"#tab_with_code\").tabs();}); 进入 grafana 界面，添加 loki 作为数据源：Configuration-Data Sources-Add data source-Loki，然后填入 loki 在集群中的地址，比如: http://loki.monitoring.svc.cluster.local:3100\n数据源添加好了，我们就可以开始查询分析日志了，点击 Explore，下拉选择 loki 作为数据源，切到 Logs 模式(不用 Metrics 模式)，在 Log labels 按钮那里就能通过 label 筛选日志了。\n更多用法请参考 官方文档\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/",
	"title": "排错指南",
	"tags": [],
	"description": "",
	"content": "kuernetes 问题定位手册(脑图)：https://www.processon.com/view/link/5e4662ade4b0d86ec4018e50\n目录  排错技巧    分析 ExitCode 定位 Pod 异常退出原因     使用 Systemtap 定位疑难杂症     容器内抓包定位网络问题      处理实践    arp_cache 溢出     inotify watch 耗尽     PID 耗尽     内存碎片化     磁盘爆满     高负载      节点排错    arp_cache: neighbor table overflow! (arp缓存溢出)     Cannot allocate memory     no space left on device     Node NotReady     soft lockup (内核软死锁)      Pod 排错    Pod Terminating 慢     Pod 一直处于 ContainerCreating 或 Waiting 状态     Pod 一直处于 Error 状态     Pod 一直处于 ImageInspectError 状态     Pod 一直处于 ImagePullBackOff 状态     Pod 一直处于 Pending 状态     Pod 一直处于 Terminating 状态     Pod 一直处于 Unknown 状态     Pod 健康检查失败     Pod 处于 CrashLoopBackOff 状态     容器进程主动退出      网络排错    网络排错手册     DNS 解析异常     LB 健康检查失败     Service 不通     Service 无法解析     网络性能差      其它排错    APIServer 响应慢     Daemonset 没有被调度     Job 无法被删除     kubectl 执行 exec 或 logs 失败     Namespace 卡在 Terminating     Node 全部消失      "
},
{
	"uri": "https://k8s.imroc.io/bigdata-ai/flink-on-kubernetes/flink-on-kubernetes/",
	"title": "Flink on Kubernetes 方案",
	"tags": [],
	"description": "",
	"content": "将 Flink 部署到 Kubernetes 有 Session Cluster、Job Cluster 和 Native Kubernetes 三种集群部署方案。\nSession Cluster 相当于将静态部署的 Standalone Cluster 容器化，TaskManager 与 JobManager 都以 Deployment 方式部署，可动态提交 Job，Job 处理能力主要取决于 TaskManager 的配置 (slot/cpu/memory) 与副本数 (replicas)，调整副本数可以动态扩容。这种方式也是比较常见和成熟的方式。\nJob Cluster 相当于给每一个独立的 Job 部署一整套 Flink 集群，这套集群就只能运行一个 Job，配备专门制作的 Job 镜像，不能动态提交其它 Job。这种模式可以让每种 Job 拥有专用的资源，独立扩容。\nNative Kubernetes 这种方式是与 Kubernetes 原生集成，相比前面两种，这种模式能做到动态向 Kubernetes 申请资源，不需要提前指定 TaskManager 数量，就像 flink 与 yarn 和 mesos 集成一样。此模式能够提高资源利用率，但还处于试验阶段，不够成熟，不建议部署到生产环境。\n总结 TODO\n"
},
{
	"uri": "https://k8s.imroc.io/ingress/choose/",
	"title": "Ingress 方案选型",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/security/cert/autogenerate-certificate-with-cert-manager/",
	"title": "使用 cert-manager 自动生成证书",
	"tags": [],
	"description": "",
	"content": "确保 cert-manager 已安装，参考 安装 cert-manager\n利用 Let’s Encrypt 生成免费证书 免费证书颁发原理 Let’s Encrypt 利用 ACME 协议来校验域名是否真的属于你，校验成功后就可以自动颁发免费证书，证书有效期只有 90 天，在到期前需要再校验一次来实现续期，幸运的是 cert-manager 可以自动续期，这样就可以使用永久免费的证书了。如何校验你对这个域名属于你呢？主流的两种校验方式是 HTTP-01 和 DNS-01，下面简单介绍下校验原理:\nHTTP-01 校验原理 HTTP-01 的校验原理是给你域名指向的 HTTP 服务增加一个临时 location ，Let’s Encrypt 会发送 http 请求到 http://\u0026lt;YOUR_DOMAIN\u0026gt;/.well-known/acme-challenge/\u0026lt;TOKEN\u0026gt;，YOUR_DOMAIN 就是被校验的域名，TOKEN 是 ACME 协议的客户端负责放置的文件，在这里 ACME 客户端就是 cert-manager，它通过修改 Ingress 规则来增加这个临时校验路径并指向提供 TOKEN 的服务。Let’s Encrypt 会对比 TOKEN 是否符合预期，校验成功后就会颁发证书。此方法仅适用于给使用 Ingress 暴露流量的服务颁发证书，并且不支持泛域名证书。\nDNS-01 校验原理 DNS-01 的校验原理是利用 DNS 提供商的 API Key 拿到你的 DNS 控制权限， 在 Let’s Encrypt 为 ACME 客户端提供令牌后，ACME 客户端 (cert-manager) 将创建从该令牌和您的帐户密钥派生的 TXT 记录，并将该记录放在 _acme-challenge.\u0026lt;YOUR_DOMAIN\u0026gt;。 然后 Let’s Encrypt 将向 DNS 系统查询该记录，如果找到匹配项，就可以颁发证书。此方法不需要你的服务使用 Ingress，并且支持泛域名证书。\n创建 Issuer/ClusterIssuer 我们需要先创建一个用于签发证书的 Issuer 或 ClusterIssuer，它们唯一区别就是 Issuer 只能用来签发自己所在 namespace 下的证书，ClusterIssuer 可以签发任意 namespace 下的证书，除了名称不同之外，两者所有字段完全一致，下面给出一些示例，简单起见，我们仅以 ClusterIssuer 为例。\n创建使用 DNS-01 校验的 ClusterIssuer 假设域名是用 cloudflare 管理的，先登录 cloudflare 拿到 API Key，然后创建一个 Secret:\nkubectl -n cert-manager create secret generic cloudflare-apikey --from-literal=apikey=213807bdxxxxxxxxxxxxxx58eac90492e6287  由于 ClusterIssuer 是 NonNamespaced 类型的资源，不在任何命名空间，它需要引用 Secret，而 Secret 必须存在某个命名空间下，所以就规定 ClusterIssuer 引用的 Secret 要与 cert-manager 在同一个命名空间下。\n 创建 DNS-01 方式校验的 ClusterIssuer:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-dns01 spec: acme: # The ACME server URL server: https://acme-v02.api.letsencrypt.org/directory # Email address used for ACME registration email: roc@imroc.io # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-dns01 solvers: - selector: {} # An empty \u0026#39;selector\u0026#39; means that this solver matches all domains dns01: # ACME DNS-01 solver configurations cloudflare: email: roc@imroc.io # A secretKeyRef to a cloudflare api key apiKeySecretRef: name: cloudflare-apikey key: apikey EOF  metadata.name: 是我们创建的签发机构的名称，后面我们创建证书的时候会引用它 acme.email: 是你自己的邮箱，证书快过期的时候会有邮件提醒，不过 cert-manager 会利用 acme 协议自动给我们重新颁发证书来续期 acme.server: 是 acme 协议的服务端，我们这里用 Let’s Encrypt，这个地址就写死成这样就行 acme.privateKeySecretRef 指示此签发机构的私钥将要存储到哪个 Secret 中，在 cert-manager 所在命名空间 solvers.dns01: 配置 DNS-01 校验方式所需的参数，最重要的是 API Key (引用提前创建好的 Secret)，不同 DNS 提供商配置不一样，具体参考官方API文档 更多字段参考 API 文档: https://docs.cert-manager.io/en/latest/reference/api-docs/index.html#clusterissuer-v1alpha2  创建使用 HTTP-01 校验的 ClusterIssuer 使用 HTTP-01 方式校验，ACME 服务端 (Let\u0026rsquo;s Encrypt) 会向客户端 (cert-manager) 提供令牌，客户端会在 web server 上特定路径上放置一个文件，该文件包含令牌以及帐户密钥的指纹。ACME 服务端会请求该路径并校验文件内容，校验成功后就会签发免费证书，更多细节参考: https://letsencrypt.org/zh-cn/docs/challenge-types/\n有个问题，ACME 服务端通过什么地址去访问 ACME 客户端的 web server 校验域名？答案是通过将被签发的证书中的域名来访问。这个机制带来的问题是:\n 不能签发泛域名证书，因为如果是泛域名，没有具体域名，ACME 服务端就不能知道该用什么地址访问 web server 去校验文件。 域名需要提前在 DNS 提供商配置好，这样 ACME 服务端通过域名请求时解析到正确 IP 才能访问成功，也就是需要提前知道你的 web server 的 IP 是什么。  cert-manager 作为 ACME 客户端，它将这个要被 ACME 服务端校验的文件通过 Ingress 来暴露，我们需要提前知道 Ingress 对外的 IP 地址是多少，这样才好配置域名。\n一些云厂商自带的 ingress controller 会给每个 Ingress 都创建一个外部地址 (通常对应一个负载均衡器)，这个时候我们需要提前创建好一个 Ingress，拿到外部 IP 并配置域名到此 IP，ACME 客户端 (cert-manager) 修改此 Ingress 的 rules，临时增加一个路径指向 cert-manager 提供的文件，ACME 服务端请求这个域名+指定路径，根据 Ingress 规则转发会返回 cert-manger 提供的这个文件，最终 ACME 服务端 (Let\u0026rsquo;s Encrypt) 校验该文件，通过后签发免费证书。\n指定 Ingress 的创建 ClusterIssuer 的示例:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-http01 spec: acme: # The ACME server URL server: https://acme-v02.api.letsencrypt.org/directory # Email address used for ACME registration email: roc@imroc.io # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-http01 solvers: - selector: {} # An empty \u0026#39;selector\u0026#39; means that this solver matches all domains http01: # ACME HTTP-01 solver configurations ingress: name: challenge EOF  solvers.http01: 配置 HTTP-01 校验方式所需的参数，ingress.name 指定提前创建好的 ingress 名称  有些自己安装的 ingress controller，所有具有相同 ingress class 的 ingress 都共用一个流量入口，通常是用 LoadBalancer 类型的 Service 暴露 ingress controller，这些具有相同 ingress class 的 ingress 的外部 IP 都是这个 Service 的外部 IP。这种情况我们创建 ClusterIssuer 时可以指定 ingress class，校验证书时，cert-manager 会直接创建新的 Ingress 资源并指定 kubernetes.io/ingress.class 这个 annotation。\n指定 ingress class 的创建 ClusterIssuer 的示例:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-http01 spec: acme: # The ACME server URL server: https://acme-v02.api.letsencrypt.org/directory # Email address used for ACME registration email: roc@imroc.io # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-http01 solvers: - selector: {} # An empty \u0026#39;selector\u0026#39; means that this solver matches all domains http01: # ACME HTTP-01 solver configurations ingress: class: nginx EOF  solvers.http01: 配置 HTTP-01 校验方式所需的参数，ingress.class 指定 ingress class 名称  创建证书 (Certificate) 有了 Issuer/ClusterIssuer，接下来我们就可以生成免费证书了，cert-manager 给我们提供了 Certificate 这个用于生成证书的自定义资源对象，它必须局限在某一个 namespace 下，证书最终会在这个 namespace 下以 Secret 的资源对象存储，假如我想在 dashboard 这个 namespace 下生成免费证书（这个 namespace 已存在)，创建一个 Certificate 资源来为我们自动生成证书，示例:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: cert-manager.io/v1alpha2 kind: Certificate metadata: name: dashboard-imroc-io namespace: kubernetes-dashboard spec: secretName: dashboard-imroc-io-tls issuerRef: name: letsencrypt-dns01 kind: ClusterIssuer dnsNames: - dashboard.imroc.io EOF  secretName: 指示证书最终存到哪个 Secret 中 issuerRef.kind: ClusterIssuer 或 Issuer，ClusterIssuer 可以被任意 namespace 的 Certificate 引用，Issuer 只能被当前 namespace 的 Certificate 引用。 issuerRef.name: 引用我们创建的 Issuer/ClusterIssuer 的名称 commonName: 对应证书的 common name 字段 dnsNames: 对应证书的 Subject Alternative Names (SANs) 字段  检查结果 创建完成等待一段时间，校验成功颁发证书后会将证书信息写入 Certificate 所在命名空间的 secretName 指定的 Secret 中，其它应用需要证书就可以直接挂载该 Secret 了。\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Generated 15s cert-manager Generated new private key Normal GenerateSelfSigned 15s cert-manager Generated temporary self signed certificate Normal OrderCreated 15s cert-manager Created Order resource \u0026#34;dashboard-imroc-io-780134401\u0026#34; Normal OrderComplete 9s cert-manager Order \u0026#34;dashboard-imroc-io-780134401\u0026#34; completed successfully Normal CertIssued 9s cert-manager Certificate issued successfully 看下我们的证书是否成功生成:\nkubectl -n dashboard get secret kubernetes-dashboard-certs -o yaml apiVersion: v1 data: ca.crt: null tls.crt: LS0***0tLQo= tls.key: LS0***0tCg== kind: Secret metadata: annotations: certmanager.k8s.io/alt-names: dashboard.imroc.io certmanager.k8s.io/certificate-name: dashboard-imroc-io certmanager.k8s.io/common-name: dashboard.imroc.io certmanager.k8s.io/ip-sans: \u0026#34;\u0026#34; certmanager.k8s.io/issuer-kind: ClusterIssuer certmanager.k8s.io/issuer-name: letsencrypt-prod creationTimestamp: 2019-09-19T13:53:55Z labels: certmanager.k8s.io/certificate-name: dashboard-imroc-io name: kubernetes-dashboard-certs namespace: dashboard resourceVersion: \u0026#34;5689447213\u0026#34; selfLink: /api/v1/namespaces/dashboard/secrets/kubernetes-dashboard-certs uid: ebfc4aec-dae4-11e9-89f7-be8690a7fdcf type: kubernetes.io/tls  tls.crt 就是颁发的证书 tls.key 是证书密钥  将 secret 挂载到需要证书的应用，通常应用也要配置下证书路径。\n"
},
{
	"uri": "https://k8s.imroc.io/deploy/kubespray/",
	"title": "使用 kubespray 部署",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/",
	"title": "处理实践",
	"tags": [],
	"description": "",
	"content": "  arp_cache 溢出   inotify watch 耗尽   PID 耗尽   内存碎片化   磁盘爆满   高负载   "
},
{
	"uri": "https://k8s.imroc.io/best-practice/deploy/highly-available/",
	"title": "如何提高服务可用性",
	"tags": [],
	"description": "",
	"content": "引言 上一篇 文章我们围绕如何合理利用资源的主题做了一些最佳实践的分享，这一次我们就如何提高服务可用性的主题来展开探讨。\n怎样提高我们部署服务的可用性呢？K8S 设计本身就考虑到了各种故障的可能性，并提供了一些自愈机制以提高系统的容错性，但有些情况还是可能导致较长时间不可用，拉低服务可用性的指标。本文将结合生产实践经验，为大家提供一些最佳实践来最大化的提高服务可用性。\n如何避免单点故障？ K8S 的设计就是假设节点是不可靠的。节点越多，发生软硬件故障导致节点不可用的几率就越高，所以我们通常需要给服务部署多个副本，根据实际情况调整 replicas 的值，如果值为 1 就必然存在单点故障，如果大于 1 但所有副本都调度到同一个节点了，那还是有单点故障，有时候还要考虑到灾难，比如整个机房不可用。\n所以我们不仅要有合理的副本数量，还需要让这些不同副本调度到不同的拓扑域(节点、可用区)，打散调度以避免单点故障，这个可以利用 Pod 反亲和性来做到，反亲和主要分强反亲和与弱反亲和两种。\n先来看个强反亲和的示例，将 dns 服务强制打散调度到不同节点上:\naffinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: k8s-app operator: In values: - kube-dns topologyKey: kubernetes.io/hostname  labelSelector.matchExpressions 写该服务对应 pod 中 labels 的 key 与 value，因为 Pod 反亲和性是通过判断 replicas 的 pod label 来实现的。 topologyKey 指定反亲和的拓扑域，即节点 label 的 key。这里用的 kubernetes.io/hostname 表示避免 pod 调度到同一节点，如果你有更高的要求，比如避免调度到同一个可用区，实现异地多活，可以用 failure-domain.beta.kubernetes.io/zone。通常不会去避免调度到同一个地域，因为一般同一个集群的节点都在一个地域，如果跨地域，即使用专线时延也会很大，所以 topologyKey 一般不至于用 failure-domain.beta.kubernetes.io/region。 requiredDuringSchedulingIgnoredDuringExecution 调度时必须满足该反亲和性条件，如果没有节点满足条件就不调度到任何节点 (Pending)。  如果不用这种硬性条件可以使用 preferredDuringSchedulingIgnoredDuringExecution 来指示调度器尽量满足反亲和性条件，即弱反亲和性，如果实在没有满足条件的，只要节点有足够资源，还是可以让其调度到某个节点，至少不会 Pending。\n我们再来看个弱反亲和的示例:\naffinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: k8s-app operator: In values: - kube-dns topologyKey: kubernetes.io/hostname 注意到了吗？相比强反亲和有些不同哦，多了一个 weight，表示此匹配条件的权重，而匹配条件被挪到了 podAffinityTerm 下面。\n如何避免节点维护或升级时导致服务不可用？ 有时候我们需要对节点进行维护或进行版本升级等操作，操作之前需要对节点执行驱逐 (kubectl drain)，驱逐时会将节点上的 Pod 进行删除，以便它们漂移到其它节点上，当驱逐完毕之后，节点上的 Pod 都漂移到其它节点了，这时我们就可以放心的对节点进行操作了。\n有一个问题就是，驱逐节点是一种有损操作，驱逐的原理:\n 封锁节点 (设为不可调度，避免新的 Pod 调度上来)。 将该节点上的 Pod 删除。 ReplicaSet 控制器检测到 Pod 减少，会重新创建一个 Pod，调度到新的节点上。  这个过程是先删除，再创建，并非是滚动更新，因此更新过程中，如果一个服务的所有副本都在被驱逐的节点上，则可能导致该服务不可用。\n我们再来下什么情况下驱逐会导致服务不可用:\n 服务存在单点故障，所有副本都在同一个节点，驱逐该节点时，就可能造成服务不可用。 服务没有单点故障，但刚好这个服务涉及的 Pod 全部都部署在这一批被驱逐的节点上，所以这个服务的所有 Pod 同时被删，也会造成服务不可用。 服务没有单点故障，也没有全部部署到这一批被驱逐的节点上，但驱逐时造成这个服务的一部分 Pod 被删，短时间内服务的处理能力下降导致服务过载，部分请求无法处理，也就降低了服务可用性。  针对第一点，我们可以使用前面讲的反亲和性来避免单点故障。\n针对第二和第三点，我们可以通过配置 PDB (PodDisruptionBudget) 来避免所有副本同时被删除，驱逐时 K8S 会 \u0026ldquo;观察\u0026rdquo; nginx 的当前可用与期望的副本数，根据定义的 PDB 来控制 Pod 删除速率，达到阀值时会等待 Pod 在其它节点上启动并就绪后再继续删除，以避免同时删除太多的 Pod 导致服务不可用或可用性降低，下面给出两个示例。\n示例一 (保证驱逐时 nginx 至少有 90% 的副本可用):\napiVersion: policy/v1beta1 kind: PodDisruptionBudget metadata: name: zk-pdb spec: minAvailable: 90% selector: matchLabels: app: zookeeper 示例二 (保证驱逐时 zookeeper 最多有一个副本不可用，相当于逐个删除并等待在其它节点完成重建):\napiVersion: policy/v1beta1 kind: PodDisruptionBudget metadata: name: zk-pdb spec: maxUnavailable: 1 selector: matchLabels: app: zookeeper 如何让服务进行平滑更新？ 解决了服务单点故障和驱逐节点时导致的可用性降低问题后，我们还需要考虑一种可能导致可用性降低的场景，那就是滚动更新。为什么服务正常滚动更新也可能影响服务的可用性呢？别急，下面我来解释下原因。\n假如集群内存在服务间调用:\n当 server 端发生滚动更新时:\n发生两种尴尬的情况:\n 旧的副本很快销毁，而 client 所在节点 kube-proxy 还没更新完转发规则，仍然将新连接调度给旧副本，造成连接异常，可能会报 \u0026ldquo;connection refused\u0026rdquo; (进程停止过程中，不再接受新请求) 或 \u0026ldquo;no route to host\u0026rdquo; (容器已经完全销毁，网卡和 IP 已不存在)。 新副本启动，client 所在节点 kube-proxy 很快 watch 到了新副本，更新了转发规则，并将新连接调度给新副本，但容器内的进程启动很慢 (比如 Tomcat 这种 java 进程)，还在启动过程中，端口还未监听，无法处理连接，也造成连接异常，通常会报 \u0026ldquo;connection refused\u0026rdquo; 的错误。  针对第一种情况，可以给 container 加 preStop，让 Pod 真正销毁前先 sleep 等待一段时间，等待 client 所在节点 kube-proxy 更新转发规则，然后再真正去销毁容器。这样能保证在 Pod Terminating 后还能继续正常运行一段时间，这段时间如果因为 client 侧的转发规则更新不及时导致还有新请求转发过来，Pod 还是可以正常处理请求，避免了连接异常的发生。听起来感觉有点不优雅，但实际效果还是比较好的，分布式的世界没有银弹，我们只能尽量在当前设计现状下找到并实践能够解决问题的最优解。\n针对第二种情况，可以给 container 加 ReadinessProbe (就绪检查)，让容器内进程真正启动完成后才更新 Service 的 Endpoint，然后 client 所在节点 kube-proxy 再更新转发规则，让流量进来。这样能够保证等 Pod 完全就绪了才会被转发流量，也就避免了链接异常的发生。\n最佳实践 yaml 示例:\nreadinessProbe: httpGet: path: /healthz port: 80 httpHeaders: - name: X-Custom-Header value: Awesome initialDelaySeconds: 10 timeoutSeconds: 1 lifecycle: preStop: exec: command: [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sleep 10\u0026#34;] 健康检查怎么配才好？ 我们都知道，给 Pod 配置健康检查也是提高服务可用性的一种手段，配置 ReadinessProbe (就绪检查) 可以避免将流量转发给还没启动完全或出现异常的 Pod；配置 LivenessProbe (存活检查) 可以让存在 bug 导致死锁或 hang 住的应用重启来恢复。但是，如果配置配置不好，也可能引发其它问题，这里根据一些踩坑经验总结了一些指导性的建议：\n 不要轻易使用 LivenessProbe，除非你了解后果并且明白为什么你需要它，参考 Liveness Probes are Dangerous 如果使用 LivenessProbe，不要和 ReadinessProbe 设置成一样 (failureThreshold 更大) 探测逻辑里不要有外部依赖 (db, 其它 pod 等)，避免抖动导致级联故障 业务程序应尽量暴露 HTTP 探测接口来适配健康检查，避免使用 TCP 探测，因为程序 hang 死时， TCP 探测仍然能通过 (TCP 的 SYN 包探测端口是否存活在内核态完成，应用层不感知)  参考资料  Affinity and anti-affinity: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity Specifying a Disruption Budget for your Application: https://kubernetes.io/docs/tasks/run-application/configure-pdb/ Liveness Probes are Dangerous: https://srcco.de/posts/kubernetes-liveness-probes-are-dangerous.html  "
},
{
	"uri": "https://k8s.imroc.io/ingress/traefik-ingress/install-traefik-ingress/",
	"title": "安装 traefik ingress controller",
	"tags": [],
	"description": "",
	"content": "最佳安装方案 如何暴露 ingress 访问入口? 最佳方案是使用 LoadBalancer 类型的 Service 来暴露，即创建外部负载均衡器来暴露流量，后续访问 ingress 的流量都走这个负载均衡器的地址，ingress 规则里面配的域名也要配置解析到这个负载均衡器的 IP 地址。\n这种方式需要集群支持 LoadBalancer 类型的 Service，如果是云厂商提供的 k8s 服务，或者在云上自建集群并使用了云厂商提供的 cloud provider，也都是支持的，创建 LoadBalancer 类型的 Service 的时候会自动调云厂商的接口创建云厂商提供的负载均衡器产品(通常公网类型的负载均衡器是付费的)；如果你的集群不是前面说的情况，是自建集群并且有自己的负载均衡器方案，并部署了相关插件来适配，比如 MetalLB 和 Porter，这样也是可以支持 LoadBalancer 类型的 Service 的。\n使用 helm 安装  参考官方文档: https://docs.traefik.io/getting-started/install-traefik/\n traefik 官方默认的 Helm Chart 是 v1.x 版本 (stable/traefik)，v2.x 的 chart 还在试验阶段\n 下面是 traefik 官方稳定版的 chart 安装方法(traefik v1.x):\n Helm 2 Helm 3  helm install stable/traefik \\  --name traefik \\  --namespace kube-system \\  --set kubernetes.ingressClass=traefik \\  --set kubernetes.ingressEndpoint.useDefaultPublishedService=true \\  --set rbac.enabled=true   helm install traefik stable/traefik \\  --namespace kube-system \\  --set kubernetes.ingressClass=traefik \\  --set kubernetes.ingressEndpoint.useDefaultPublishedService=true \\  --set rbac.enabled=true    $(function(){$(\"#traefik-v1\").tabs();});  kubernetes.ingressClass=traefik: 创建的 ingress 中包含 kubernetes.io/ingress.class 这个 annotation 并且值与这里配置的一致，这个 traefik ingress controller 才会处理 (生成转发规则) kubernetes.ingressEndpoint.useDefaultPublishedService=true: 这个置为 true 主要是为了让 ingress 的外部地址正确显示 (显示为负载均衡器的地址)，因为如果不配置这个，默认情况下会将 ingress controller 所有实例的节点 ip 写到 ingress 的 address 列表里，使用 kubectl get ingress 查看时会很丑陋并且容易误解。 rbac.enabled 默认为 false，如果没有事先给 default 的 service account 绑足够权限就会报错，通常置为 true，自动创建 rbac 规则  如果喜欢尝鲜，可以装 traefik v2.x 版本的 chart:\n Helm 2 Helm 3  git clone --depth 1 https://github.com/containous/traefik-helm-chart.git kubectl apply -f traefik-helm-chart/traefik/crds helm repo add traefik https://containous.github.io/traefik-helm-chart helm repo update helm install traefik/traefik \\  --name traefik \\  --namespace kube-system   helm repo add traefik https://containous.github.io/traefik-helm-chart helm repo update helm install traefik traefik/traefik \\  --namespace kube-system \\  --set ports.web.port=80 \\  --set ports.websecure.port=443 \\  --set=\u0026#34;additionalArguments={--providers.kubernetesingress}\u0026#34;    $(function(){$(\"#traefik-v2\").tabs();}); 参考资料  Github 主页: https://github.com/containous/traefik helm hub 主页: https://hub.helm.sh/charts/stable/traefik 官方文档: https://docs.traefik.io  "
},
{
	"uri": "https://k8s.imroc.io/deploy/manual/",
	"title": "手工部署",
	"tags": [],
	"description": "",
	"content": "部署详情 各组件版本:\n kubernetes 1.16.1 containerd 1.3.0 coredns v1.6.2 cni v0.8.2 flannel v0.11.0 etcd v3.4.1  特点:\n kubelet 证书自动签发并轮转 kube-proxy 以 daemonset 方式部署，无需为其手动签发管理证书 运行时没有 docker 直接使用 containerd，绕过 dockerd 的许多 bug  部署步骤  部署前的准备工作 部署 ETCD 部署 Master 部署 Worker 节点 部署关键附加组件  "
},
{
	"uri": "https://k8s.imroc.io/bigdata-ai/flink-on-kubernetes/session-cluster/",
	"title": "Session Cluster 模式部署",
	"tags": [],
	"description": "",
	"content": "参考官方文档: https://ci.apache.org/projects/flink/flink-docs-stable/ops/deployment/kubernetes.html#flink-session-cluster-on-kubernetes\n准备资源文件(flink.yaml):\napiVersion: v1 kind: ConfigMap metadata: name: flink-config labels: app: flink data: flink-conf.yaml: |+ jobmanager.rpc.address: flink-jobmanager taskmanager.numberOfTaskSlots: 1 blob.server.port: 6124 jobmanager.rpc.port: 6123 taskmanager.rpc.port: 6122 jobmanager.heap.size: 1024m taskmanager.memory.process.size: 1024m log4j.properties: |+ log4j.rootLogger=INFO, file log4j.logger.akka=INFO log4j.logger.org.apache.kafka=INFO log4j.logger.org.apache.hadoop=INFO log4j.logger.org.apache.zookeeper=INFO log4j.appender.file=org.apache.log4j.FileAppender log4j.appender.file.file=${log.file} log4j.appender.file.layout=org.apache.log4j.PatternLayout log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n log4j.logger.org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline=ERROR, file --- apiVersion: apps/v1 kind: Deployment metadata: name: flink-jobmanager spec: replicas: 1 selector: matchLabels: app: flink component: jobmanager template: metadata: labels: app: flink component: jobmanager spec: containers: - name: jobmanager image: flink:latest workingDir: /opt/flink command: [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;$FLINK_HOME/bin/jobmanager.sh start;\\ while :; do if [[ -f $(find log -name \u0026#39;*jobmanager*.log\u0026#39; -print -quit) ]]; then tail -f -n +1 log/*jobmanager*.log; fi; done\u0026#34;] ports: - containerPort: 6123 name: rpc - containerPort: 6124 name: blob - containerPort: 8081 name: ui livenessProbe: tcpSocket: port: 6123 initialDelaySeconds: 30 periodSeconds: 60 volumeMounts: - name: flink-config-volume mountPath: /opt/flink/conf securityContext: runAsUser: 9999 # refers to user _flink_ from official flink image, change if necessary volumes: - name: flink-config-volume configMap: name: flink-config items: - key: flink-conf.yaml path: flink-conf.yaml - key: log4j.properties path: log4j.properties --- apiVersion: apps/v1 kind: Deployment metadata: name: flink-taskmanager spec: replicas: 2 selector: matchLabels: app: flink component: taskmanager template: metadata: labels: app: flink component: taskmanager spec: containers: - name: taskmanager image: flink:latest workingDir: /opt/flink command: [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;$FLINK_HOME/bin/taskmanager.sh start; \\ while :; do if [[ -f $(find log -name \u0026#39;*taskmanager*.log\u0026#39; -print -quit) ]]; then tail -f -n +1 log/*taskmanager*.log; fi; done\u0026#34;] ports: - containerPort: 6122 name: rpc livenessProbe: tcpSocket: port: 6122 initialDelaySeconds: 30 periodSeconds: 60 volumeMounts: - name: flink-config-volume mountPath: /opt/flink/conf/ securityContext: runAsUser: 9999 # refers to user _flink_ from official flink image, change if necessary volumes: - name: flink-config-volume configMap: name: flink-config items: - key: flink-conf.yaml path: flink-conf.yaml - key: log4j.properties path: log4j.properties --- apiVersion: v1 kind: Service metadata: name: flink-jobmanager spec: type: ClusterIP ports: - name: rpc port: 6123 - name: blob port: 6124 - name: ui port: 8081 selector: app: flink component: jobmanager --- apiVersion: v1 kind: Service metadata: name: flink-jobmanager-rest spec: type: NodePort ports: - name: rest port: 8081 targetPort: 8081 selector: app: flink component: jobmanager 安装：\nkubectl apply -f flink.yaml 如何访问 JobManager 的 UI ？在 TKE 或者 EKS 上，支持 LoadBalancer 类型的 Service，可以将 JobManager 的 UI 用 LB 暴露：\nkubectl patch service flink-jobmanager -p \u0026#39;{\u0026#34;spec\u0026#34;:{\u0026#34;type\u0026#34;:\u0026#34;LoadBalancer\u0026#34;}}\u0026#39; 卸载：\nkubectl delete -f flink.yaml  若要部署到不同命名空间，请提前创建好命名空间并在所有 kubectl 命令后加 -n  "
},
{
	"uri": "https://k8s.imroc.io/avoid/",
	"title": "避坑指南",
	"tags": [],
	"description": "",
	"content": "目录  .Net Core 配置文件在Kubernetes中无法热加载     cgroup 泄露     conntrack 冲突导致丢包     tcp tw recycle 引发丢包     使用 NodeLocal DNS (缓存)     使用 oom-guard 在用户态处理 cgroup OOM     解决长连接服务扩容失效     踩坑分享    ARP 缓存爆满导致健康检查失败   DNS 5 秒延时   DNS 解析异常   kubectl edit 或者 apply 报 SchemaError   LB 压测 NodePort CPS 低   Pod 偶尔存活检查失败   Pod 访问另一个集群的 apiserver 有延时   神秘的溢出与丢包   访问 externalTrafficPolicy 为 Local 的 Service 对应 LB 有时超时   诡异的 No route to host   跨 VPC 访问 NodePort 经常超时   驱逐导致服务中断    "
},
{
	"uri": "https://k8s.imroc.io/monitoring/build-cloud-native-large-scale-distributed-monitoring-system/thanos-deploy/",
	"title": "Thanos 部署与实践",
	"tags": [],
	"description": "",
	"content": "概述 上一篇 Thanos 架构详解 我们深入理解了 thanos 的架构设计与实现原理，现在我们来聊聊实战，分享一下如何部署和使用 Thanos。\n部署方式 本文聚焦 Thanos 的云原生部署方式，充分利用 Kubernetes 的资源调度与动态扩容能力。从官方 这里 可以看到，当前 thanos 在 Kubernetes 上部署有以下三种：\n prometheus-operator: 集群中安装了 prometheus-operator 后，就可以通过创建 CRD 对象来部署 Thanos 了。 社区贡献的一些 helm charts: 很多个版本，目标都是能够使用 helm 来一键部署 thanos。 kube-thanos: Thanos 官方的开源项目，包含部署 thanos 到 kubernetes 的 jsonnet 模板与 yaml 示例。  本文将使用基于 kube-thanos 提供的 yaml 示例 (examples/all/manifests) 来部署，原因是 prometheus-operator 与社区的 helm chart 方式部署多了一层封装，屏蔽了许多细节，并且它们的实现都还不太成熟；直接使用 kubernetes 的 yaml 资源文件部署更直观，也更容易做自定义，而且我相信使用 thanos 的用户通常都是高玩了，也有必要对 thanos 理解透彻，日后才好根据实际场景做架构和配置的调整，直接使用 yaml 部署能够让我们看清细节。\n方案选型 Sidecar or Receiver 看了上一篇文章的同学应该知道，目前官方的架构图用的 Sidecar 方案，Receiver 是一个暂时还没有完全发布的组件。通常来说，Sidecar 方案相对成熟一些，最新的数据存储和计算 (比如聚合函数) 比较 \u0026ldquo;分布式\u0026rdquo;，更加高效也更容易扩展。\nReceiver 方案是让 Prometheus 通过 remote wirte API 将数据 push 到 Receiver 集中存储 (同样会清理过期数据):\n那么该选哪种方案呢？我的建议是：\n 如果你的 Query 跟 Sidecar 离的比较远，比如 Sidecar 分布在多个数据中心，Query 向所有 Sidecar 查数据，速度会很慢，这种情况可以考虑用 Receiver，将数据集中吐到 Receiver，然后 Receiver 与 Query 部署在一起，Query 直接向 Receiver 查最新数据，提升查询性能。 如果你的使用场景只允许 Prometheus 将数据 push 到远程，可以考虑使用 Receiver。比如 IoT 设备没有持久化存储，只能将数据 push 到远程。  此外的场景应该都尽量使用 Sidecar 方案。\n评估是否需要 Ruler Ruler 是一个可选组件，原则上推荐尽量使用 Prometheus 自带的 rule 功能 (生成新指标+告警)，这个功能需要一些 Prometheus 最新数据，直接使用 Prometheus 本机 rule 功能和数据，性能开销相比 Thanos Ruler 这种分布式方案小得多，并且几乎不会出错，Thanos Ruler 由于是分布式，所以更容易出错一些。\n如果某些有关联的数据分散在多个不同 Prometheus 上，比如对某个大规模服务采集做了分片，每个 Prometheus 仅采集一部分 endpoint 的数据，对于 record 类型的 rule (生成的新指标)，还是可以使用 Prometheus 自带的 rule 功能，在查询时再聚合一下就可以(如果可以接受的话)；对于 alert 类型的 rule，就需要用 Thanos Ruler 来做了，因为有关联的数据分散在多个 Prometheus 上，用单机数据去做 alert 计算是不准确的，就可能会造成误告警或不告警。\n评估是否需要 Store Gateway 与 Compact Store 也是一个可选组件，也是 Thanos 的一大亮点的关键：数据长期保存。\n评估是否需要 Store 组件实际就是评估一下自己是否有数据长期存储的需求，比如查看一两个月前的监控数据。如果有，那么 Thanos 可以将数据上传到对象存储保存。Thanos 支持以下对象存储:\n Google Cloud Storage AWS/S3 Azure Storage Account OpenStack Swift Tencent COS AliYun OSS  在国内，最方便还是使用腾讯云 COS 或者阿里云 OSS 这样的公有云对象存储服务。如果你的服务没有跑在公有云上，也可以通过跟云服务厂商拉专线的方式来走内网使用对象存储，这样速度通常也是可以满足需求的；如果实在用不了公有云的对象存储服务，也可以自己安装 minio 来搭建兼容 AWS 的 S3 对象存储服务。\n搞定了对象存储，还需要给 Thanos 多个组件配置对象存储相关的信息，以便能够上传与读取监控数据。除 Query 以外的所有 Thanos 组件 (Sidecar、Receiver、Ruler、Store Gateway、Compact) 都需要配置对象存储信息，使用 --objstore.config 直接配置内容或 --objstore.config-file 引用对象存储配置文件，不同对象存储配置方式不一样，参考官方文档: https://thanos.io/storage.md\n通常使用了对象存储来长期保存数据不止要安装 Store Gateway，还需要安装 Compact 来对对象存储里的数据进行压缩与降采样，这样可以提升查询大时间范围监控数据的性能。注意：Compact 并不会减少对象存储的使用空间，而是会增加，增加更长采样间隔的监控数据，这样当查询大时间范围的数据时，就自动拉取更长时间间隔采样的数据以减少查询数据的总量，从而加快查询速度 (大时间范围的数据不需要那么精细)，当放大查看时 (选择其中一小段时间)，又自动选择拉取更短采样间隔的数据，从而也能显示出小时间范围的监控细节。\n部署实践 这里以 Thanos 最新版本为例，选择 Sidecar 方案，介绍各个组件的 k8s yaml 定义方式并解释一些重要细节 (根据自身需求，参考上一节的方案选型，自行评估需要安装哪些组件)。\n准备对象存储配置 如果我们要使用对象存储来长期保存数据，那么就要准备下对象存储的配置信息 (thanos-objectstorage-secret.yaml)，比如使用腾讯云 COS 来存储:\napiVersion: v1 kind: Secret metadata: name: thanos-objectstorage namespace: thanos type: Opaque stringData: objectstorage.yaml: | type: COS config: bucket: \u0026#34;thanos\u0026#34; region: \u0026#34;ap-singapore\u0026#34; app_id: \u0026#34;12*******5\u0026#34; secret_key: \u0026#34;tsY***************************Edm\u0026#34; secret_id: \u0026#34;AKI******************************gEY\u0026#34; 或者使用阿里云 OSS 存储:\napiVersion: v1 kind: Secret metadata: name: thanos-objectstorage namespace: thanos type: Opaque stringData: objectstorage.yaml: | type: ALIYUNOSS config: endpoint: \u0026#34;oss-cn-hangzhou-internal.aliyuncs.com\u0026#34; bucket: \u0026#34;thanos\u0026#34; access_key_id: \u0026#34;LTA******************KBu\u0026#34; access_key_secret: \u0026#34;oki************************2HQ\u0026#34;  注: 对敏感信息打码了\n 给 Prometheus 加上 Sidecar 如果选用 Sidecar 方案，就需要给 Prometheus 加上 Thanos Sidecar，准备 prometheus.yaml:\nkind: Service apiVersion: v1 metadata: name: prometheus-headless namespace: thanos labels: app.kubernetes.io/name: prometheus spec: type: ClusterIP clusterIP: None selector: app.kubernetes.io/name: prometheus ports: - name: web protocol: TCP port: 9090 targetPort: web - name: grpc port: 10901 targetPort: grpc --- apiVersion: v1 kind: ServiceAccount metadata: name: prometheus namespace: thanos --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRole metadata: name: prometheus namespace: thanos rules: - apiGroups: [\u0026#34;\u0026#34;] resources: - nodes - nodes/proxy - nodes/metrics - services - endpoints - pods verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;configmaps\u0026#34;] verbs: [\u0026#34;get\u0026#34;] - nonResourceURLs: [\u0026#34;/metrics\u0026#34;] verbs: [\u0026#34;get\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: prometheus subjects: - kind: ServiceAccount name: prometheus namespace: thanos roleRef: kind: ClusterRole name: prometheus apiGroup: rbac.authorization.k8s.io --- apiVersion: apps/v1 kind: StatefulSet metadata: name: prometheus namespace: thanos labels: app.kubernetes.io/name: thanos-query spec: serviceName: prometheus-headless podManagementPolicy: Parallel replicas: 2 selector: matchLabels: app.kubernetes.io/name: prometheus template: metadata: labels: app.kubernetes.io/name: prometheus spec: serviceAccountName: prometheus securityContext: fsGroup: 2000 runAsNonRoot: true runAsUser: 1000 affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app.kubernetes.io/name operator: In values: - prometheus topologyKey: kubernetes.io/hostname containers: - name: prometheus image: quay.io/prometheus/prometheus:v2.15.2 args: - --config.file=/etc/prometheus/config_out/prometheus.yaml - --storage.tsdb.path=/prometheus - --storage.tsdb.retention.time=10d - --web.route-prefix=/ - --web.enable-lifecycle - --storage.tsdb.no-lockfile - --storage.tsdb.min-block-duration=2h - --storage.tsdb.max-block-duration=2h - --log.level=debug ports: - containerPort: 9090 name: web protocol: TCP livenessProbe: failureThreshold: 6 httpGet: path: /-/healthy port: web scheme: HTTP periodSeconds: 5 successThreshold: 1 timeoutSeconds: 3 readinessProbe: failureThreshold: 120 httpGet: path: /-/ready port: web scheme: HTTP periodSeconds: 5 successThreshold: 1 timeoutSeconds: 3 volumeMounts: - mountPath: /etc/prometheus/config_out name: prometheus-config-out readOnly: true - mountPath: /prometheus name: prometheus-storage - mountPath: /etc/prometheus/rules name: prometheus-rules - name: thanos image: quay.io/thanos/thanos:v0.11.0 args: - sidecar - --log.level=debug - --tsdb.path=/prometheus - --prometheus.url=http://127.0.0.1:9090 - --objstore.config-file=/etc/thanos/objectstorage.yaml - --reloader.config-file=/etc/prometheus/config/prometheus.yaml.tmpl - --reloader.config-envsubst-file=/etc/prometheus/config_out/prometheus.yaml - --reloader.rule-dir=/etc/prometheus/rules/ env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name ports: - name: http-sidecar containerPort: 10902 - name: grpc containerPort: 10901 livenessProbe: httpGet: port: 10902 path: /-/healthy readinessProbe: httpGet: port: 10902 path: /-/ready volumeMounts: - name: prometheus-config-tmpl mountPath: /etc/prometheus/config - name: prometheus-config-out mountPath: /etc/prometheus/config_out - name: prometheus-rules mountPath: /etc/prometheus/rules - name: prometheus-storage mountPath: /prometheus - name: thanos-objectstorage subPath: objectstorage.yaml mountPath: /etc/thanos/objectstorage.yaml volumes: - name: prometheus-config-tmpl configMap: defaultMode: 420 name: prometheus-config-tmpl - name: prometheus-config-out emptyDir: {} - name: prometheus-rules configMap: name: prometheus-rules - name: thanos-objectstorage secret: secretName: thanos-objectstorage volumeClaimTemplates: - metadata: name: prometheus-storage labels: app.kubernetes.io/name: prometheus spec: accessModes: - ReadWriteOnce resources: requests: storage: 200Gi volumeMode: Filesystem  Prometheus 使用 StatefulSet 方式部署，挂载数据盘以便存储最新监控数据。 由于 Prometheus 副本之间没有启动顺序的依赖，所以 podManagementPolicy 指定为 Parallel，加快启动速度。 为 Prometheus 绑定足够的 RBAC 权限，以便后续配置使用 k8s 的服务发现 (kubernetes_sd_configs) 时能够正常工作。 为 Prometheus 创建 headless 类型 service，一方面是 StatefulSet 本身需要指定 headless 的 serviceName，另一方面是为后续 Thanos Query 通过 DNS SRV 记录来动态发现 Sidecar 的 gRPC 端点做准备 (使用 headless service 才能让 DNS SRV 正确返回所有端点)。 使用两个 Prometheus 副本，用于实现高可用。 使用硬反亲和，避免 Prometheus 部署在同一节点，既可以分散压力也可以避免单点故障。 Prometheus 使用 --storage.tsdb.retention.time 指定数据保留时长，默认15天，可以根据数据增长速度和数据盘大小做适当调整(数据增长取决于采集的指标和目标端点的数量和采集频率)。 Sidecar 使用 --objstore.config-file 引用我们刚刚创建并挂载的对象存储配置文件，用于上传数据到对象存储。 通常会给 Prometheus 附带一个 quay.io/coreos/prometheus-config-reloader 来监听配置变更并动态加载，但 thanos sidecar 也为我们提供了这个功能，所以可以直接用 thanos sidecar 来实现此功能，也支持配置文件根据模板动态生成：--reloader.config-file 指定 Prometheus 配置文件模板，--reloader.config-envsubst-file 指定生成配置文件的存放路径，假设是 /etc/prometheus/config_out/prometheus.yaml ，那么 /etc/prometheus/config_out 这个路径使用 emptyDir 让 Prometheus 与 Sidecar 实现配置文件共享挂载，Prometheus 再通过 --config.file 指定生成出来的配置文件，当配置有更新时，挂载的配置文件也会同步更新，Sidecar 也会通知 Prometheus 重新加载配置。另外，Sidecar 与 Prometheus 也挂载同一份 rules 配置文件，配置更新后 Sidecar 仅通知 Prometheus 加载配置，不支持模板，因为 rules 配置不需要模板来动态生成。  然后再给 Prometheus 准备配置 (prometheus-config.yaml):\napiVersion: v1 kind: ConfigMap metadata: name: prometheus-config-tmpl namespace: thanos data: prometheus.yaml.tmpl: |- global: scrape_interval: 5s evaluation_interval: 5s external_labels: cluster: prometheus-ha prometheus_replica: $(POD_NAME) rule_files: - /etc/prometheus/rules/*rules.yaml scrape_configs: - job_name: cadvisor metrics_path: /metrics/cadvisor scrape_interval: 10s scrape_timeout: 10s scheme: https tls_config: insecure_skip_verify: true bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) --- apiVersion: v1 kind: ConfigMap metadata: name: prometheus-rules labels: name: prometheus-rules namespace: thanos data: alert-rules.yaml: |- groups: - name: k8s.rules rules: - expr: | sum(rate(container_cpu_usage_seconds_total{job=\u0026#34;cadvisor\u0026#34;, image!=\u0026#34;\u0026#34;, container!=\u0026#34;\u0026#34;}[5m])) by (namespace) record: namespace:container_cpu_usage_seconds_total:sum_rate - expr: | sum(container_memory_usage_bytes{job=\u0026#34;cadvisor\u0026#34;, image!=\u0026#34;\u0026#34;, container!=\u0026#34;\u0026#34;}) by (namespace) record: namespace:container_memory_usage_bytes:sum - expr: | sum by (namespace, pod, container) ( rate(container_cpu_usage_seconds_total{job=\u0026#34;cadvisor\u0026#34;, image!=\u0026#34;\u0026#34;, container!=\u0026#34;\u0026#34;}[5m]) ) record: namespace_pod_container:container_cpu_usage_seconds_total:sum_rate  本文重点不在 prometheus 的配置文件，所以这里仅以采集 kubelet 所暴露的 cadvisor 容器指标的简单配置为例。 Prometheus 实例采集的所有指标数据里都会额外加上 external_labels 里指定的 label，通常用 cluster 区分当前 Prometheus 所在集群的名称，我们再加了个 prometheus_replica，用于区分相同 Prometheus 副本（这些副本所采集的数据除了 prometheus_replica 的值不一样，其它几乎一致，这个值会被 Thanos Sidecar 替换成 Pod 副本的名称，用于 Thanos 实现 Prometheus 高可用）  安装 Query 准备 thanos-query.yaml:\napiVersion: v1 kind: Service metadata: name: thanos-query namespace: thanos labels: app.kubernetes.io/name: thanos-query spec: ports: - name: grpc port: 10901 targetPort: grpc - name: http port: 9090 targetPort: http selector: app.kubernetes.io/name: thanos-query --- apiVersion: apps/v1 kind: Deployment metadata: name: thanos-query namespace: thanos labels: app.kubernetes.io/name: thanos-query spec: replicas: 3 selector: matchLabels: app.kubernetes.io/name: thanos-query template: metadata: labels: app.kubernetes.io/name: thanos-query spec: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: labelSelector: matchExpressions: - key: app.kubernetes.io/name operator: In values: - thanos-query topologyKey: kubernetes.io/hostname weight: 100 containers: - args: - query - --log.level=debug - --query.auto-downsampling - --grpc-address=0.0.0.0:10901 - --http-address=0.0.0.0:9090 - --query.partial-response - --query.replica-label=prometheus_replica - --query.replica-label=rule_replica - --store=dnssrv+_grpc._tcp.prometheus-headless.thanos.svc.cluster.local - --store=dnssrv+_grpc._tcp.thanos-rule.thanos.svc.cluster.local - --store=dnssrv+_grpc._tcp.thanos-store.thanos.svc.cluster.local image: thanosio/thanos:v0.11.0 livenessProbe: failureThreshold: 4 httpGet: path: /-/healthy port: 9090 scheme: HTTP periodSeconds: 30 name: thanos-query ports: - containerPort: 10901 name: grpc - containerPort: 9090 name: http readinessProbe: failureThreshold: 20 httpGet: path: /-/ready port: 9090 scheme: HTTP periodSeconds: 5 terminationMessagePolicy: FallbackToLogsOnError terminationGracePeriodSeconds: 120  因为 Query 是无状态的，使用 Deployment 部署，也不需要 headless service，直接创建普通的 service。 使用软反亲和，尽量不让 Query 调度到同一节点。 部署多个副本，实现 Query 的高可用。 --query.partial-response 启用 Partial Response，这样可以在部分后端 Store API 返回错误或超时的情况下也能看到正确的监控数据(如果后端 Store API 做了高可用，挂掉一个副本，Query 访问挂掉的副本超时，但由于还有没挂掉的副本，还是能正确返回结果；如果挂掉的某个后端本身就不存在我们需要的数据，挂掉也不影响结果的正确性；总之如果各个组件都做了高可用，想获得错误的结果都难，所以我们有信心启用 Partial Response 这个功能)。 --query.auto-downsampling 查询时自动降采样，提升查询效率。 --query.replica-label 指定我们刚刚给 Prometheus 配置的 prometheus_replica 这个 external label，Query 向 Sidecar 拉取 Prometheus 数据时会识别这个 label 并自动去重，这样即使挂掉一个副本，只要至少有一个副本正常也不会影响查询结果，也就是可以实现 Prometheus 的高可用。同理，再指定一个 rule_replica 用于给 Ruler 做高可用。 --store 指定实现了 Store API 的地址(Sidecar, Ruler, Store Gateway, Receiver)，通常不建议写静态地址，而是使用服务发现机制自动发现 Store API 地址，如果是部署在同一个集群，可以用 DNS SRV 记录来做服务发现，比如 dnssrv+_grpc._tcp.prometheus-headless.thanos.svc.cluster.local，也就是我们刚刚为包含 Sidecar 的 Prometheus 创建的 headless service (使用 headless service 才能正确实现服务发现)，并且指定了名为 grpc 的 tcp 端口，同理，其它组件也可以按照这样加到 --store 参数里；如果是其它有些组件部署在集群外，无法通过集群 dns 解析 DNS SRV 记录，可以使用配置文件来做服务发现，也就是指定 --store.sd-files 参数，将其它 Store API 地址写在配置文件里 (挂载 ConfigMap)，需要增加地址时直接更新 ConfigMap (不需要重启 Query)。  安装 Store Gateway 准备 thanos-store.yaml:\napiVersion: v1 kind: Service metadata: name: thanos-store namespace: thanos labels: app.kubernetes.io/name: thanos-store spec: clusterIP: None ports: - name: grpc port: 10901 targetPort: 10901 - name: http port: 10902 targetPort: 10902 selector: app.kubernetes.io/name: thanos-store --- apiVersion: apps/v1 kind: StatefulSet metadata: name: thanos-store namespace: thanos labels: app.kubernetes.io/name: thanos-store spec: replicas: 2 selector: matchLabels: app.kubernetes.io/name: thanos-store serviceName: thanos-store podManagementPolicy: Parallel template: metadata: labels: app.kubernetes.io/name: thanos-store spec: containers: - args: - store - --log.level=debug - --data-dir=/var/thanos/store - --grpc-address=0.0.0.0:10901 - --http-address=0.0.0.0:10902 - --objstore.config-file=/etc/thanos/objectstorage.yaml - --experimental.enable-index-header image: thanosio/thanos:v0.11.0 livenessProbe: failureThreshold: 8 httpGet: path: /-/healthy port: 10902 scheme: HTTP periodSeconds: 30 name: thanos-store ports: - containerPort: 10901 name: grpc - containerPort: 10902 name: http readinessProbe: failureThreshold: 20 httpGet: path: /-/ready port: 10902 scheme: HTTP periodSeconds: 5 terminationMessagePolicy: FallbackToLogsOnError volumeMounts: - mountPath: /var/thanos/store name: data readOnly: false - name: thanos-objectstorage subPath: objectstorage.yaml mountPath: /etc/thanos/objectstorage.yaml terminationGracePeriodSeconds: 120 volumes: - name: thanos-objectstorage secret: secretName: thanos-objectstorage volumeClaimTemplates: - metadata: labels: app.kubernetes.io/name: thanos-store name: data spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi  Store Gateway 实际也可以做到一定程度的无状态，它会需要一点磁盘空间来对对象存储做索引以加速查询，但数据不那么重要，是可以删除的，删除后会自动去拉对象存储查数据重新建立索引。这里我们避免每次重启都重新建立索引，所以用 StatefulSet 部署 Store Gateway，挂载一块小容量的磁盘(索引占用不到多大空间)。 同样创建 headless service，用于 Query 对 Store Gateway 进行服务发现。 部署两个副本，实现 Store Gateway 的高可用。 Store Gateway 也需要对象存储的配置，用于读取对象存储的数据，所以要挂载对象存储的配置文件。  安装 Ruler 准备 Ruler 部署配置 thanos-ruler.yaml:\napiVersion: v1 kind: Service metadata: labels: app.kubernetes.io/name: thanos-rule name: thanos-rule namespace: thanos spec: clusterIP: None ports: - name: grpc port: 10901 targetPort: grpc - name: http port: 10902 targetPort: http selector: app.kubernetes.io/name: thanos-rule --- apiVersion: apps/v1 kind: StatefulSet metadata: labels: app.kubernetes.io/name: thanos-rule name: thanos-rule namespace: thanos spec: replicas: 2 selector: matchLabels: app.kubernetes.io/name: thanos-rule serviceName: thanos-rule podManagementPolicy: Parallel template: metadata: labels: app.kubernetes.io/name: thanos-rule spec: containers: - args: - rule - --grpc-address=0.0.0.0:10901 - --http-address=0.0.0.0:10902 - --rule-file=/etc/thanos/rules/*rules.yaml - --objstore.config-file=/etc/thanos/objectstorage.yaml - --data-dir=/var/thanos/rule - --label=rule_replica=\u0026#34;$(NAME)\u0026#34; - --alert.label-drop=\u0026#34;rule_replica\u0026#34; - --query=dnssrv+_http._tcp.thanos-query.thanos.svc.cluster.local env: - name: NAME valueFrom: fieldRef: fieldPath: metadata.name image: thanosio/thanos:v0.11.0 livenessProbe: failureThreshold: 24 httpGet: path: /-/healthy port: 10902 scheme: HTTP periodSeconds: 5 name: thanos-rule ports: - containerPort: 10901 name: grpc - containerPort: 10902 name: http readinessProbe: failureThreshold: 18 httpGet: path: /-/ready port: 10902 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 5 terminationMessagePolicy: FallbackToLogsOnError volumeMounts: - mountPath: /var/thanos/rule name: data readOnly: false - name: thanos-objectstorage subPath: objectstorage.yaml mountPath: /etc/thanos/objectstorage.yaml - name: thanos-rules mountPath: /etc/thanos/rules volumes: - name: thanos-objectstorage secret: secretName: thanos-objectstorage - name: thanos-rules configMap: name: thanos-rules volumeClaimTemplates: - metadata: labels: app.kubernetes.io/name: thanos-rule name: data spec: accessModes: - ReadWriteOnce resources: requests: storage: 100Gi  Ruler 是有状态服务，使用 Statefulset 部署，挂载磁盘以便存储根据 rule 配置计算出的新数据。 同样创建 headless service，用于 Query 对 Ruler 进行服务发现。 部署两个副本，且使用 --label=rule_replica= 给所有数据添加 rule_replica 的 label (与 Query 配置的 replica_label 相呼应)，用于实现 Ruler 高可用。同时指定 --alert.label-drop 为 rule_replica，在触发告警发送通知给 AlertManager 时，去掉这个 label，以便让 AlertManager 自动去重 (避免重复告警)。 使用 --query 指定 Query 地址，这里还是用 DNS SRV 来做服务发现，但效果跟配 dns+thanos-query.thanos.svc.cluster.local:9090 是一样的，最终都是通过 Query 的 ClusterIP (VIP) 访问，因为它是无状态的，可以直接由 K8S 来给我们做负载均衡。 Ruler 也需要对象存储的配置，用于上传计算出的数据到对象存储，所以要挂载对象存储的配置文件。 --rule-file 指定挂载的 rule 配置，Ruler 根据配置来生成数据和触发告警。  再准备 Ruler 配置文件 thanos-ruler-config.yaml:\napiVersion: v1 kind: ConfigMap metadata: name: thanos-rules labels: name: thanos-rules namespace: thanos data: record.rules.yaml: |- groups: - name: k8s.rules rules: - expr: | sum(rate(container_cpu_usage_seconds_total{job=\u0026#34;cadvisor\u0026#34;, image!=\u0026#34;\u0026#34;, container!=\u0026#34;\u0026#34;}[5m])) by (namespace) record: namespace:container_cpu_usage_seconds_total:sum_rate - expr: | sum(container_memory_usage_bytes{job=\u0026#34;cadvisor\u0026#34;, image!=\u0026#34;\u0026#34;, container!=\u0026#34;\u0026#34;}) by (namespace) record: namespace:container_memory_usage_bytes:sum - expr: | sum by (namespace, pod, container) ( rate(container_cpu_usage_seconds_total{job=\u0026#34;cadvisor\u0026#34;, image!=\u0026#34;\u0026#34;, container!=\u0026#34;\u0026#34;}[5m]) ) record: namespace_pod_container:container_cpu_usage_seconds_total:sum_rate  配置内容仅为示例，根据自身情况来配置，格式基本兼容 Prometheus 的 rule 配置格式，参考: https://thanos.io/components/rule.md/#configuring-rules  安装 Compact 准备 Compact 部署配置 thanos-compact.yaml:\napiVersion: v1 kind: Service metadata: labels: app.kubernetes.io/name: thanos-compact name: thanos-compact namespace: thanos spec: ports: - name: http port: 10902 targetPort: http selector: app.kubernetes.io/name: thanos-compact --- apiVersion: apps/v1 kind: StatefulSet metadata: labels: app.kubernetes.io/name: thanos-compact name: thanos-compact namespace: thanos spec: replicas: 1 selector: matchLabels: app.kubernetes.io/name: thanos-compact serviceName: thanos-compact template: metadata: labels: app.kubernetes.io/name: thanos-compact spec: containers: - args: - compact - --wait - --objstore.config-file=/etc/thanos/objectstorage.yaml - --data-dir=/var/thanos/compact - --debug.accept-malformed-index - --log.level=debug - --retention.resolution-raw=90d - --retention.resolution-5m=180d - --retention.resolution-1h=360d image: thanosio/thanos:v0.11.0 livenessProbe: failureThreshold: 4 httpGet: path: /-/healthy port: 10902 scheme: HTTP periodSeconds: 30 name: thanos-compact ports: - containerPort: 10902 name: http readinessProbe: failureThreshold: 20 httpGet: path: /-/ready port: 10902 scheme: HTTP periodSeconds: 5 terminationMessagePolicy: FallbackToLogsOnError volumeMounts: - mountPath: /var/thanos/compact name: data readOnly: false - name: thanos-objectstorage subPath: objectstorage.yaml mountPath: /etc/thanos/objectstorage.yaml terminationGracePeriodSeconds: 120 volumes: - name: thanos-objectstorage secret: secretName: thanos-objectstorage volumeClaimTemplates: - metadata: labels: app.kubernetes.io/name: thanos-compact name: data spec: accessModes: - ReadWriteOnce resources: requests: storage: 100Gi  Compact 只能部署单个副本，因为如果多个副本都去对对象存储的数据做压缩和降采样的话，会造成冲突。 使用 StatefulSet 部署，方便自动创建和挂载磁盘。磁盘用于存放临时数据，因为 Compact 需要一些磁盘空间来存放数据处理过程中产生的中间数据。 --wait 让 Compact 一直运行，轮询新数据来做压缩和降采样。 Compact 也需要对象存储的配置，用于读取对象存储数据以及上传压缩和降采样后的数据到对象存储。 创建一个普通 service，主要用于被 Prometheus 使用 kubernetes 的 endpoints 服务发现来采集指标(其它组件的 service 也一样有这个用途)。 --retention.resolution-raw 指定原始数据存放时长，--retention.resolution-5m 指定降采样到数据点 5 分钟间隔的数据存放时长，--retention.resolution-1h 指定降采样到数据点 1 小时间隔的数据存放时长，它们的数据精细程度递减，占用的存储空间也是递减，通常建议它们的存放时间递增配置 (一般只有比较新的数据才会放大看，久远的数据通常只会使用大时间范围查询来看个大致，所以建议将精细程度低的数据存放更长时间)  安装 Receiver 该组件处于试验阶段，慎用。准备 Receiver 部署配置 thanos-receiver.yaml:\napiVersion: v1 kind: ConfigMap metadata: name: thanos-receive-hashrings namespace: thanos data: thanos-receive-hashrings.json: | [ { \u0026#34;hashring\u0026#34;: \u0026#34;soft-tenants\u0026#34;, \u0026#34;endpoints\u0026#34;: [ \u0026#34;thanos-receive-0.thanos-receive.kube-system.svc.cluster.local:10901\u0026#34;, \u0026#34;thanos-receive-1.thanos-receive.kube-system.svc.cluster.local:10901\u0026#34;, \u0026#34;thanos-receive-2.thanos-receive.kube-system.svc.cluster.local:10901\u0026#34; ] } ] --- apiVersion: v1 kind: Service metadata: name: thanos-receive namespace: thanos labels: kubernetes.io/name: thanos-receive spec: ports: - name: http port: 10902 protocol: TCP targetPort: 10902 - name: remote-write port: 19291 protocol: TCP targetPort: 19291 - name: grpc port: 10901 protocol: TCP targetPort: 10901 selector: kubernetes.io/name: thanos-receive clusterIP: None --- apiVersion: apps/v1 kind: StatefulSet metadata: labels: kubernetes.io/name: thanos-receive name: thanos-receive namespace: thanos spec: replicas: 3 selector: matchLabels: kubernetes.io/name: thanos-receive serviceName: thanos-receive template: metadata: labels: kubernetes.io/name: thanos-receive spec: containers: - args: - receive - --grpc-address=0.0.0.0:10901 - --http-address=0.0.0.0:10902 - --remote-write.address=0.0.0.0:19291 - --objstore.config-file=/etc/thanos/objectstorage.yaml - --tsdb.path=/var/thanos/receive - --tsdb.retention=12h - --label=receive_replica=\u0026#34;$(NAME)\u0026#34; - --label=receive=\u0026#34;true\u0026#34; - --receive.hashrings-file=/etc/thanos/thanos-receive-hashrings.json - --receive.local-endpoint=$(NAME).thanos-receive.thanos.svc.cluster.local:10901 env: - name: NAME valueFrom: fieldRef: fieldPath: metadata.name image: thanosio/thanos:v0.11.0 livenessProbe: failureThreshold: 4 httpGet: path: /-/healthy port: 10902 scheme: HTTP periodSeconds: 30 name: thanos-receive ports: - containerPort: 10901 name: grpc - containerPort: 10902 name: http - containerPort: 19291 name: remote-write readinessProbe: httpGet: path: /-/ready port: 10902 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 30 resources: limits: cpu: \u0026#34;4\u0026#34; memory: 8Gi requests: cpu: \u0026#34;2\u0026#34; memory: 4Gi volumeMounts: - mountPath: /var/thanos/receive name: data readOnly: false - mountPath: /etc/thanos/thanos-receive-hashrings.json name: thanos-receive-hashrings subPath: thanos-receive-hashrings.json - mountPath: /etc/thanos/objectstorage.yaml name: thanos-objectstorage subPath: objectstorage.yaml terminationGracePeriodSeconds: 120 volumes: - configMap: defaultMode: 420 name: thanos-receive-hashrings name: thanos-receive-hashrings - name: thanos-objectstorage secret: secretName: thanos-objectstorage volumeClaimTemplates: - metadata: labels: app.kubernetes.io/name: thanos-receive name: data spec: accessModes: - ReadWriteOnce resources: requests: storage: 200Gi  部署 3 个副本， 配置 hashring， --label=receive_replica 为数据添加 receive_replica 这个 label (Query 的 --query.replica-label 也要加上这个) 来实现 Receiver 的高可用。 Query 要指定 Receiver 后端地址: --store=dnssrv+_grpc._tcp.thanos-receive.thanos.svc.cluster.local request, limit 根据自身规模情况自行做适当调整。 --tsdb.retention 根据自身需求调整最新数据的保留时间。 如果改命名空间，记得把 Receiver 的 --receive.local-endpoint 参数也改下，不然会疯狂报错直至 OOMKilled。  因为使用了 Receiver 来统一接收 Prometheus 的数据，所以 Prometheus 也不需要 Sidecar 了，但需要给 Prometheus 配置文件里加下 remote_write，让 Prometheus 将数据 push 给 Receiver:\nremote_write: - url: http://thanos-receive.thanos.svc.cluster.local:19291/api/v1/receive 指定 Query 为数据源 查询监控数据时需要指定 Prometheus 数据源地址，由于我们使用了 Thanos 来做分布式，而 Thanos 关键查询入口就是 Query，所以我们需要将数据源地址指定为 Query 的地址，假如使用 Grafana 查询，进入 Configuration-Data Sources-Add data source，选择 Prometheus，指定 thanos query 的地址: http://thanos-query.thanos.svc.cluster.local:9090\n总结 本文教了大家如何选型 Thanos 部署方案并详细讲解了各个组件的安装方法，如果仔细阅读完本系列文章，我相信你已经有能力搭建并运维一套大型监控系统了。\n"
},
{
	"uri": "https://k8s.imroc.io/bigdata-ai/flink-on-kubernetes/job-cluster/",
	"title": "Job Cluster 模式部署",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/ingress/nginx-ingress/",
	"title": "Nginx Ingress",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/ingress/traefik-ingress/use-traefik-to-support-login/",
	"title": "使用 Traefik V2 让你的后台管理页面支持登录",
	"tags": [],
	"description": "",
	"content": "我们安装的应用，它们的后台管理页面很多不支持用户登录(认证)，所以没有将其暴露出来对外提供访问，我们经常用 kubectl proxy 的方式来访问，这样比较不方便。\n这里以 Traefik 本身的后台管理页面为例，将其加上 basic auth 登录才允许访问。\n创建用户名密码：\nUSERNAME=roc PASSWORD=mypassword 创建 Secret:\nUSERS=$(htpasswd -nb USERNAME PASSWORD) cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: Secret metadata: name: authsecret namespace: kube-system type: Opaque stringData: users: ${USERS} EOF 创建 Middleware:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: traefik.containo.us/v1alpha1 kind: Middleware metadata: name: roc-auth namespace: kube-system spec: basicAuth: secret: authsecret EOF 创建 IngressRoute，引用 Middleware:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute name: traefik-dashboard namespace: kube-system spec: entryPoints: - websecure routes: - kind: Rule match: Host(`traefik.imroc.io`) \u0026amp;\u0026amp; (PathPrefix(`/dashboard`) || PathPrefix(`/api`)) services: - kind: TraefikService name: api@internal middlewares: - name: roc-auth tls: secretName: traefik-imroc-io-tls EOF 打开浏览器，进入 traefik 后台管理页面： https://traefik.imroc.io/dashboard/，通常浏览器检测到401会自动弹出简单的登录框，我们输入用户名密码即可进入管理页面。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/",
	"title": "节点排错",
	"tags": [],
	"description": "",
	"content": "本章包含各种经典报错，分析可能原因并给出相应的解决方案\n arp_cache: neighbor table overflow! (arp缓存溢出)   Cannot allocate memory   no space left on device   Node NotReady   soft lockup (内核软死锁)   "
},
{
	"uri": "https://k8s.imroc.io/bigdata-ai/flink-on-kubernetes/native-kubernetes/",
	"title": "Native Kubernetes 模式部署",
	"tags": [],
	"description": "",
	"content": "与 Kubernetes 集成 在 flink 1.10 之前，在 k8s 上运行 flink 任务都是需要事先指定 TaskManager 的个数以及CPU和内存的，存在一个问题：大多数情况下，你在任务启动前根本无法精确的预估这个任务需要多少个TaskManager，如果指定多了，会导致资源浪费，指定少了，会导致任务调度不起来。本质原因是在 Kubernetes 上运行的 Flink 任务并没有直接向 Kubernetes 集群去申请资源。\n在 2020-02-11 发布了 flink 1.10，该版本完成了与 k8s 集成的第一阶段，实现了向 k8s 动态申请资源，就像跟 yarn 或 mesos 集成那样。\n部署步骤 确定 flink 部署的 namespace，这里我选 \u0026ldquo;flink\u0026rdquo;，确保 namespace 已创建:\nkubectl create ns flink 创建 RBAC (创建 ServiceAccount 绑定 flink 需要的对 k8s 集群操作的权限):\napiVersion: v1 kind: ServiceAccount metadata: name: flink namespace: flink --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: flink-role-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: edit subjects: - kind: ServiceAccount name: flink namespace: flink 利用 job 运行启动 flink 的引导程序 (请求 k8s 创建 jobmanager 相关的资源: service, deployment, configmap):\napiVersion: batch/v1 kind: Job metadata: name: boot-flink namespace: flink spec: template: spec: serviceAccount: flink restartPolicy: OnFailure containers: - name: start image: flink:1.10 workingDir: /opt/flink command: [\u0026#34;bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;$FLINK_HOME/bin/kubernetes-session.sh \\ -Dkubernetes.cluster-id=roc \\ -Dkubernetes.jobmanager.service-account=flink \\ -Dtaskmanager.memory.process.size=1024m \\ -Dkubernetes.taskmanager.cpu=1 \\ -Dtaskmanager.numberOfTaskSlots=1 \\ -Dkubernetes.container.image=flink:1.10 \\ -Dkubernetes.namespace=flink\u0026#34;]  kubernetes.cluster-id: 指定 flink 集群的名称，后续自动创建的 k8s 资源会带上这个作为前缀或后缀 kubernetes.namespace: 指定 flink 相关的资源创建在哪个命名空间，这里我们用 flink 命名空间 kubernetes.jobmanager.service-account: 指定我们刚刚为 flink 创建的 ServiceAccount kubernetes.container.image: 指定 flink 需要用的镜像，这里我们部署的 1.10 版本，所以镜像用 flink:1.10  部署完成后，我们可以看到有刚刚运行完成的 job 的 pod 和被这个 job 拉起的 flink jobmanager 的 pod，前缀与配置 kubernetes.cluster-id 相同:\n$ kubectl -n flink get pod NAME READY STATUS RESTARTS AGE roc-cf9f6b5df-csk9z 1/1 Running 0 84m boot-flink-nc2qx 0/1 Completed 0 84m 还有 jobmanager 的 service:\n$ kubectl -n flink get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE roc ClusterIP 172.16.255.152 \u0026lt;none\u0026gt; 8081/TCP,6123/TCP,6124/TCP 88m roc-rest LoadBalancer 172.16.255.11 150.109.27.251 8081:31240/TCP 88m 访问 http://150.109.27.251:8081 即可进入此 flink 集群的 ui 界面。\n参考资料  Active Kubernetes integration phase 2 - Advanced Features: https://issues.apache.org/jira/browse/FLINK-14460 Apache Flink 1.10.0 Release Announcement: https://flink.apache.org/news/2020/02/11/release-1.10.0.html Native Kubernetes Setup Beta (flink与kubernetes集成的官方教程): https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/deployment/native_kubernetes.html  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/",
	"title": "Pod 排错",
	"tags": [],
	"description": "",
	"content": "本文是本书排查指南板块下问题排查章节的 Pod排错 一节，介绍 Pod 各种异常现象，可能的原因以及解决方法。\n常用命令 排查过程常用的命名如下:\n 查看 Pod 状态: kubectl get pod \u0026lt;pod-name\u0026gt; -o wide 查看 Pod 的 yaml 配置: kubectl get pod \u0026lt;pod-name\u0026gt; -o yaml 查看 Pod 事件: kubectl describe pod \u0026lt;pod-name\u0026gt; 查看容器日志: kubectl logs \u0026lt;pod-name\u0026gt; [-c \u0026lt;container-name\u0026gt;]  Pod 状态 Pod 有多种状态，这里罗列一下:\n Error: Pod 启动过程中发生错误 NodeLost: Pod 所在节点失联 Unkown: Pod 所在节点失联或其它未知异常 Waiting: Pod 等待启动 Pending: Pod 等待被调度 ContainerCreating: Pod 容器正在被创建 Terminating: Pod 正在被销毁 CrashLoopBackOff： 容器退出，kubelet 正在将它重启 InvalidImageName： 无法解析镜像名称 ImageInspectError： 无法校验镜像 ErrImageNeverPull： 策略禁止拉取镜像 ImagePullBackOff： 正在重试拉取 RegistryUnavailable： 连接不到镜像中心 ErrImagePull： 通用的拉取镜像出错 CreateContainerConfigError： 不能创建 kubelet 使用的容器配置 CreateContainerError： 创建容器失败 RunContainerError： 启动容器失败 PreStartHookError: 执行 preStart hook 报错 PostStartHookError： 执行 postStart hook 报错 ContainersNotInitialized： 容器没有初始化完毕 ContainersNotReady： 容器没有准备完毕 ContainerCreating：容器创建中 PodInitializing：pod 初始化中 DockerDaemonNotReady：docker还没有完全启动 NetworkPluginNotReady： 网络插件还没有完全启动  问题导航 有时候我们无法直接通过异常状态找到异常原因，这里我们罗列一下各种现象，点击即可进入相应的文章，帮助你分析问题，罗列各种可能的原因，进一步定位根因:\n Pod Terminating 慢   Pod 一直处于 ContainerCreating 或 Waiting 状态   Pod 一直处于 Error 状态   Pod 一直处于 ImageInspectError 状态   Pod 一直处于 ImagePullBackOff 状态   Pod 一直处于 Pending 状态   Pod 一直处于 Terminating 状态   Pod 一直处于 Unknown 状态   Pod 健康检查失败   Pod 处于 CrashLoopBackOff 状态   容器进程主动退出   "
},
{
	"uri": "https://k8s.imroc.io/ingress/traefik-ingress/",
	"title": "Traefik Ingress",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/security/",
	"title": "安全指南",
	"tags": [],
	"description": "",
	"content": "目录  用户管理    利用 CSR API 创建用户      集群权限控制    控制应用权限     控制用户权限      集群证书管理    安装 cert-manager     使用 cert-manager 自动生成证书      "
},
{
	"uri": "https://k8s.imroc.io/best-practice/",
	"title": "最佳实践",
	"tags": [],
	"description": "",
	"content": "目录  服务部署最佳实践    如何合理利用资源     如何提高服务可用性      ETCD 优化     Master 优化     内核参数优化     "
},
{
	"uri": "https://k8s.imroc.io/deploy/addons/",
	"title": "附加组件",
	"tags": [],
	"description": "",
	"content": "目录  以 Daemonset 方式部署 kube-proxy   部署 CoreDNS   "
},
{
	"uri": "https://k8s.imroc.io/trick/",
	"title": "奇技淫巧",
	"tags": [],
	"description": "",
	"content": "  kubectl 高效技巧   yaml 片段   在容器内使用 perf   实用命令与脚本   泛域名动态转发 Service   "
},
{
	"uri": "https://k8s.imroc.io/monitoring/",
	"title": "监控指南",
	"tags": [],
	"description": "",
	"content": "由浅入深，平滑学习曲线让你快速掌握云原生监控系统的搭建与使用。\n 使用 kube-promethues 快速上手集群监控     打造云原生大型分布式监控系统    大规模场景下 Prometheus 的优化手段   Thanos 架构详解   Thanos 部署与实践    PromQL 技巧     "
},
{
	"uri": "https://k8s.imroc.io/log/",
	"title": "日志收集",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/",
	"title": "网络排错",
	"tags": [],
	"description": "",
	"content": "  网络排错手册   DNS 解析异常   LB 健康检查失败   Service 不通   Service 无法解析   网络性能差   "
},
{
	"uri": "https://k8s.imroc.io/bigdata-ai/",
	"title": "大数据与 AI",
	"tags": [],
	"description": "",
	"content": "目录  Flink on Kubernetes   "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/",
	"title": "其它排错",
	"tags": [],
	"description": "",
	"content": "  APIServer 响应慢   Daemonset 没有被调度   Job 无法被删除   kubectl 执行 exec 或 logs 失败   Namespace 卡在 Terminating   Node 全部消失   "
},
{
	"uri": "https://k8s.imroc.io/dev/",
	"title": "开发指南",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/monitoring/build-cloud-native-large-scale-distributed-monitoring-system/",
	"title": "打造云原生大型分布式监控系统",
	"tags": [],
	"description": "",
	"content": "  大规模场景下 Prometheus 的优化手段     Thanos 架构详解     Thanos 部署与实践     "
},
{
	"uri": "https://k8s.imroc.io/monitoring/promql/",
	"title": "PromQL 技巧",
	"tags": [],
	"description": "",
	"content": "复制标签名 pod_name \u0026ndash;\u0026gt; pod:\nlabel_replace( container_cpu_system_seconds_total, \u0026quot;pod\u0026quot;, \u0026quot;$1\u0026quot;, \u0026quot;pod_name\u0026quot;, \u0026quot;(.*)\u0026quot; ) 新标签名跟其它指标:\nsum by (pod)( irate( ( label_replace( container_cpu_system_seconds_total{container_name!=\u0026quot;\u0026quot;}, \u0026quot;pod\u0026quot;, \u0026quot;$1\u0026quot;, \u0026quot;pod_name\u0026quot;, \u0026quot;(.*)\u0026quot; ) * on (namespace,pod) group_left(workload,workload_type) mixin_pod_workload{namespace=\u0026quot;$namespace\u0026quot;, workload=~\u0026quot;$workload\u0026quot;, workload_type=~\u0026quot;$workload_type\u0026quot;} )[1m:15s] ) ) "
},
{
	"uri": "https://k8s.imroc.io/avoid/dotnet-configuration-auto-reload/",
	"title": ".Net Core 配置文件在Kubernetes中无法热加载",
	"tags": [],
	"description": "",
	"content": "问题描述 在使用 kubernetes 部署应用时, 我使用 kubernetes 的 configmap 来管理配置文件: appsettings.json , 修改configmap 的配置文件后, 我来到了容器里, 通过 cat /app/config/appsetting.json 命令查看容器是否已经加载了最新的配置文件, 很幸运的是, 通过命令行查看容器配置发现已经处于最新状态(修改configmap后10-15s 生效), 我尝试请求应用的API, 发现API 在执行过程中使用的配置是老旧的内容, 而不是最新的内容。在本地执行应用时并未出现配置无法热更新的问题。\n# 相关版本 kubernetes 版本: 1.14.2 # 要求版本大于等于 3.1 .Net core: 3.1 # 容器 os-release (并非 windows) NAME=\u0026#34;Debian GNU/Linux\u0026#34; VERSION_ID=\u0026#34;10\u0026#34; VERSION=\u0026#34;10 (buster)\u0026#34; VERSION_CODENAME=buster ID=debian HOME_URL=\u0026#34;https://www.debian.org/\u0026#34; SUPPORT_URL=\u0026#34;https://www.debian.org/support\u0026#34; BUG_REPORT_URL=\u0026#34;https://bugs.debian.org/\u0026#34; # 基础镜像: mcr.microsoft.com/dotnet/core/sdk:3.1-buster mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim 问题猜想 通过命令行排查发现最新的 configmap 配置内容已经在容器的指定目录上更新到最新，但是应用仍然使用老旧的配置内容, 这意味着问题发生在: configmap-\u0026gt;容器-\u0026gt;应用, 容器和应用之间, 容器指定目录下的配置更新并没有触发 .Net 热加载机制, 那究竟是为什么没有触发配置热加载,需要深挖根本原因, 直觉猜想是: 查看 .Net Core 标准库的配置热加载的实现检查触发条件, 很有可能是触发的条件不满足导致应用配置无法重新加载。\n问题排查 猜想方向是热更新的触发条件不满足, 我们熟知使用 configmap 挂载文件是使用symlink来挂载, 而非常用的物理文件系统, 在修改完 configmap , 容器重新加载配置后,这一过程并不会改变文件的修改时间等信息(从容器的角度看)。对此，我们做了一个实验,通过对比configmap修改前和修改后来观察配置( appsettings.json )在容器的属性变化(注: 均在容器加载最新配置后对比), 使用 stat 命令来佐证了这个细节点。\nBefore:\nroot@app-785bc59df6-gdmnf:/app/Config# stat appsettings.json File: Config/appsettings.json -\u0026gt; ..data/appsettings.json Size: 35 Blocks: 0 IO Block: 4096 symbolic link Device: ca01h/51713d Inode: 27263079 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2020-04-25 08:21:18.490453316 +0000 Modify: 2020-04-25 08:21:18.490453316 +0000 Change: 2020-04-25 08:21:18.490453316 +0000 Birth: - After:\nroot@app-785bc59df6-gdmnf:/app/Config# stat appsettings.json File: appsettings.json -\u0026gt; ..data/appsettings.json Size: 35 Blocks: 0 IO Block: 4096 symbolic link Device: ca01h/51713d Inode: 27263079 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2020-04-25 08:21:18.490453316 +0000 Modify: 2020-04-25 08:21:18.490453316 +0000 Change: 2020-04-25 08:21:18.490453316 +0000 Birth: - 通过标准库源码发现, .Net core 配置热更新机制似乎是基于文件的最后修改日期来触发的, 根据上面的前后对比显而易见, configmap 的修改并没有让容器里的指定的文件的最后修改日期改变，也就未触发 .Net 应用配置的热加载。\n解决办法 既然猜想基本得到证实, 由于不太熟悉这门语言, 我们尝试在网络上寻找解决办法，很幸运的是我们找到了找到了相关的内容, fbeltrao 开源了一个第三方库(ConfigMapFileProvider) 来专门解决这个问题，通过监听文件内容hash值的变化实现配置热加载。 于是, 我们在修改了项目的代码:\nBefore:\n// 配置被放在了/app/Config/ 目录下 var configPath = Path.Combine(env.ContentRootPath, \u0026#34;Config\u0026#34;); config.AddJsonFile(Path.Combine(configPath, \u0026#34;appsettings.json\u0026#34;), optional: false, reloadOnChange: true); After:\n// 配置被放在了/app/Config/ 目录下 config.AddJsonFile(ConfigMapFileProvider.FromRelativePath(\u0026#34;Config\u0026#34;), \u0026#34;appsettings.json\u0026#34;, optional: false, reloadOnChange: true); 修改完项目的代码后, 重新构建镜像, 更新部署在 kubernetes 上的应用, 然后再次测试, 到此为止, 会出现两种状态:\n 一种是你热加载配置完全可用, 非常值得祝贺, 你已经成功修复了这个bug; 一种是你的热加载配置功能还存在 bug, 比如: 上一次请求, 配置仍然使用的老旧配置内容, 下一次请求却使用了最新的配置内容,这个时候, 我们需要继续向下排查: .NET Core 引入了Options模式，使用类来表示相关的设置组,用强类型的类来表达配置项(白话大概表述为: 代码里面有个对象对应配置里的某个字段, 配置里对应的字段更改会触发代码里对象的属性变化), 示例如下:  配置示例:\ncat appsettings.json \u0026#34;JwtIssuerOptions\u0026#34;: { \u0026#34;Issuer\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;Audience\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;SecretKey\u0026#34;: \u0026#34;test\u0026#34; ... } 代码示例:\nservices.Configure\u0026lt;JwtIssuerOptions\u0026gt;(Configuration.GetSection(\u0026#34;JwtIssuerOptions\u0026#34;)); 而 Options 模式分为三种:\n IOptions: Singleton(单例)，值一旦生成, 除非通过代码的方式更改，否则它的值不会更新 IOptionsMonitor: Singleton(单例), 通过IOptionsChangeTokenSource\u0026lt;\u0026gt; 能够和配置文件一起更新，也能通过代码的方式更改值 IOptionsSnapshot: Scoped，配置文件更新的下一次访问，它的值会更新，但是它不能跨范围通过代码的方式更改值，只能在当前范围（请求）内有效。  在知道这三种模式的意义后，我们已经完全找到了问题的根因, 把 Options 模式设置为:IOptionsMonitor就能解决完全解决配置热加载的问题。\n相关链接  配置监听ConfigMapFileProvider 相似的Issue: 1175 官方Options 描述 IOptions、IOptionsMonitor以及IOptionsSnapshot 测试  "
},
{
	"uri": "https://k8s.imroc.io/",
	"title": "Kubernetes 实践指南",
	"tags": [],
	"description": "",
	"content": " 本书还正在起草，部分内容还不太成熟，请关注文章头部的成熟度提示，无提示的表示已成熟\n 目录  注：不能点击的标题是还正在路上的内容\n  部署指南    方案选型     使用 kubespray 部署     手工部署    部署前的准备工作     部署 ETCD     部署 Master     部署 Worker 节点     部署关键组件      附加组件    以 Daemonset 方式部署 kube-proxy     部署 CoreDNS      附录    安装 kubectl       Ingress 指南    彻底理解 Ingress     Ingress 方案选型     Nginx Ingress    安装 nginx ingress controller      Traefik Ingress    安装 traefik ingress controller     使用 Traefik V2 让你的后台管理页面支持登录       Metrics 指南     配置管理    使用 Helm 管理集群资源    安装 Helm     Helm V2 迁移到 V3     Helm 常见问题       排错指南    排错技巧    分析 ExitCode 定位 Pod 异常退出原因     使用 Systemtap 定位疑难杂症     容器内抓包定位网络问题      处理实践    arp_cache 溢出     inotify watch 耗尽     PID 耗尽     内存碎片化     磁盘爆满     高负载      节点排错    arp_cache: neighbor table overflow! (arp缓存溢出)     Cannot allocate memory     no space left on device     Node NotReady     soft lockup (内核软死锁)      Pod 排错    Pod Terminating 慢     Pod 一直处于 ContainerCreating 或 Waiting 状态     Pod 一直处于 Error 状态     Pod 一直处于 ImageInspectError 状态     Pod 一直处于 ImagePullBackOff 状态     Pod 一直处于 Pending 状态     Pod 一直处于 Terminating 状态     Pod 一直处于 Unknown 状态     Pod 健康检查失败     Pod 处于 CrashLoopBackOff 状态     容器进程主动退出      网络排错    网络排错手册     DNS 解析异常     LB 健康检查失败     Service 不通     Service 无法解析     网络性能差      其它排错    APIServer 响应慢     Daemonset 没有被调度     Job 无法被删除     kubectl 执行 exec 或 logs 失败     Namespace 卡在 Terminating     Node 全部消失       避坑指南    .Net Core 配置文件在Kubernetes中无法热加载     cgroup 泄露     conntrack 冲突导致丢包     tcp tw recycle 引发丢包     使用 NodeLocal DNS (缓存)     使用 oom-guard 在用户态处理 cgroup OOM     解决长连接服务扩容失效     踩坑分享    ARP 缓存爆满导致健康检查失败     DNS 5 秒延时     DNS 解析异常     kubectl edit 或者 apply 报 SchemaError     LB 压测 NodePort CPS 低     Pod 偶尔存活检查失败     Pod 访问另一个集群的 apiserver 有延时     神秘的溢出与丢包     访问 externalTrafficPolicy 为 Local 的 Service 对应 LB 有时超时     诡异的 No route to host     跨 VPC 访问 NodePort 经常超时     驱逐导致服务中断       安全指南    用户管理    利用 CSR API 创建用户      集群权限控制    控制应用权限     控制用户权限      集群证书管理    安装 cert-manager     使用 cert-manager 自动生成证书       最佳实践    服务部署最佳实践    如何合理利用资源     如何提高服务可用性      ETCD 优化     Master 优化     内核参数优化      奇技淫巧    kubectl 高效技巧     yaml 片段    Deployment     亲和与反亲和      在容器内使用 perf     实用命令与脚本    Pod 相关脚本     网络调试相关脚本     节点相关脚本      泛域名动态转发 Service      监控指南    使用 kube-promethues 快速上手集群监控     打造云原生大型分布式监控系统    大规模场景下 Prometheus 的优化手段     Thanos 架构详解     Thanos 部署与实践      PromQL 技巧      日志收集    利用 Loki/Promtail/Grafana 收集分析日志      大数据与 AI    Flink on Kubernetes    Flink 介绍     Flink on Kubernetes 方案     Session Cluster 模式部署     Job Cluster 模式部署     Native Kubernetes 模式部署       开发指南    Go 语言编译原理与优化     使用 client-go 开发 k8s 应用      References          在线阅读 本书将支持中英文两个语言版本，通常文章会先用中文起草并更新，等待其内容较为成熟完善，更新不再频繁的时候才会翻译成英文，点击左上角切换语言。\n 中文: https://k8s.imroc.io English: https://k8s.imroc.io/en  项目源码 项目源码存放于 Github 上: https://github.com/imroc/kubernetes-practice-guide\n贡献 欢迎参与贡献和完善内容，贡献方法参考 CONTRIBUTING\nLicense 署名-非商业性使用-相同方式共享 4.0 (CC BY-NC-SA 4.0)\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/trick/analysis-exitcode/",
	"title": "分析 ExitCode 定位 Pod 异常退出原因",
	"tags": [],
	"description": "",
	"content": "使用 kubectl describe pod \u0026lt;pod name\u0026gt; 查看异常 pod 的状态:\nContainers: kubedns: Container ID: docker://5fb8adf9ee62afc6d3f6f3d9590041818750b392dff015d7091eaaf99cf1c945 Image: ccr.ccs.tencentyun.com/library/kubedns-amd64:1.14.4 Image ID: docker-pullable://ccr.ccs.tencentyun.com/library/kubedns-amd64@sha256:40790881bbe9ef4ae4ff7fe8b892498eecb7fe6dcc22661402f271e03f7de344 Ports: 10053/UDP, 10053/TCP, 10055/TCP Host Ports: 0/UDP, 0/TCP, 0/TCP Args: --domain=cluster.local. --dns-port=10053 --config-dir=/kube-dns-config --v=2 State: Running Started: Tue, 27 Aug 2019 10:58:49 +0800 Last State: Terminated Reason: Error Exit Code: 255 Started: Tue, 27 Aug 2019 10:40:42 +0800 Finished: Tue, 27 Aug 2019 10:58:27 +0800 Ready: True Restart Count: 1 在容器列表里看 Last State 字段，其中 ExitCode 即程序上次退出时的状态码，如果不为 0，表示异常退出，我们可以分析下原因。\n退出状态码的区间  必须在 0-255 之间 0 表示正常退出 外界中断将程序退出的时候状态码区间在 129-255，(操作系统给程序发送中断信号，比如 kill -9 是 SIGKILL，ctrl+c 是 SIGINT) 一般程序自身原因导致的异常退出状态区间在 1-128 (这只是一般约定，程序如果一定要用129-255的状态码也是可以的)  假如写代码指定的退出状态码时不在 0-255 之间，例如: exit(-1)，这时会自动做一个转换，最终呈现的状态码还是会在 0-255 之间。我们把状态码记为 code\n 当指定的退出时状态码为负数，那么转换公式如下:  256 - (|code| % 256)  当指定的退出时状态码为正数，那么转换公式如下:  code % 256 常见异常状态码  137 (被 SIGKILL 中断信号杀死)   此状态码一般是因为 pod 中容器内存达到了它的资源限制(resources.limits)，一般是内存溢出(OOM)，CPU达到限制只需要不分时间片给程序就可以。因为限制资源是通过 linux 的 cgroup 实现的，所以 cgroup 会将此容器强制杀掉，类似于 kill -9，此时在 describe pod 中可以看到 Reason 是 OOMKilled\n  还可能是宿主机本身资源不够用了(OOM)，内核会选取一些进程杀掉来释放内存\n  不管是 cgroup 限制杀掉进程还是因为节点机器本身资源不够导致进程死掉，都可以从系统日志中找到记录:\n ubuntu 的系统日志在 /var/log/syslog，centos 的系统日志在 /var/log/messages，都可以用 journalctl -k 来查看系统日志\n   也可能是 livenessProbe (存活检查) 失败，kubelet 杀死的 pod\n  还可能是被恶意木马进程杀死\n   1 和 255  这种可能是一般错误，具体错误原因只能看容器日志，因为很多程序员写异常退出时习惯用 exit(1) 或 exit(-1)，-1 会根据转换规则转成 255    状态码参考 这里罗列了一些状态码的含义：Appendix E. Exit Codes With Special Meanings\nLinux 标准中断信号 Linux 程序被外界中断时会发送中断信号，程序退出时的状态码就是中断信号值加上 128 得到的，比如 SIGKILL 的中断信号值为 9，那么程序退出状态码就为 9+128=137。以下是标准信号值参考：\nSignal Value Action Comment ────────────────────────────────────────────────────────────────────── SIGHUP 1 Term Hangup detected on controlling terminal or death of controlling process SIGINT 2 Term Interrupt from keyboard SIGQUIT 3 Core Quit from keyboard SIGILL 4 Core Illegal Instruction SIGABRT 6 Core Abort signal from abort(3) SIGFPE 8 Core Floating-point exception SIGKILL 9 Term Kill signal SIGSEGV 11 Core Invalid memory reference SIGPIPE 13 Term Broken pipe: write to pipe with no readers; see pipe(7) SIGALRM 14 Term Timer signal from alarm(2) SIGTERM 15 Term Termination signal SIGUSR1 30,10,16 Term User-defined signal 1 SIGUSR2 31,12,17 Term User-defined signal 2 SIGCHLD 20,17,18 Ign Child stopped or terminated SIGCONT 19,18,25 Cont Continue if stopped SIGSTOP 17,19,23 Stop Stop process SIGTSTP 18,20,24 Stop Stop typed at terminal SIGTTIN 21,21,26 Stop Terminal input for background process SIGTTOU 22,22,27 Stop Terminal output for background process C/C++ 退出状态码 /usr/include/sysexits.h 试图将退出状态码标准化(仅限 C/C++):\n#define EX_OK 0 /* successful termination */ #define EX__BASE 64 /* base value for error messages */ #define EX_USAGE 64 /* command line usage error */ #define EX_DATAERR 65 /* data format error */ #define EX_NOINPUT 66 /* cannot open input */ #define EX_NOUSER 67 /* addressee unknown */ #define EX_NOHOST 68 /* host name unknown */ #define EX_UNAVAILABLE 69 /* service unavailable */ #define EX_SOFTWARE 70 /* internal software error */ #define EX_OSERR 71 /* system error (e.g., can\u0026#39;t fork) */ #define EX_OSFILE 72 /* critical OS file missing */ #define EX_CANTCREAT 73 /* can\u0026#39;t create (user) output file */ #define EX_IOERR 74 /* input/output error */ #define EX_TEMPFAIL 75 /* temp failure; user is invited to retry */ #define EX_PROTOCOL 76 /* remote error in protocol */ #define EX_NOPERM 77 /* permission denied */ #define EX_CONFIG 78 /* configuration error */ #define EX__MAX 78 /* maximum listed value */ "
},
{
	"uri": "https://k8s.imroc.io/reference/net-shell/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "网络排障脚本 观察是否有 conntrack 冲突 watch -n1 \u0026lsquo;conntrack -S | awk -F = \u0026ldquo;{print $7}\u0026rdquo; | awk \u0026ldquo;{sum += $1} END {print sum}\u0026quot;\u0026rsquo;\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/slow-apiserver/",
	"title": "APIServer 响应慢",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/arp-cache-overflow-causes-healthcheck-failed/",
	"title": "ARP 缓存爆满导致健康检查失败",
	"tags": [],
	"description": "",
	"content": "案例 TKE 一用户某集群节点数 1200+，用户监控方案是 daemonset 部署 node-exporter 暴露节点监控指标，使用 hostNework 方式，statefulset 部署 promethues 且仅有一个实例，落在了一个节点上，promethues 请求所有节点 node-exporter 获取节点监控指标，也就是或扫描所有节点，导致 arp cache 需要存所有 node 的记录，而节点数 1200+，大于了 net.ipv4.neigh.default.gc_thresh3 的默认值 1024，这个值是个硬限制，arp cache记录数大于这个就会强制触发 gc，所以会造成频繁gc，当有数据包发送会查本地 arp，如果本地没找到 arp 记录就会判断当前 arp cache 记录数+1是否大于 gc_thresh3，如果没有就会广播 arp 查询 mac 地址，如果大于了就直接报 arp_cache: neighbor table overflow!，并且放弃 arp 请求，无法获取 mac 地址也就无法知道探测报文该往哪儿发(即便就在本机某个 veth pair)，kubelet 对本机 pod 做存活检查发 arp 查 mac 地址，在 arp cahce 找不到，由于这时 arp cache已经满了，刚要 gc 但还没做所以就只有报错丢包，导致存活检查失败重启 pod\n解决方案 调整部分节点内核参数，将 arp cache 的 gc 阀值调高 (/etc/sysctl.conf):\nnet.ipv4.neigh.default.gc_thresh1 = 80000 net.ipv4.neigh.default.gc_thresh2 = 90000 net.ipv4.neigh.default.gc_thresh3 = 100000 并给 node 打下label，修改 pod spec，加下 nodeSelector 或者 nodeAffnity，让 pod 只调度到这部分改过内核参数的节点，更多请参考本书 处理实践: arp_cache 溢出\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/arp_cache-overflow/",
	"title": "arp_cache 溢出",
	"tags": [],
	"description": "",
	"content": "如何判断 arp_cache 溢出？ 内核日志会有有下面的报错:\narp_cache: neighbor table overflow! 查看当前 arp 记录数:\n$ arp -an | wc -l 1335 查看 arp gc 阀值:\n$ sysctl -a | grep gc_thresh net.ipv4.neigh.default.gc_thresh1 = 128 net.ipv4.neigh.default.gc_thresh2 = 512 net.ipv4.neigh.default.gc_thresh3 = 1024 net.ipv6.neigh.default.gc_thresh1 = 128 net.ipv6.neigh.default.gc_thresh2 = 512 net.ipv6.neigh.default.gc_thresh3 = 1024 当前 arp 记录数接近 gc_thresh3 比较容易 overflow，因为当 arp 记录达到 gc_thresh3 时会强制触发 gc 清理，当这时又有数据包要发送，并且根据目的 IP 在 arp cache 中没找到 mac 地址，这时会判断当前 arp cache 记录数加 1 是否大于 gc_thresh3，如果没有大于就会 时就会报错: arp_cache: neighbor table overflow!\n解决方案 调整节点内核参数，将 arp cache 的 gc 阀值调高 (/etc/sysctl.conf):\nnet.ipv4.neigh.default.gc_thresh1 = 80000 net.ipv4.neigh.default.gc_thresh2 = 90000 net.ipv4.neigh.default.gc_thresh3 = 100000 分析是否只是部分业务的 Pod 的使用场景需要节点有比较大的 arp 缓存空间。\n如果不是，就需要调整所有节点内核参数。\n如果是，可以将部分 Node 打上标签，比如:\nkubectl label node host1 arp_cache=large 然后用 nodeSelector 或 nodeAffnity 让这部分需要内核有大 arp_cache 容量的 Pod 只调度到这部分节点，推荐使用 nodeAffnity，yaml 示例:\ntemplate: spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: arp_cache operator: In values: - large "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/arp_cache-neighbor-table-overflow/",
	"title": "arp_cache: neighbor table overflow! (arp缓存溢出)",
	"tags": [],
	"description": "",
	"content": "节点内核报这个错说明当前节点 arp 缓存满了。\n查看当前 arp 记录数:\n$ arp -an | wc -l 1335 查看 gc 阀值:\n$ sysctl -a | grep net.ipv4.neigh.default.gc_thresh net.ipv4.neigh.default.gc_thresh1 = 128 net.ipv4.neigh.default.gc_thresh2 = 512 net.ipv4.neigh.default.gc_thresh3 = 1024 当前 arp 记录数接近 gc_thresh3 比较容易 overflow，因为当 arp 记录达到 gc_thresh3 时会强制触发 gc 清理，当这时又有数据包要发送，并且根据目的 IP 在 arp cache 中没找到 mac 地址，这时会判断当前 arp cache 记录数加 1 是否大于 gc_thresh3，如果没有大于就会 时就会报错: neighbor table overflow!\n什么场景下会发生 集群规模大，node 和 pod 数量超多，参考本书避坑宝典的 案例分享: ARP 缓存爆满导致健康检查失败\n解决方案 调整部分节点内核参数，将 arp cache 的 gc 阀值调高 (/etc/sysctl.conf):\nnet.ipv4.neigh.default.gc_thresh1 = 80000 net.ipv4.neigh.default.gc_thresh2 = 90000 net.ipv4.neigh.default.gc_thresh3 = 100000 并给 node 打下label，修改 pod spec，加下 nodeSelector 或者 nodeAffnity，让 pod 只调度到这部分改过内核参数的节点\n参考资料  Scaling Kubernetes to 2,500 Nodes: https://openai.com/blog/scaling-kubernetes-to-2500-nodes/  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/cannot-allocate-memory/",
	"title": "Cannot allocate memory",
	"tags": [],
	"description": "",
	"content": "容器启动失败，报错 Cannot allocate memory。\nPID 耗尽 如果登录 ssh 困难，并且登录成功后执行任意命名经常报 Cannot allocate memory，多半是 PID 耗尽了。\n处理方法参考本书 处理实践: PID 耗尽\n"
},
{
	"uri": "https://k8s.imroc.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/avoid/cgroup-leaking/",
	"title": "cgroup 泄露",
	"tags": [],
	"description": "",
	"content": "内核 Bug memcg 是 Linux 内核中用于管理 cgroup 内存的模块，整个生命周期应该是跟随 cgroup 的，但是在低版本内核中(已知3.10)，一旦给某个 memory cgroup 开启 kmem accounting 中的 memory.kmem.limit_in_bytes 就可能会导致不能彻底删除 memcg 和对应的 cssid，也就是说应用即使已经删除了 cgroup (/sys/fs/cgroup/memory 下对应的 cgroup 目录已经删除), 但在内核中没有释放 cssid，导致内核认为的 cgroup 的数量实际数量不一致，我们也无法得知内核认为的 cgroup 数量是多少。\n关于 cgroup kernel memory，在 kernel.org 中有如下描述：\n2.7 Kernel Memory Extension (CONFIG_MEMCG_KMEM) ----------------------------------------------- With the Kernel memory extension, the Memory Controller is able to limit the amount of kernel memory used by the system. Kernel memory is fundamentally different than user memory, since it can't be swapped out, which makes it possible to DoS the system by consuming too much of this precious resource. Kernel memory accounting is enabled for all memory cgroups by default. But it can be disabled system-wide by passing cgroup.memory=nokmem to the kernel at boot time. In this case, kernel memory will not be accounted at all. Kernel memory limits are not imposed for the root cgroup. Usage for the root cgroup may or may not be accounted. The memory used is accumulated into memory.kmem.usage_in_bytes, or in a separate counter when it makes sense. (currently only for tcp). The main \u0026quot;kmem\u0026quot; counter is fed into the main counter, so kmem charges will also be visible from the user counter. Currently no soft limit is implemented for kernel memory. It is future work to trigger slab reclaim when those limits are reached. 这是一个 cgroup memory 的扩展，用于限制对 kernel memory 的使用，但该特性在老于 4.0 版本中是个实验特性，存在泄露问题，在 4.x 较低的版本也还有泄露问题，应该是造成泄露的代码路径没有完全修复，推荐 4.3 以上的内核。\n造成容器创建失败 这个问题可能会导致创建容器失败，因为创建容器为其需要创建 cgroup 来做隔离，而低版本内核有个限制：允许创建的 cgroup 最大数量写死为 65535 (点我跳转到 commit)，如果节点上经常创建和销毁大量容器导致创建很多 cgroup，删除容器但没有彻底删除 cgroup 造成泄露(真实数量我们无法得知)，到达 65535 后再创建容器就会报创建 cgroup 失败并报错 no space left on device，使用 kubernetes 最直观的感受就是 pod 创建之后无法启动成功。\npod 启动失败，报 event 示例:\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 15m default-scheduler Successfully assigned jenkins/jenkins-7845b9b665-nrvks to 10.10.252.4 Warning FailedCreatePodContainer 25s (x70 over 15m) kubelet, 10.10.252.4 unable to ensure pod container exists: failed to create container for [kubepods besteffort podc6eeec88-8664-11e9-9524-5254007057ba] : mkdir /sys/fs/cgroup/memory/kubepods/besteffort/podc6eeec88-8664-11e9-9524-5254007057ba: no space left on device dockerd 日志报错示例:\nDec 24 11:54:31 VM_16_11_centos dockerd[11419]: time=\u0026#34;2018-12-24T11:54:31.195900301+08:00\u0026#34; level=error msg=\u0026#34;Handler for POST /v1.31/containers/b98d4aea818bf9d1d1aa84079e1688cd9b4218e008c58a8ef6d6c3c106403e7b/start returned error: OCI runtime create failed: container_linux.go:348: starting container process caused \\\u0026#34;process_linux.go:279: applying cgroup configuration for process caused \\\\\\\u0026#34;mkdir /sys/fs/cgroup/memory/kubepods/burstable/pod79fe803c-072f-11e9-90ca-525400090c71/b98d4aea818bf9d1d1aa84079e1688cd9b4218e008c58a8ef6d6c3c106403e7b: no space left on device\\\\\\\u0026#34;\\\u0026#34;: unknown\u0026#34; kubelet 日志报错示例:\nSep 09 18:09:09 VM-0-39-ubuntu kubelet[18902]: I0909 18:09:09.449722 18902 remote_runtime.go:92] RunPodSandbox from runtime service failed: rpc error: code = Unknown desc = failed to start sandbox container for pod \u0026#34;osp-xxx-com-ljqm19-54bf7678b8-bvz9s\u0026#34;: Error response from daemon: oci runtime error: container_linux.go:247: starting container process caused \u0026#34;process_linux.go:258: applying cgroup configuration for process caused \\\u0026#34;mkdir /sys/fs/cgroup/memory/kubepods/burstable/podf1bd9e87-1ef2-11e8-afd3-fa163ecf2dce/8710c146b3c8b52f5da62e222273703b1e3d54a6a6270a0ea7ce1b194f1b5053: no space left on device\\\u0026#34;\u0026#34; 新版的内核限制为 2^31 (可以看成几乎不限制，点我跳转到代码): cgroup_idr_alloc() 传入 end 为 0 到 idr_alloc()， 再传给 idr_alloc_u32(), end 的值最终被三元运算符 end\u0026gt;0 ? end-1 : INT_MAX 转成了 INT_MAX 常量，即 2^31。所以如果新版内核有泄露问题会更难定位，表现形式会是内存消耗严重，幸运的是新版内核已经修复，推荐 4.3 以上。\n规避方案 如果你用的低版本内核(比如 CentOS 7 v3.10 的内核)并且不方便升级内核，可以通过不开启 kmem accounting 来实现规避，但会比较麻烦。\nkubelet 和 runc 都会给 memory cgroup 开启 kmem accounting，所以要规避这个问题，就要保证kubelet 和 runc 都别开启 kmem accounting，下面分别进行说明:\nrunc runc 在合并 这个PR (2017-02-27) 之后创建的容器都默认开启了 kmem accounting，后来社区也注意到这个问题，并做了比较灵活的修复， PR 1921 给 runc 增加了 \u0026ldquo;nokmem\u0026rdquo; 编译选项，缺省的 release 版本没有使用这个选项， 自己使用 nokmem 选项编译 runc 的方法:\ncd $GO_PATH/src/github.com/opencontainers/runc/ make BUILDTAGS=\u0026#34;seccomp nokmem\u0026#34; docker-ce v18.09.1 之后的 runc 默认关闭了 kmem accounting，所以也可以直接升级 docker 到这个版本之后。\nkubelet 如果是 1.14 版本及其以上，可以在编译的时候通过 build tag 来关闭 kmem accounting:\nKUBE_GIT_VERSION=v1.14.1 ./build/run.sh make kubelet GOFLAGS=\u0026#34;-tags=nokmem\u0026#34; 如果是低版本需要修改代码重新编译。kubelet 在创建 pod 对应的 cgroup 目录时，也会调用 libcontianer 中的代码对 cgroup 做设置，在 pkg/kubelet/cm/cgroup_manager_linux.go 的 Create 方法中，会调用 Manager.Apply 方法，最终调用 vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go 中的 MemoryGroup.Apply 方法，开启 kmem accounting。这里也需要进行处理，可以将这部分代码注释掉然后重新编译 kubelet。\n参考资料  一行 kubernetes 1.9 代码引发的血案（与 CentOS 7.x 内核兼容性问题）: http://dockone.io/article/4797 Cgroup泄漏\u0026ndash;潜藏在你的集群中: https://tencentcloudcontainerteam.github.io/2018/12/29/cgroup-leaking/  "
},
{
	"uri": "https://k8s.imroc.io/avoid/conntrack-conflict/",
	"title": "conntrack 冲突导致丢包",
	"tags": [],
	"description": "",
	"content": "TODO\n"
},
{
	"uri": "https://k8s.imroc.io/cluster/runtime/containerd/",
	"title": "Containerd",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/daemonset-not-scheduled/",
	"title": "Daemonset 没有被调度",
	"tags": [],
	"description": "",
	"content": "Daemonset 的期望实例为 0，可能原因:\n controller-manager 的 bug，重启 controller-manager 可以恢复 controller-manager 挂了  "
},
{
	"uri": "https://k8s.imroc.io/trick/yaml/deployment/",
	"title": "Deployment",
	"tags": [],
	"description": "",
	"content": "最简单的 nginx 测试服务 apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx --- apiVersion: v1 kind: Service metadata: name: nginx labels: app: nginx spec: type: ClusterIP ports: - port: 80 protocol: TCP name: http selector: app: nginx "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/dns-lookup-5s-delay/",
	"title": "DNS 5 秒延时",
	"tags": [],
	"description": "",
	"content": "延时现象 客户反馈从 pod 中访问服务时，总是有些请求的响应时延会达到5秒。正常的响应只需要毫秒级别的时延。\n抓包  通过 nsenter 进入 pod netns，使用节点上的 tcpdump 抓 pod 中的包 (抓包方法参考这里)，发现是有的 DNS 请求没有收到响应，超时 5 秒后，再次发送 DNS 请求才成功收到响应。 在 kube-dns pod 抓包，发现是有 DNS 请求没有到达 kube-dns pod，在中途被丢弃了。  为什么是 5 秒？ man resolv.conf 可以看到 glibc 的 resolver 的缺省超时时间是 5s:\ntimeout:n Sets the amount of time the resolver will wait for a response from a remote name server before retrying the query via a different name server. Measured in seconds, the default is RES_TIMEOUT (currently 5, see \u0026lt;resolv.h\u0026gt;). The value for this option is silently capped to 30. 丢包原因 经过搜索发现这是一个普遍问题。\n根本原因是内核 conntrack 模块的 bug，netfilter 做 NAT 时可能发生资源竞争导致部分报文丢弃。\nWeave works的工程师 Martynas Pumputis 对这个问题做了很详细的分析：Racy conntrack and DNS lookup timeouts\n相关结论：\n 只有多个线程或进程，并发从同一个 socket 发送相同五元组的 UDP 报文时，才有一定概率会发生 glibc, musl(alpine linux的libc库)都使用 \u0026ldquo;parallel query\u0026rdquo;, 就是并发发出多个查询请求，因此很容易碰到这样的冲突，造成查询请求被丢弃 由于 ipvs 也使用了 conntrack, 使用 kube-proxy 的 ipvs 模式，并不能避免这个问题  问题的根本解决 Martynas 向内核提交了两个 patch 来 fix 这个问题，不过他说如果集群中有多个DNS server的情况下，问题并没有完全解决。\n其中一个 patch 已经在 2018-7-18 被合并到 linux 内核主线中: netfilter: nf_conntrack: resolve clash for matching conntracks\n目前只有4.19.rc 版本包含这个patch。\n规避办法 规避方案一：使用TCP发送DNS请求 由于TCP没有这个问题，有人提出可以在容器的resolv.conf中增加options use-vc, 强制glibc使用TCP协议发送DNS query。下面是这个man resolv.conf中关于这个选项的说明：\nuse-vc (since glibc 2.14) Sets RES_USEVC in _res.options. This option forces the use of TCP for DNS resolutions. 笔者使用镜像\u0026quot;busybox:1.29.3-glibc\u0026rdquo; (libc 2.24) 做了试验，并没有见到这样的效果，容器仍然是通过UDP发送DNS请求。\n规避方案二：避免相同五元组DNS请求的并发 resolv.conf还有另外两个相关的参数：\n single-request-reopen (since glibc 2.9) single-request (since glibc 2.10)  man resolv.conf中解释如下：\nsingle-request-reopen (since glibc 2.9) Sets RES_SNGLKUPREOP in _res.options. The resolver uses the same socket for the A and AAAA requests. Some hardware mistakenly sends back only one reply. When that happens the client system will sit and wait for the second reply. Turning this option on changes this behavior so that if two requests from the same port are not handled correctly it will close the socket and open a new one before sending the second request. single-request (since glibc 2.10) Sets RES_SNGLKUP in _res.options. By default, glibc performs IPv4 and IPv6 lookups in parallel since version 2.9. Some appliance DNS servers cannot handle these queries properly and make the requests time out. This option disables the behavior and makes glibc perform the IPv6 and IPv4 requests sequentially (at the cost of some slowdown of the resolving process). 用自己的话解释下：\n single-request-reopen: 发送 A 类型请求和 AAAA 类型请求使用不同的源端口，这样两个请求在 conntrack 表中不占用同一个表项，从而避免冲突 single-request: 避免并发，改为串行发送 A 类型和 AAAA 类型请求，没有了并发，从而也避免了冲突  要给容器的 resolv.conf 加上 options 参数，有几个办法：\n1) 在容器的 \u0026ldquo;ENTRYPOINT\u0026rdquo; 或者 \u0026ldquo;CMD\u0026rdquo; 脚本中，执行 /bin/echo \u0026lsquo;options single-request-reopen\u0026rsquo; \u0026gt;\u0026gt; /etc/resolv.conf\n2) 在 pod 的 postStart hook 中:\nlifecycle: postStart: exec: command: - /bin/sh - -c - \u0026#34;/bin/echo \u0026#39;options single-request-reopen\u0026#39; \u0026gt;\u0026gt; /etc/resolv.conf\u0026#34; 3) 使用 template.spec.dnsConfig (k8s v1.9 及以上才支持):\ntemplate: spec: dnsConfig: options: - name: single-request-reopen 4) 使用 ConfigMap 覆盖 pod 里面的 /etc/resolv.conf:\nconfigmap:\napiVersion: v1 data: resolv.conf: | nameserver 1.2.3.4 search default.svc.cluster.local svc.cluster.local cluster.local ec2.internal options ndots:5 single-request-reopen timeout:1 kind: ConfigMap metadata: name: resolvconf pod spec:\nvolumeMounts: - name: resolv-conf mountPath: /etc/resolv.conf subPath: resolv.conf ... volumes: - name: resolv-conf configMap: name: resolvconf items: - key: resolv.conf path: resolv.conf 5) 使用 MutatingAdmissionWebhook\nMutatingAdmissionWebhook 是 1.9 引入的 Controller，用于对一个指定的 Resource 的操作之前，对这个 resource 进行变更。 istio 的自动 sidecar注入就是用这个功能来实现的。 我们也可以通过 MutatingAdmissionWebhook，来自动给所有POD，注入以上3)或者4)所需要的相关内容。\n以上方法中， 1)和2)都需要修改镜像， 3)和4)则只需要修改POD的spec， 能适用于所有镜像。不过还是有不方便的地方：\n 每个工作负载的yaml都要做修改，比较麻烦 对于通过helm创建的工作负载，需要修改helm charts  方法5)对集群使用者最省事，照常提交工作负载即可。不过初期需要一定的开发工作量。\n规避方案三：使用本地DNS缓存 容器的DNS请求都发往本地的DNS缓存服务(dnsmasq, nscd等)，不需要走DNAT，也不会发生conntrack冲突。另外还有个好处，就是避免DNS服务成为性能瓶颈。\n使用本地DNS缓存有两种方式：\n 每个容器自带一个DNS缓存服务 每个节点运行一个DNS缓存服务，所有容器都把本节点的DNS缓存作为自己的 nameserver  从资源效率的角度来考虑的话，推荐后一种方式。官方也意识到了这个问题比较常见，给出了 coredns 以 cache 模式作为 daemonset 部署的解决方案: https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/\n实施办法 条条大路通罗马，不管怎么做，最终到达上面描述的效果即可。\nPOD中要访问节点上的DNS缓存服务，可以使用节点的IP。 如果节点上的容器都连在一个虚拟bridge上， 也可以使用这个bridge的三层接口的IP(在TKE中，这个三层接口叫cbr0)。 要确保DNS缓存服务监听这个地址。\n如何把POD的/etc/resolv.conf中的nameserver设置为节点IP呢？\n一个办法，是设置 POD.spec.dnsPolicy 为 \u0026ldquo;Default\u0026rdquo;， 意思是POD里面的 /etc/resolv.conf， 使用节点上的文件。缺省使用节点上的 /etc/resolv.conf(如果kubelet通过参数\u0026ndash;resolv-conf指定了其他文件，则使用\u0026ndash;resolv-conf所指定的文件)。\n另一个办法，是给每个节点的kubelet指定不同的\u0026ndash;cluster-dns参数，设置为节点的IP，POD.spec.dnsPolicy仍然使用缺省值\u0026quot;ClusterFirst\u0026rdquo;。 kops项目甚至有个issue在讨论如何在部署集群时设置好\u0026ndash;cluster-dns指向节点IP: https://github.com/kubernetes/kops/issues/5584\n参考资料  Racy conntrack and DNS lookup timeouts: https://www.weave.works/blog/racy-conntrack-and-dns-lookup-timeouts 5 – 15s DNS lookups on Kubernetes? : https://blog.quentin-machu.fr/2018/06/24/5-15s-dns-lookups-on-kubernetes/ DNS intermittent delays of 5s: https://github.com/kubernetes/kubernetes/issues/56903 记一次Docker/Kubernetes上无法解释的连接超时原因探寻之旅: https://mp.weixin.qq.com/s/VYBs8iqf0HsNg9WAxktzYQ  "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/dns-resolution-abnormal/",
	"title": "DNS 解析异常",
	"tags": [],
	"description": "",
	"content": "现象: 有个用户反馈域名解析有时有问题，看报错是解析超时。\n第一反应当然是看 coredns 的 log:\n[ERROR] 2 loginspub.xxxxmobile-inc.net. A: unreachable backend: read udp 172.16.0.230:43742-\u0026gt;10.225.30.181:53: i/o timeout 这是上游 DNS 解析异常了，因为解析外部域名 coredns 默认会请求上游 DNS 来查询，这里的上游 DNS 默认是 coredns pod 所在宿主机的 resolv.conf 里面的 nameserver (coredns pod 的 dnsPolicy 为 \u0026ldquo;Default\u0026rdquo;，也就是会将宿主机里的 resolv.conf 里的 nameserver 加到容器里的 resolv.conf, coredns 默认配置 proxy . /etc/resolv.conf, 意思是非 service 域名会使用 coredns 容器中 resolv.conf 文件里的 nameserver 来解析)\n确认了下，超时的上游 DNS 10.225.30.181 并不是期望的 nameserver，VPC 默认 DNS 应该是 180 开头的。看了 coredns 所在节点的 resolv.conf，发现确实多出了这个非期望的 nameserver，跟用户确认了下，这个 DNS 不是用户自己加上去的，添加节点时这个 nameserver 本身就在 resolv.conf 中。\n根据内部同学反馈， 10.225.30.181 是广州一台年久失修将被撤裁的 DNS，物理网络，没有 VIP，撤掉就没有了，所以如果 coredns 用到了这台 DNS 解析时就可能 timeout。后面我们自己测试，某些 VPC 的集群确实会有这个 nameserver，奇了怪了，哪里冒出来的？\n又试了下直接创建 CVM，不加进 TKE 节点发现没有这个 nameserver，只要一加进 TKE 节点就有了 !!!\n看起来是 TKE 的问题，将 CVM 添加到 TKE 集群会自动重装系统，初始化并加进集群成为 K8S 的 node，确认了初始化过程并不会写 resolv.conf，会不会是 TKE 的 OS 镜像问题？尝试搜一下除了 /etc/resolv.conf 之外哪里还有这个 nameserver 的 IP，最后发现 /etc/resolvconf/resolv.conf.d/base 这里面有。\n看下 /etc/resolvconf/resolv.conf.d/base 的作用：Ubuntu 的 /etc/resolv.conf 是动态生成的，每次重启都会将 /etc/resolvconf/resolv.conf.d/base 里面的内容加到 /etc/resolv.conf 里。\n经确认: 这个文件确实是 TKE 的 Ubuntu OS 镜像里自带的，可能发布 OS 镜像时不小心加进去的。\n那为什么有些 VPC 的集群的节点 /etc/resolv.conf 里面没那个 IP 呢？它们的 OS 镜像里也都有那个文件那个 IP 呀。\n请教其它部门同学发现:\n 非 dhcp 子机，cvm 的 cloud-init 会覆盖 /etc/resolv.conf 来设置 dns dhcp 子机，cloud-init 不会设置，而是通过 dhcp 动态下发 2018 年 4 月 之后创建的 VPC 就都是 dhcp 类型了的，比较新的 VPC 都是 dhcp 类型的  真相大白：/etc/resolv.conf 一开始内容都包含 /etc/resolvconf/resolv.conf.d/base 的内容，也就是都有那个不期望的 nameserver，但老的 VPC 由于不是 dhcp 类型，所以 cloud-init 会覆盖 /etc/resolv.conf，抹掉了不被期望的 nameserver，而新创建的 VPC 都是 dhcp 类型，cloud-init 不会覆盖 /etc/resolv.conf，导致不被期望的 nameserver 残留在了 /etc/resolv.conf，而 coredns pod 的 dnsPolicy 为 “Default”，也就是会将宿主机的 /etc/resolv.conf 中的 nameserver 加到容器里，coredns 解析集群外的域名默认使用这些 nameserver 来解析，当用到那个将被撤裁的 nameserver 就可能 timeout。\n临时解决: 删掉 /etc/resolvconf/resolv.conf.d/base 重启\n长期解决: 我们重新制作 TKE Ubuntu OS 镜像然后发布更新\n这下应该没问题了吧，But, 用户反馈还是会偶尔解析有问题，但现象不一样了，这次并不是 dns timeout。\n用脚本跑测试仔细分析现象:\n 请求 loginspub.xxxxmobile-inc.net 时，偶尔提示域名无法解析 请求 accounts.google.com 时，偶尔提示连接失败  进入 dns 解析偶尔异常的容器的 netns 抓包:\n dns 请求会并发请求 A 和 AAAA 记录 测试脚本发请求打印序号，抓包然后 wireshark 分析对比异常时请求序号偏移量，找到异常时的 dns 请求报文，发现异常时 A 和 AAAA 记录的请求 id 冲突，并且 AAAA 响应先返回  正常情况下id不会冲突，这里冲突了也就能解释这个 dns 解析异常的现象了:\n loginspub.xxxxmobile-inc.net 没有 AAAA (ipv6) 记录，它的响应先返回告知 client 不存在此记录，由于请求 id 跟 A 记录请求冲突，后面 A 记录响应返回了 client 发现 id 重复就忽略了，然后认为这个域名无法解析 accounts.google.com 有 AAAA 记录，响应先返回了，client 就拿这个记录去尝试请求，但当前容器环境不支持 ipv6，所以会连接失败  那为什么 dns 请求 id 会冲突?\n继续观察发现: 其它节点上的 pod 不会复现这个问题，有问题这个节点上也不是所有 pod 都有这个问题，只有基于 alpine 镜像的容器才有这个问题，在此节点新起一个测试的 alpine:latest 的容器也一样有这个问题。\n为什么 alpine 镜像的容器在这个节点上有问题在其它节点上没问题？ 为什么其他镜像的容器都没问题？它们跟 alpine 的区别是什么？\n发现一点区别: alpine 使用的底层 c 库是 musl libc，其它镜像基本都是 glibc\n翻 musl libc 源码, 构造 dns 请求时，请求 id 的生成没加锁，而且跟当前时间戳有关 (network/res_mkquery.c):\n/* Make a reasonably unpredictable id */ clock_gettime(CLOCK_REALTIME, \u0026amp;ts); id = ts.tv_nsec + ts.tv_nsec/65536UL \u0026amp; 0xffff; 看注释，作者应该认为这样id基本不会冲突，事实证明，绝大多数情况确实不会冲突，我在网上搜了很久没有搜到任何关于 musl libc 的 dns 请求 id 冲突的情况。这个看起来取决于硬件，可能在某种类型硬件的机器上运行，短时间内生成的 id 就可能冲突。我尝试跟用户在相同地域的集群，添加相同配置相同机型的节点，也复现了这个问题，但后来删除再添加时又不能复现了，看起来后面新建的 cvm 又跑在了另一种硬件的母机上了。\nOK，能解释通了，再底层的细节就不清楚了，我们来看下解决方案:\n 换基础镜像 (不用alpine) 完全静态编译业务程序(不依赖底层c库)，比如go语言程序编译时可以关闭 cgo (CGO_ENABLED=0)，并告诉链接器要静态链接 (go build 后面加 -ldflags '-d')，但这需要语言和编译工具支持才可以  最终建议用户基础镜像换成另一个比较小的镜像: debian:stretch-slim。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/dns/",
	"title": "DNS 解析异常",
	"tags": [],
	"description": "",
	"content": "5 秒延时 如果DNS查询经常延时5秒才返回，通常是遇到内核 conntrack 冲突导致的丢包，详见 案例分享: DNS 5秒延时\n解析超时 如果容器内报 DNS 解析超时，先检查下集群 DNS 服务 (kube-dns/coredns) 的 Pod 是否 Ready，如果不是，请参考本章其它小节定位原因。如果运行正常，再具体看下超时现象。\n解析外部域名超时 可能原因:\n 上游 DNS 故障 上游 DNS 的 ACL 或防火墙拦截了报文  所有解析都超时 如果集群内某个 Pod 不管解析 Service 还是外部域名都失败，通常是 Pod 与集群 DNS 之间通信有问题。\n可能原因:\n 节点防火墙没放开集群网段，导致如果 Pod 跟集群 DNS 的 Pod 不在同一个节点就无法通信，DNS 请求也就无法被收到  "
},
{
	"uri": "https://k8s.imroc.io/best-practice/etcd/",
	"title": "ETCD 优化",
	"tags": [],
	"description": "",
	"content": "高可用部署 部署一个高可用ETCD集群可以参考官方文档: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/clustering.md\n 如果是 self-host 方式部署的集群，可以用 etcd-operator 部署 etcd 集群；也可以使用另一个小集群专门部署 etcd (使用 etcd-operator)\n 提高磁盘 IO 性能 ETCD 对磁盘写入延迟非常敏感，对于负载较重的集群建议磁盘使用 SSD 固态硬盘。可以使用 diskbench 或 fio 测量磁盘实际顺序 IOPS。\n提高 ETCD 的磁盘 IO 优先级 由于 ETCD 必须将数据持久保存到磁盘日志文件中，因此来自其他进程的磁盘活动可能会导致增加写入时间，结果导致 ETCD 请求超时和临时 leader 丢失。当给定高磁盘优先级时，ETCD 服务可以稳定地与这些进程一起运行:\nsudo ionice -c2 -n0 -p $(pgrep etcd) 提高存储配额 默认 ETCD 空间配额大小为 2G，超过 2G 将不再写入数据。通过给 ETCD 配置 --quota-backend-bytes 参数增大空间配额，最大支持 8G。\n分离 events 存储 集群规模大的情况下，集群中包含大量节点和服务，会产生大量的 event，这些 event 将会对 etcd 造成巨大压力并占用大量 etcd 存储空间，为了在大规模集群下提高性能，可以将 events 存储在单独的 ETCD 集群中。\n配置 kube-apiserver：\n--etcd-servers=\u0026#34;http://etcd1:2379,http://etcd2:2379,http://etcd3:2379\u0026#34; --etcd-servers-overrides=\u0026#34;/events#http://etcd4:2379,http://etcd5:2379,http://etcd6:2379\u0026#34; 减小网络延迟 如果有大量并发客户端请求 ETCD leader 服务，则可能由于网络拥塞而延迟处理 follower 对等请求。在 follower 节点上的发送缓冲区错误消息：\ndropped MsgProp to 247ae21ff9436b2d since streamMsg\u0026#39;s sending buffer is full dropped MsgAppResp to 247ae21ff9436b2d since streamMsg\u0026#39;s sending buffer is full 可以通过在客户端提高 ETCD 对等网络流量优先级来解决这些错误。在 Linux 上，可以使用 tc 对对等流量进行优先级排序：\n$ tc qdisc add dev eth0 root handle 1: prio bands 3 $ tc filter add dev eth0 parent 1: protocol ip prio 1 u32 match ip sport 2380 0xffff flowid 1:1 $ tc filter add dev eth0 parent 1: protocol ip prio 1 u32 match ip dport 2380 0xffff flowid 1:1 $ tc filter add dev eth0 parent 1: protocol ip prio 2 u32 match ip sport 2379 0xffff flowid 1:1 $ tc filter add dev eth0 parent 1: protocol ip prio 2 u32 match ip dport 2379 0xffff flowid 1:1 "
},
{
	"uri": "https://k8s.imroc.io/cluster/network/flannel/",
	"title": "Flannel",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/dev/golang-build/",
	"title": "Go 语言编译原理与优化",
	"tags": [],
	"description": "",
	"content": "编译阶段 (Compilation) debug 参数 -m 打印编译器更多想法的细节\n-gcflags \u0026#39;-m\u0026#39; -S 打印汇编\n-gcflags \u0026#39;-S\u0026#39; 优化和内联 默认开启了优化和内联，但是debug的时候开启可能会出现一些奇怪的问题，通过下面的参数可以禁止任何优化\n-gcflags \u0026#39;-N -l\u0026#39; 内联级别：\n -gcflags='-l -l' 内联级别2，更积极，可能更快，可能会制作更大的二进制文件。 -gcflags='-l -l -l' 内联级别3，再次更加激进，二进制文件肯定更大，也许更快，但也许会有 bug。 -gcflags=-l=4 (4个-l)在 Go 1.11 中将支持实验性的中间栈内联优化。  逃逸分析  如果一个局部变量值超越了函数调用的生命周期，编译器自动将它逃逸到堆 如果一个通过new或make来分配的对象，在函数内即使将指针传递给了其它函数，其它函数会被内联到当前函数，相当于指针不会逃逸出本函数，最终不返回指针的话，该指针对应的值也都会分配在栈上，而不是在堆  链接阶段 (Linking)  Go 支持 internal 和 external 两种链接方式: internal 使用 go 自身实现的 linker，external 需要启动外部的 linker linker 的主要工作是将 .o (object file) 链接成最终可执行的二进制 对应命令: go tool link，对应源码: $GOROOT/src/cmd/link 通过 -ldflags 给链接器传参，参数详见: go tool link --help  关于 CGO  启用cgo可以调用外部依赖的c库 go的编译器会判断环境变量 CGO_ENABLED 来决定是否启用cgo，默认 CGO_ENABLED=1 即启用cgo 源码文件头部的 build tag 可以根据cgo是否启用决定源码是否被编译(// +build cgo 表示希望cgo启用时被编译，相反的是 // +build !cgo) 标准库中有部分实现有两份源码，比如: $GOROOT/src/os/user/lookup_unix.go 和 $GOROOT/src/os/user/cgo_lookup_unix.go ，它们有相同的函数，但实现不一样，前者是纯go实现，后者是使用cgo调用外部依赖来实现，标准库中使用cgo比较常见的是 net 包。  internal linking  link 默认使用 internal 方式 直接使用 go 本身的实现的 linker 来链接代码， 功能比较简单，仅仅是将 .o 和预编译的 .a 写到最终二进制文件中(.a文件在 $GOROOT/pkg 和 $GOPATH/pkg 中，其实就是.o文件打包的压缩包，通过 tar -zxvf 可以解压出来查看)  external linking  会启动外部 linker (gcc/clang)，通过 -ldflags '-linkmode \u0026quot;external\u0026quot;' 启用 external linking 通过 -extldflags 给外部 linker 传参，比如： -ldflags '-linkmode \u0026quot;external\u0026quot; -extldflags \u0026quot;-static\u0026quot;'  static link go编译出来就是一个二进制，自带runtime，不需要解释器，但并不意味着就不需要任何依赖，但也可以通过静态链接来做到完全不用任何依赖，全部”揉“到一个二进制文件中。实现静态链接的方法：\n 如果是 external linking，可以这样: -ldflags '-linkmode external -extldflags -static' 如果用默认的 internal linking，可以这样: -ldflags '-d'  ldflags 其它常用参数  -s -w 是去除符号表和DWARF调试信息(可以减小二进制体积，但不利于调试，可在用于生产环境)，示例: -ldflags '-s -w' -X 可以给变量注入值，比如编译时用脚本动态注入当前版本和 commit id 到代码的变量中，通常程序的 version 子命令或参数输出当前版本信息时就用这种方式实现，示例：-ldflags '-X myapp/pkg/version/version=v1.0.0'  使用 Docker 编译 使用 Docker 编译可以不用依赖本机 go 环境，将编译环境标准化，特别在有外部动态链接库依赖的情况下很有用，可以直接 run 一个容器来编译，给它挂载源码目录和二进制输出目录，这样我们就可以拿到编译出来的二进制了，这里以编译cfssl为例:\nROOT_PKG=github.com/cloudflare/cfssl CMD_PKG=$ROOT_PKG/cmd LOCAL_SOURCE_PATH=/Users/roc/go/src/$ROOT_PKG LOCAL_OUTPUT_PATH=$PWD GOPATH=/go/src ROOT_PATH=$GOPATH/$ROOT_PKG CMD_PATH=$GOPATH/$CMD_PKG docker run --rm \\  -v $LOCAL_SOURCE_PATH:$ROOT_PATH \\  -v $LOCAL_OUTPUT_PATH:/output \\  -w $ROOT_PATH \\  golang:1.13 \\  go build -v \\  -ldflags \u0026#39;-d\u0026#39; \\  -o /output/ \\  $CMD_PATH/... 编译镜像可以参考下面示例（使用docker多阶段构建，完全静态编译，没有外部依赖）:\nFROMgolang:1.12-stretch as builderMAINTAINERrockerchen@tencent.comENV BUILD_DIR /go/src/cloud.tencent.com/qc_container_cluster/hpa-metrics-serverWORKDIR$BUILD_DIRCOPY ./ $BUILD_DIRRUN CGO_ENABLED=0 go build -v -o /hpa-metrics-server \\  -ldflags \u0026#39;-d\u0026#39; \\  ./FROMubuntu:16.04MAINTAINERrockerchen@tencent.comRUN apt-get update -yRUN DEBIAN_FRONTEND=noninteractive apt-get install -y curl iproute2 inetutils-tools telnet inetutils-pingRUN apt-get install --no-install-recommends --no-install-suggests ca-certificates -yCOPY --from=builder /hpa-metrics-server /hpa-metrics-serverRUN chmod a+x /hpa-metrics-server参考资料  Go 性能调优之 —— 编译优化: https://segmentfault.com/a/1190000016354799  "
},
{
	"uri": "https://k8s.imroc.io/cluster/ingress/",
	"title": "Ingress 方案",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/runnig-out-of-inotify-watches/",
	"title": "inotify watch 耗尽",
	"tags": [],
	"description": "",
	"content": "每个 linux 进程可以持有多个 fd，每个 inotify 类型的 fd 可以 watch 多个目录，每个用户下所有进程 inotify 类型的 fd 可以 watch 的总目录数有个最大限制，这个限制可以通过内核参数配置: fs.inotify.max_user_watches\n查看最大 inotify watch 数:\n$ cat /proc/sys/fs/inotify/max_user_watches 8192 使用下面的脚本查看当前有 inotify watch 类型 fd 的进程以及每个 fd watch 的目录数量，降序输出，带总数统计:\n#!/usr/bin/env bash # # Copyright 2019 (c) roc # # This script shows processes holding the inotify fd, alone with HOW MANY directories each inotify fd watches(0 will be ignored). total=0 result=\u0026#34;EXE PID FD-INFO INOTIFY-WATCHES\\n\u0026#34; while read pid fd; do \\  exe=\u0026#34;$(readlink -f /proc/$pid/exe || echo n/a)\u0026#34;; \\  fdinfo=\u0026#34;/proc/$pid/fdinfo/$fd\u0026#34; ; \\  count=\u0026#34;$(grep -c inotify \u0026#34;$fdinfo\u0026#34; || true)\u0026#34;; \\  if [ $((count)) != 0 ]; then total=$((total+count)); \\  result+=\u0026#34;$exe$pid$fdinfo$count\\n\u0026#34;; \\  fi done \u0026lt;\u0026lt;\u0026lt; \u0026#34;$(lsof +c 0 -n -P -u root|awk \u0026#39;/inotify$/ { gsub(/[urw]$/,\u0026#34;\u0026#34;,$4); print $2\u0026#34; \u0026#34;$4 }\u0026#39;)\u0026#34; \u0026amp;\u0026amp; echo \u0026#34;total $totalinotify watches\u0026#34; \u0026amp;\u0026amp; result=\u0026#34;$(echo -e $result|column -t)\\n\u0026#34; \u0026amp;\u0026amp; echo -e \u0026#34;$result\u0026#34; | head -1 \u0026amp;\u0026amp; echo -e \u0026#34;$result\u0026#34; | sed \u0026#34;1d\u0026#34; | sort -k 4rn; 示例输出:\ntotal 7882 inotify watches EXE PID FD-INFO INOTIFY-WATCHES /usr/local/qcloud/YunJing/YDEyes/YDService 25813 /proc/25813/fdinfo/8 7077 /usr/bin/kubelet 1173 /proc/1173/fdinfo/22 665 /usr/bin/ruby2.3 13381 /proc/13381/fdinfo/14 54 /usr/lib/policykit-1/polkitd 1458 /proc/1458/fdinfo/9 14 /lib/systemd/systemd-udevd 450 /proc/450/fdinfo/9 13 /usr/sbin/nscd 7935 /proc/7935/fdinfo/3 6 /usr/bin/kubelet 1173 /proc/1173/fdinfo/28 5 /lib/systemd/systemd 1 /proc/1/fdinfo/17 4 /lib/systemd/systemd 1 /proc/1/fdinfo/18 4 /lib/systemd/systemd 1 /proc/1/fdinfo/26 4 /lib/systemd/systemd 1 /proc/1/fdinfo/28 4 /usr/lib/policykit-1/polkitd 1458 /proc/1458/fdinfo/8 4 /usr/local/bin/sidecar-injector 4751 /proc/4751/fdinfo/3 3 /usr/lib/accountsservice/accounts-daemon 1178 /proc/1178/fdinfo/7 2 /usr/local/bin/galley 8228 /proc/8228/fdinfo/10 2 /usr/local/bin/galley 8228 /proc/8228/fdinfo/9 2 /lib/systemd/systemd 1 /proc/1/fdinfo/11 1 /sbin/agetty 1437 /proc/1437/fdinfo/4 1 /sbin/agetty 1440 /proc/1440/fdinfo/4 1 /usr/bin/kubelet 1173 /proc/1173/fdinfo/10 1 /usr/local/bin/envoy 4859 /proc/4859/fdinfo/5 1 /usr/local/bin/envoy 5427 /proc/5427/fdinfo/5 1 /usr/local/bin/envoy 6058 /proc/6058/fdinfo/3 1 /usr/local/bin/envoy 6893 /proc/6893/fdinfo/3 1 /usr/local/bin/envoy 6950 /proc/6950/fdinfo/3 1 /usr/local/bin/galley 8228 /proc/8228/fdinfo/3 1 /usr/local/bin/pilot-agent 3819 /proc/3819/fdinfo/5 1 /usr/local/bin/pilot-agent 4244 /proc/4244/fdinfo/5 1 /usr/local/bin/pilot-agent 5901 /proc/5901/fdinfo/3 1 /usr/local/bin/pilot-agent 6789 /proc/6789/fdinfo/3 1 /usr/local/bin/pilot-agent 6808 /proc/6808/fdinfo/3 1 /usr/local/bin/pilot-discovery 6231 /proc/6231/fdinfo/3 1 /usr/local/bin/sidecar-injector 4751 /proc/4751/fdinfo/5 1 /usr/sbin/acpid 1166 /proc/1166/fdinfo/6 1 /usr/sbin/dnsmasq 7572 /proc/7572/fdinfo/8 1 如果看到总 watch 数比较大，接近最大限制，可以修改内核参数调高下这个限制。\n临时调整:\nsudo sysctl fs.inotify.max_user_watches=524288 永久生效:\necho \u0026#34;fs.inotify.max_user_watches=524288\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf \u0026amp;\u0026amp; sysctl -p 打开 inotify_add_watch 跟踪，进一步 debug inotify watch 耗尽的原因:\necho 1 \u0026gt;\u0026gt; /sys/kernel/debug/tracing/events/syscalls/sys_exit_inotify_add_watch/enable "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/job-cannot-delete/",
	"title": "Job 无法被删除",
	"tags": [],
	"description": "",
	"content": "原因  可能是 k8s 的一个bug: https://github.com/kubernetes/kubernetes/issues/43168 本质上是脏数据问题，Running+Succeed != 期望Completions 数量，低版本 kubectl 不容忍，delete job 的时候打开debug(加-v=8)，会看到kubectl不断在重试，直到达到timeout时间。新版kubectl会容忍这些，删除job时会删除关联的pod  解决方法  升级 kubectl 版本，1.12 以上 低版本 kubectl 删除 job 时带 --cascade=false 参数(如果job关联的pod没删完，加这个参数不会删除关联的pod)  kubectl delete job --cascade=false \u0026lt;job name\u0026gt; "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/schemaerror-when-using-kubectl-apply-or-edit/",
	"title": "kubectl edit 或者 apply 报 SchemaError",
	"tags": [],
	"description": "",
	"content": "问题现象 kubectl edit 或 apply 资源报如下错误:\nerror: SchemaError(io.k8s.apimachinery.pkg.apis.meta.v1.APIGroup): invalid object doesn't have additional properties 集群版本：v1.10\n排查过程  使用 kubectl apply -f tmp.yaml --dry-run -v8 发现请求 /openapi/v2 这个 api 之后，kubectl在 validate 过程报错。 换成 kubectl 1.12 之后没有再报错。 kubectl get --raw '/openapi/v2' 发现返回的 json 内容与正常集群有差异，刚开始返回的 json title 为 Kubernetes metrics-server，正常的是 Kubernetes。 怀疑是 metrics-server 的问题，发现集群内确实安装了 k8s 官方的 metrics-server，询问得知之前是 0.3.1，后面升级为了 0.3.5。 将 metrics-server 回滚之后恢复正常。  原因分析 初步怀疑，新版本的 metrics-server 使用了新的 openapi-generator，生成的 openapi 格式和之前 k8s 版本生成的有差异。导致旧版本的 kubectl 在解析 openapi 的 schema 时发生异常，查看代码发现1.10 和 1.12 版本在解析 openapi 的 schema 时，实现确实有差异。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/kubectl-exec-or-logs-failed/",
	"title": "kubectl 执行 exec 或 logs 失败",
	"tags": [],
	"description": "",
	"content": "通常是 apiserver \u0026ndash;\u0026gt; kubelet:10250 之间的网络不通，10250 是 kubelet 提供接口的端口，kubectl exec 和 kubectl logs 的原理就是 apiserver 调 kubelet，kubelet 再调运行时 (比如 dockerd) 来实现的，所以要保证 kubelet 10250 端口对 apiserver 放通。检查防火墙、iptables 规则是否对 10250 端口或某些 IP 进行了拦截。\n"
},
{
	"uri": "https://k8s.imroc.io/trick/efficient-kubectl/",
	"title": "kubectl 高效技巧",
	"tags": [],
	"description": "",
	"content": "k 命令 是否有过因为使用 kubectl 经常需要重复输入命名空间而苦恼？是否觉得应该要有个记住命名空间的功能，自动记住上次使用的命名空间，不需要每次都输入？可惜没有这种功能，但是，本文会教你一个非常巧妙的方法完美帮你解决这个痛点。\n将如下脚本粘贴到当前shell(注册k命令到当前终端session):\nfunction k() { cmdline=`HISTTIMEFORMAT=\u0026#34;\u0026#34; history | awk \u0026#39;$2 == \u0026#34;kubectl\u0026#34; \u0026amp;\u0026amp; (/-n/ || /--namespace/) {for(i=2;i\u0026lt;=NF;i++)printf(\u0026#34;%s \u0026#34;,$i);print \u0026#34;\u0026#34;}\u0026#39; | tail -n 1` regs=(\u0026#39;\\-n [\\w\\-\\d]+\u0026#39; \u0026#39;\\-n=[\\w\\-\\d]+\u0026#39; \u0026#39;\\-\\-namespace [\\w\\-\\d]+\u0026#39; \u0026#39;\\-\\-namespace=[\\w\\-\\d]+\u0026#39;) for i in \u0026#34;${!regs[@]}\u0026#34;; do reg=${regs[i]} nsarg=`echo $cmdline | grep -o -P \u0026#34;$reg\u0026#34;` if [[ \u0026#34;$nsarg\u0026#34; == \u0026#34;\u0026#34; ]]; then continue fi cmd=\u0026#34;kubectl $nsarg$@\u0026#34; echo \u0026#34;$cmd\u0026#34; $cmd return done cmd=\u0026#34;kubectl $@\u0026#34; echo \u0026#34;$cmd\u0026#34; $cmd } mac 用户可以使用 dash 的 snippets 功能快速将上面的函数粘贴，使用 kk. 作为触发键 (dash snippets可以全局监听键盘输入，使用指定的输入作为触发而展开配置的内容，相当于是全局代码片段)，以后在某个终端想使用 k 的时候按下 kk. 就可以将 k 命令注册到当前终端，dash snippets 配置如图所示：\n将 k 当作 kubectl 来用，只是不需要输入命名空间，它会调用 kubectl 并自动加上上次使用的非默认的命名空间，如果想切换命名空间，再常规的使用一次 kubectl 就行，下面是示范：\n哈哈，是否感觉可以少输入很多字符，提高 kubectl 使用效率了？这是目前我探索解决 kubectl 重复输入命名空间的最好方案，一开始是受 fuck命令 的启发，想用 go 语言开发个 k 命令，但是发现两个缺点：\n 需要安装二进制才可以使用（对于需要在多个地方用kubectl管理多个集群的人来说实在太麻烦） 如果当前 shell 默认没有将历史输入记录到 history 文件( bash 的 history 文件默认是 ~/.bash_history)，那么将无法准确知道上一次 kubectl 使用的哪个命名空间  这里解释下第二个缺点的原因：ssh 连上服务器会启动一个 shell 进程，通常是 bash，大多 bash 默认配置会实时将历史输入追加到 ~/.bash_history里，所以开多个ssh使用history命令看到的历史输入是一样的，但有些默认不会实时记录历史到~/.bash_history，而是记在当前 shell 进程的内存中，在 shell 退出时才会写入到文件。这种情况新起的进程是无法知道当前 shell 的最近历史输入的，fuck命令 也不例外。\n所以最完美的解决方案就是注册函数到当前shell来调用，配合 dash 的 snippets 功能可以实现快速注册，解决复制粘贴的麻烦\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/lb-healthcheck-failed/",
	"title": "LB 健康检查失败",
	"tags": [],
	"description": "",
	"content": "可能原因:\n 节点防火墙规则没放开 nodeport 区间端口 (默认 30000-32768) 检查iptables和云主机安全组 LB IP 绑到 kube-ipvs0 导致丢源 IP为 LB IP 的包: https://github.com/kubernetes/kubernetes/issues/79783  TODO: 完善\n"
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/low-cps-from-lb-to-nodeport/",
	"title": "LB 压测 NodePort CPS 低",
	"tags": [],
	"description": "",
	"content": "现象: LoadBalancer 类型的 Service，直接压测 NodePort CPS 比较高，但如果压测 LB CPS 就很低。\n环境说明: 用户使用的黑石TKE，不是公有云TKE，黑石的机器是物理机，LB的实现也跟公有云不一样，但 LoadBalancer 类型的 Service 的实现同样也是 LB 绑定各节点的 NodePort，报文发到 LB 后转到节点的 NodePort， 然后再路由到对应 pod，而测试在公有云 TKE 环境下没有这个问题。\n client 抓包: 大量SYN重传。 server 抓包: 抓 NodePort 的包，发现当 client SYN 重传时 server 能收到 SYN 包但没有响应。  又是 SYN 收到但没响应，难道又是开启 tcp_tw_recycle 导致的？检查节点的内核参数发现并没有开启，除了这个原因，还会有什么情况能导致被丢弃？\nconntrack -S 看到 insert_failed 数量在不断增加，也就是 conntrack 在插入很多新连接的时候失败了，为什么会插入失败？什么情况下会插入失败？\n挖内核源码: netfilter conntrack 模块为每个连接创建 conntrack 表项时，表项的创建和最终插入之间还有一段逻辑，没有加锁，是一种乐观锁的过程。conntrack 表项并发刚创建时五元组不冲突的话可以创建成功，但中间经过 NAT 转换之后五元组就可能变成相同，第一个可以插入成功，后面的就会插入失败，因为已经有相同的表项存在。比如一个 SYN 已经做了 NAT 但是还没到最终插入的时候，另一个 SYN 也在做 NAT，因为之前那个 SYN 还没插入，这个 SYN 做 NAT 的时候就认为这个五元组没有被占用，那么它 NAT 之后的五元组就可能跟那个还没插入的包相同。\n在我们这个问题里实际就是 netfilter 做 SNAT 时源端口选举冲突了，黑石 LB 会做 SNAT，SNAT 时使用了 16 个不同 IP 做源，但是短时间内源 Port 却是集中一致的，并发两个 SYN a 和SYN b，被 LB SNAT 后源 IP 不同但源 Port 很可能相同，这里就假设两个报文被 LB SNAT 之后它们源 IP 不同源 Port 相同，报文同时到了节点的 NodePort 会再次做 SNAT 再转发到对应的 Pod，当报文到了 NodePort 时，这时它们五元组不冲突，netfilter 为它们分别创建了 conntrack 表项，SYN a 被节点 SNAT 时默认行为是 从 port_range 范围的当前源 Port 作为起始位置开始循环遍历，选举出没有被占用的作为源 Port，因为这两个 SYN 源 Port 相同，所以它们源 Port 选举的起始位置相同，当 SYN a 选出源 Port 但还没将 conntrack 表项插入时，netfilter 认为这个 Port 没被占用就很可能给 SYN b 也选了相同的源 Port，这时他们五元组就相同了，当 SYN a 的 conntrack 表项插入后再插入 SYN b 的 conntrack 表项时，发现已经有相同的记录就将 SYN b 的 conntrack 表项丢弃了。\n解决方法探索: 不使用源端口选举，在 iptables 的 MASQUERADE 规则如果加 --random-fully 这个 flag 可以让端口选举完全随机，基本上能避免绝大多数的冲突，但也无法完全杜绝。最终决定开发 LB 直接绑 Pod IP，不基于 NodePort，从而避免 netfilter 的 SNAT 源端口冲突问题。\n"
},
{
	"uri": "https://k8s.imroc.io/best-practice/master/",
	"title": "Master 优化",
	"tags": [],
	"description": "",
	"content": "Kubernetes 自 v1.6 以来，官方就宣称单集群最大支持 5000 个节点。不过这只是理论上，在具体实践中从 0 到 5000，还是有很长的路要走，需要见招拆招。\n官方标准如下：\n 不超过 5000 个节点 不超过 150000 个 pod 不超过 300000 个容器 每个节点不超过 100 个 pod  Master 节点配置优化 GCE 推荐配置：\n 1-5 节点: n1-standard-1 6-10 节点: n1-standard-2 11-100 节点: n1-standard-4 101-250 节点: n1-standard-8 251-500 节点: n1-standard-16 超过 500 节点: n1-standard-32  AWS 推荐配置：\n 1-5 节点: m3.medium 6-10 节点: m3.large 11-100 节点: m3.xlarge 101-250 节点: m3.2xlarge 251-500 节点: c4.4xlarge 超过 500 节点: c4.8xlarge  对应 CPU 和内存为：\n 1-5 节点: 1vCPU 3.75G内存 6-10 节点: 2vCPU 7.5G内存 11-100 节点: 4vCPU 15G内存 101-250 节点: 8vCPU 30G内存 251-500 节点: 16vCPU 60G内存 超过 500 节点: 32vCPU 120G内存  kube-apiserver 优化 高可用  方式一: 启动多个 kube-apiserver 实例通过外部 LB 做负载均衡。 方式二: 设置 --apiserver-count 和 --endpoint-reconciler-type，可使得多个 kube-apiserver 实例加入到 Kubernetes Service 的 endpoints 中，从而实现高可用。  不过由于 TLS 会复用连接，所以上述两种方式都无法做到真正的负载均衡。为了解决这个问题，可以在服务端实现限流器，在请求达到阀值时告知客户端退避或拒绝连接，客户端则配合实现相应负载切换机制。\n控制连接数 kube-apiserver 以下两个参数可以控制连接数:\n--max-mutating-requests-inflight int The maximum number of mutating requests in flight at a given time. When the server exceeds this, it rejects requests. Zero for no limit. (default 200) --max-requests-inflight int The maximum number of non-mutating requests in flight at a given time. When the server exceeds this, it rejects requests. Zero for no limit. (default 400) 节点数量在 1000 - 3000 之间时，推荐：\n--max-requests-inflight=1500 --max-mutating-requests-inflight=500 节点数量大于 3000 时，推荐：\n--max-requests-inflight=3000 --max-mutating-requests-inflight=1000 kube-scheduler 与 kube-controller-manager 优化 高可用 kube-controller-manager 和 kube-scheduler 是通过 leader election 实现高可用，启用时需要添加以下参数:\n--leader-elect=true --leader-elect-lease-duration=15s --leader-elect-renew-deadline=10s --leader-elect-resource-lock=endpoints --leader-elect-retry-period=2s 控制 QPS 与 kube-apiserver 通信的 qps 限制，推荐为：\n--kube-api-qps=100 集群 DNS 高可用 设置反亲和，让集群 DNS (kube-dns 或 coredns) 分散在不同节点，避免单点故障:\naffinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - weight: 100 labelSelector: matchExpressions: - key: k8s-app operator: In values: - kube-dns topologyKey: kubernetes.io/hostname "
},
{
	"uri": "https://k8s.imroc.io/cluster/metrics/",
	"title": "Metrics 方案",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/namespace-stuck-on-terminating/",
	"title": "Namespace 卡在 Terminating",
	"tags": [],
	"description": "",
	"content": "Namespace 上存在 Finalizers 删除 ns 后，一直卡在 Terminating 状态。通常是存在 finalizers，通过 kubectl get ns xxx -o yaml 可以看到是否有 finalizers:\n$ kubectl get ns -o yaml kube-node-lease apiVersion: v1 kind: Namespace metadata: ... finalizers: - finalizers.kubesphere.io/namespaces labels: kubesphere.io/workspace: system-workspace name: kube-node-lease ownerReferences: - apiVersion: tenant.kubesphere.io/v1alpha1 blockOwnerDeletion: true controller: true kind: Workspace name: system-workspace uid: d4310acd-1fdc-11ea-a370-a2c490b9ae47 spec: {} 此例是因为之前装过 kubesphere，然后卸载了，但没有清理 finalizers，将其删除就可以了。\nk8s 资源的 metadata 里如果存在 finalizers，那么该资源一般是由某应用创建的，或者是这个资源是此应用关心的。应用会在资源的 metadata 里的 finalizers 加了一个它自己可以识别的标识，这意味着这个资源被删除时需要由此应用来做删除前的清理，清理完了它需要将标识从该资源的 finalizers 中移除，然后才会最终彻底删除资源。比如 Rancher 创建的一些资源就会写入 finalizers 标识。\n如果应用被删除，而finalizer没清理，删除资源时就会一直卡在terminating，可以手动删除finalizer来解决。\n手动删除方法：\n kubectl edit ns xx 删除 spec.finalizers。 如果k8s版本较高会发现方法1行不通，因为高版本更改 namespace finalizers 被移到了 namespace 的 finalize 这个 subresource (参考官方文档API文档)，并且需要使用 PUT 请求，可以先执行 kubectl proxy 然后再起一个终端用 curl 模拟请求去删 finalizers:  curl -H \u0026#34;Content-Type: application/json\u0026#34; -XPUT -d \u0026#39;{\u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;Namespace\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;delete-me\u0026#34;},\u0026#34;spec\u0026#34;:{\u0026#34;finalizers\u0026#34;:[]}}\u0026#39; http://localhost:8001/api/v1/namespaces/delete-me/finalize  替换 delete-me 为你的 namespace 名称\n 参考资料:\n Node Lease 的 Proposal: https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/0009-node-heartbeat.md  metrics server 被删除 删除 ns 时，apiserver 会调注册上去的扩展 api 去清理资源，如果扩展 api 对应的服务也被删了，那么就无法清理完成，也就一直卡在 Terminating。\n下面的例子就是使用 prometheus-adapter 注册的 resource metrics api，但 prometheus-adapter 已经被删除了:\n$ kubectl get apiservice ... v1beta1.metrics.k8s.io monitoring/prometheus-adapter False (ServiceNotFound) 75d ... "
},
{
	"uri": "https://k8s.imroc.io/cluster/ingress/nginx/",
	"title": "Nginx Ingress",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/no-space-left-on-device/",
	"title": "no space left on device",
	"tags": [],
	"description": "",
	"content": " 有时候节点 NotReady， kubelet 日志报 no space left on device 有时候创建 Pod 失败，describe pod 看 event 报 no space left on device  出现这种错误有很多中可能原因，下面我们来根据现象找对应原因。\ninotify watch 耗尽 节点 NotReady，kubelet 启动失败，看 kubelet 日志:\nJul 18 15:20:58 VM_16_16_centos kubelet[11519]: E0718 15:20:58.280275 11519 raw.go:140] Failed to watch directory \u0026#34;/sys/fs/cgroup/memory/kubepods\u0026#34;: inotify_add_watch /sys/fs/cgroup/memory/kubepods/burstable/pod926b7ff4-7bff-11e8-945b-52540048533c/6e85761a30707b43ed874e0140f58839618285fc90717153b3cbe7f91629ef5a: no space left on device 系统调用 inotify_add_watch 失败，提示 no space left on device， 这是因为系统上进程 watch 文件目录的总数超出了最大限制，可以修改内核参数调高限制，详细请参考本书 处理实践: inotify watch 耗尽\ncgroup 泄露 查看当前 cgroup 数量:\n$ cat /proc/cgroups | column -t #subsys_name hierarchy num_cgroups enabled cpuset 5 29 1 cpu 7 126 1 cpuacct 7 126 1 memory 9 127 1 devices 4 126 1 freezer 2 29 1 net_cls 6 29 1 blkio 10 126 1 perf_event 3 29 1 hugetlb 11 29 1 pids 8 126 1 net_prio 6 29 1 cgroup 子系统目录下面所有每个目录及其子目录都认为是一个独立的 cgroup，所以也可以在文件系统中统计目录数来获取实际 cgroup 数量，通常跟 /proc/cgroups 里面看到的应该一致:\n$ find -L /sys/fs/cgroup/memory -type d | wc -l 127 当 cgroup 泄露发生时，这里的数量就不是真实的了，低版本内核限制最大 65535 个 cgroup，并且开启 kmem 删除 cgroup 时会泄露，大量创建删除容器后泄露了许多 cgroup，最终总数达到 65535，新建容器创建 cgroup 将会失败，报 no space left on device\n详细请参考本书 案例分享: cgroup 泄露\n磁盘被写满(TODO) Pod 启动失败，状态 CreateContainerError:\ncsi-cephfsplugin-27znb 0/2 CreateContainerError 167 17h Pod 事件报错:\nWarning Failed 5m1s (x3397 over 17h) kubelet, ip-10-0-151-35.us-west-2.compute.internal (combined from similar events): Error: container create failed: container_linux.go:336: starting container process caused \u0026#34;process_linux.go:399: container init caused \\\u0026#34;rootfs_linux.go:58: mounting \\\\\\\u0026#34;/sys\\\\\\\u0026#34; to rootfs \\\\\\\u0026#34;/var/lib/containers/storage/overlay/051e985771cc69f3f699895a1dada9ef6483e912b46a99e004af7bb4852183eb/merged\\\\\\\u0026#34; at \\\\\\\u0026#34;/var/lib/containers/storage/overlay/051e985771cc69f3f699895a1dada9ef6483e912b46a99e004af7bb4852183eb/merged/sys\\\\\\\u0026#34; caused \\\\\\\u0026#34;no space left on device\\\\\\\u0026#34;\\\u0026#34;\u0026#34; "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/not-ready/",
	"title": "Node NotReady",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/node-all-gone/",
	"title": "Node 全部消失",
	"tags": [],
	"description": "",
	"content": "Rancher 清除 Node 导致集群异常 现象 安装了 rancher 的用户，在卸载 rancher 的时候，可能会手动执行 kubectl delete ns local 来删除这个 rancher 创建的 namespace，但直接这样做会导致所有 node 被清除，通过 kubectl get node 获取不到 node。\n原因 看了下 rancher 源码，rancher 通过 nodes.management.cattle.io 这个 CRD 存储和管理 node，会给所有 node 创建对应的这个 CRD 资源，metadata 中加入了两个 finalizer，其中 user-node-remove_local 对应的 finalizer 处理逻辑就是删除对应的 k8s node 资源，也就是 delete ns local 时，会尝试删除 nodes.management.cattle.io 这些 CRD 资源，进而触发 rancher 的 finalizer 逻辑去删除对应的 k8s node 资源，从而清空了 node，所以 kubectl get node 就看不到 node 了，集群里的服务就无法被调度。\n规避方案 不要在 rancher 组件卸载完之前手动 delete ns local。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/pid-full/",
	"title": "PID 耗尽",
	"tags": [],
	"description": "",
	"content": "如何判断 PID 耗尽 首先要确认当前的 PID 限制，检查全局 PID 最大限制:\ncat /proc/sys/kernel/pid_max 也检查下线程数限制：\ncat /proc/sys/kernel/threads-max 再检查下当前用户是否还有 ulimit 限制最大进程数。\n确认当前实际 PID 数量，检查当前用户的 PID 数量:\nps -eLf | wc -l 如果发现实际 PID 数量接近最大限制说明 PID 就可能会爆满导致经常有进程无法启动，低版本内核可能报错: Cannot allocate memory，这个报错信息不准确，在内核 4.1 以后改进了: https://github.com/torvalds/linux/commit/35f71bc0a09a45924bed268d8ccd0d3407bc476f\n如何解决 临时调大 PID 和线程数限制：\necho 65535 \u0026gt; /proc/sys/kernel/pid_max echo 65535 \u0026gt; /proc/sys/kernel/threads-max 永久调大 PID 和线程数限制:\necho \u0026#34;kernel.pid_max=65535 \u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf \u0026amp;\u0026amp; sysctl -p echo \u0026#34;kernel.threads-max=65535 \u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf \u0026amp;\u0026amp; sysctl -p k8s 1.14 支持了限制 Pod 的进程数量: https://kubernetes.io/blog/2019/04/15/process-id-limiting-for-stability-improvements-in-kubernetes-1.14/\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/slow-terminating/",
	"title": "Pod Terminating 慢",
	"tags": [],
	"description": "",
	"content": "可能原因  进程通过 bash -c 启动导致 kill 信号无法透传给业务进程  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-containercreating-or-waiting/",
	"title": "Pod 一直处于 ContainerCreating 或 Waiting 状态",
	"tags": [],
	"description": "",
	"content": "Pod 配置错误  检查是否打包了正确的镜像 检查配置了正确的容器参数  挂载 Volume 失败 Volume 挂载失败也分许多种情况，先列下我这里目前已知的。\nPod 漂移没有正常解挂之前的磁盘 在云尝试托管的 K8S 服务环境下，默认挂载的 Volume 一般是块存储类型的云硬盘，如果某个节点挂了，kubelet 无法正常运行或与 apiserver 通信，到达时间阀值后会触发驱逐，自动在其它节点上启动相同的副本 (Pod 漂移)，但是由于被驱逐的 Node 无法正常运行并不知道自己被驱逐了，也就没有正常执行解挂，cloud-controller-manager 也在等解挂成功后再调用云厂商的接口将磁盘真正从节点上解挂，通常会等到一个时间阀值后 cloud-controller-manager 会强制解挂云盘，然后再将其挂载到 Pod 最新所在节点上，这种情况下 ContainerCreating 的时间相对长一点，但一般最终是可以启动成功的，除非云厂商的 cloud-controller-manager 逻辑有 bug。\n命中 K8S 挂载 configmap/secret 的 subpath 的 bug 最近发现如果 Pod 挂载了 configmap 或 secret， 如果后面修改了 configmap 或 secret 的内容，Pod 里的容器又原地重启了(比如存活检查失败被 kill 然后重启拉起)，就会触发 K8S 的这个 bug，团队的小伙伴已提 PR: https://github.com/kubernetes/kubernetes/pull/82784\n如果是这种情况，容器会一直启动不成功，可以看到类似以下的报错:\n$ kubectl -n prod get pod -o yaml manage-5bd487cf9d-bqmvm ... lastState: terminated containerID: containerd://e6746201faa1dfe7f3251b8c30d59ebf613d99715f3b800740e587e681d2a903 exitCode: 128 finishedAt: 2019-09-15T00:47:22Z message: \u0026#39;failed to create containerd task: OCI runtime create failed: container_linux.go:345: starting container process caused \u0026#34;process_linux.go:424: container init caused \\\u0026#34;rootfs_linux.go:58: mounting \\\\\\\u0026#34;/var/lib/kubelet/pods/211d53f4-d08c-11e9-b0a7-b6655eaf02a6/volume-subpaths/manage-config-volume/manage/0\\\\\\\u0026#34; to rootfs \\\\\\\u0026#34;/run/containerd/io.containerd.runtime.v1.linux/k8s.io/e6746201faa1dfe7f3251b8c30d59ebf613d99715f3b800740e587e681d2a903/rootfs\\\\\\\u0026#34; at \\\\\\\u0026#34;/run/containerd/io.containerd.runtime.v1.linux/k8s.io/e6746201faa1dfe7f3251b8c30d59ebf613d99715f3b800740e587e681d2a903/rootfs/app/resources/application.properties\\\\\\\u0026#34; caused \\\\\\\u0026#34;no such file or directory\\\\\\\u0026#34;\\\u0026#34;\u0026#34;: unknown\u0026#39; 磁盘爆满 启动 Pod 会调 CRI 接口创建容器，容器运行时创建容器时通常会在数据目录下为新建的容器创建一些目录和文件，如果数据目录所在的磁盘空间满了就会创建失败并报错:\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedCreatePodSandBox 2m (x4307 over 16h) kubelet, 10.179.80.31 (combined from similar events): Failed create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod \u0026#34;apigateway-6dc48bf8b6-l8xrw\u0026#34;: Error response from daemon: mkdir /var/lib/docker/aufs/mnt/1f09d6c1c9f24e8daaea5bf33a4230de7dbc758e3b22785e8ee21e3e3d921214-init: no space left on device 解决方法参考本书 处理实践：磁盘爆满\n节点内存碎片化 如果节点上内存碎片化严重，缺少大页内存，会导致即使总的剩余内存较多，但还是会申请内存失败，参考 处理实践: 内存碎片化\nlimit 设置太小或者单位不对 如果 limit 设置过小以至于不足以成功运行 Sandbox 也会造成这种状态，常见的是因为 memory limit 单位设置不对造成的 limit 过小，比如误将 memory 的 limit 单位像 request 一样设置为小 m，这个单位在 memory 不适用，会被 k8s 识别成 byte， 应该用 Mi 或 M。，\n举个例子: 如果 memory limit 设为 1024m 表示限制 1.024 Byte，这么小的内存， pause 容器一起来就会被 cgroup-oom kill 掉，导致 pod 状态一直处于 ContainerCreating。\n这种情况通常会报下面的 event:\nPod sandbox changed, it will be killed and re-created。 kubelet 报错:\nto start sandbox container for pod ... Error response from daemon: OCI runtime create failed: container_linux.go:348: starting container process caused \u0026#34;process_linux.go:301: running exec setns process for init caused \\\u0026#34;signal: killed\\\u0026#34;\u0026#34;: unknown 拉取镜像失败 镜像拉取失败也分很多情况，这里列举下:\n 配置了错误的镜像 Kubelet 无法访问镜像仓库（比如默认 pause 镜像在 gcr.io 上，国内环境访问需要特殊处理） 拉取私有镜像的 imagePullSecret 没有配置或配置有误 镜像太大，拉取超时（可以适当调整 kubelet 的 \u0026ndash;image-pull-progress-deadline 和 \u0026ndash;runtime-request-timeout 选项）  CNI 网络错误 如果发生 CNI 网络错误通常需要检查下网络插件的配置和运行状态，如果没有正确配置或正常运行通常表现为:\n 无法配置 Pod 网络 无法分配 Pod IP  controller-manager 异常 查看 master 上 kube-controller-manager 状态，异常的话尝试重启。\n安装 docker 没删干净旧版本 如果节点上本身有 docker 或者没删干净，然后又安装 docker，比如在 centos 上用 yum 安装:\nyum install -y docker 这样可能会导致 dockerd 创建容器一直不成功，从而 Pod 状态一直 ContainerCreating，查看 event 报错:\n Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedCreatePodSandBox 18m (x3583 over 83m) kubelet, 192.168.4.5 (combined from similar events): Failed create pod sandbox: rpc error: code = Unknown desc = failed to start sandbox container for pod \u0026quot;nginx-7db9fccd9b-2j6dh\u0026quot;: Error response from daemon: ttrpc: client shutting down: read unix @-\u0026gt;@/containerd-shim/moby/de2bfeefc999af42783115acca62745e6798981dff75f4148fae8c086668f667/shim.sock: read: connection reset by peer: unknown Normal SandboxChanged 3m12s (x4420 over 83m) kubelet, 192.168.4.5 Pod sandbox changed, it will be killed and re-created. 可能是因为重复安装 docker 版本不一致导致一些组件之间不兼容，从而导致 dockerd 无法正常创建容器。\n存在同名容器 如果节点上已有同名容器，创建 sandbox 就会失败，event:\n Warning FailedCreatePodSandBox 2m kubelet, 10.205.8.91 Failed create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod \u0026quot;lomp-ext-d8c8b8c46-4v8tl\u0026quot;: operation timeout: context deadline exceeded Warning FailedCreatePodSandBox 3s (x12 over 2m) kubelet, 10.205.8.91 Failed create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod \u0026quot;lomp-ext-d8c8b8c46-4v8tl\u0026quot;: Error response from daemon: Conflict. The container name \u0026quot;/k8s_POD_lomp-ext-d8c8b8c46-4v8tl_default_65046a06-f795-11e9-9bb6-b67fb7a70bad_0\u0026quot; is already in use by container \u0026quot;30aa3f5847e0ce89e9d411e76783ba14accba7eb7743e605a10a9a862a72c1e2\u0026quot;. You have to remove (or rename) that container to be able to reuse that name. 关于什么情况下会产生同名容器，这个有待研究。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-error/",
	"title": "Pod 一直处于 Error 状态",
	"tags": [],
	"description": "",
	"content": "TODO: 展开优化\n通常处于 Error 状态说明 Pod 启动过程中发生了错误。常见的原因包括：\n 依赖的 ConfigMap、Secret 或者 PV 等不存在 请求的资源超过了管理员设置的限制，比如超过了 LimitRange 等 违反集群的安全策略，比如违反了 PodSecurityPolicy 等 容器无权操作集群内的资源，比如开启 RBAC 后，需要为 ServiceAccount 配置角色绑定  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-imageinspecterror/",
	"title": "Pod 一直处于 ImageInspectError 状态",
	"tags": [],
	"description": "",
	"content": "通常是镜像文件损坏了，可以尝试删除损坏的镜像重新拉取\nTODO: 完善\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-imagepullbackoff/",
	"title": "Pod 一直处于 ImagePullBackOff 状态",
	"tags": [],
	"description": "",
	"content": "http 类型 registry，地址未加入到 insecure-registry dockerd 默认从 https 类型的 registry 拉取镜像，如果使用 https 类型的 registry，则必须将它添加到 insecure-registry 参数中，然后重启或 reload dockerd 生效。\nhttps 自签发类型 resitry，没有给节点添加 ca 证书 如果 registry 是 https 类型，但证书是自签发的，dockerd 会校验 registry 的证书，校验成功才能正常使用镜像仓库，要想校验成功就需要将 registry 的 ca 证书放置到 /etc/docker/certs.d/\u0026lt;registry:port\u0026gt;/ca.crt 位置。\n私有镜像仓库认证失败 如果 registry 需要认证，但是 Pod 没有配置 imagePullSecret，配置的 Secret 不存在或者有误都会认证失败。\n镜像文件损坏 如果 push 的镜像文件损坏了，下载下来也用不了，需要重新 push 镜像文件。\n镜像拉取超时 如果节点上新起的 Pod 太多就会有许多可能会造成容器镜像下载排队，如果前面有许多大镜像需要下载很长时间，后面排队的 Pod 就会报拉取超时。\nkubelet 默认串行下载镜像:\n--serialize-image-pulls Pull images one at a time. We recommend *not* changing the default value on nodes that run docker daemon with version \u0026lt; 1.9 or an Aufs storage backend. Issue #10959 has more details. (default true) 也可以开启并行下载并控制并发:\n--registry-qps int32 If \u0026gt; 0, limit registry pull QPS to this value. If 0, unlimited. (default 5) --registry-burst int32 Maximum size of a bursty pulls, temporarily allows pulls to burst to this number, while still not exceeding registry-qps. Only used if --registry-qps \u0026gt; 0 (default 10) 镜像不不存在 kubelet 日志:\nPullImage \u0026#34;imroc/test:v0.2\u0026#34; from image service failed: rpc error: code = Unknown desc = Error response from daemon: manifest for imroc/test:v0.2 not found "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-pending/",
	"title": "Pod 一直处于 Pending 状态",
	"tags": [],
	"description": "",
	"content": "Pending 状态说明 Pod 还没有被调度到某个节点上，需要看下 Pod 事件进一步判断原因，比如:\n$ kubectl describe pod tikv-0 ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 3m (x106 over 33m) default-scheduler 0/4 nodes are available: 1 node(s) had no available volume zone, 2 Insufficient cpu, 3 Insufficient memory. 下面列举下可能原因和解决方法。\n节点资源不够 节点资源不够有以下几种情况:\n CPU 负载过高 剩余可以被分配的内存不够 剩余可用 GPU 数量不够 (通常在机器学习场景，GPU 集群环境)  如果判断某个 Node 资源是否足够？ 通过 kubectl describe node \u0026lt;node-name\u0026gt; 查看 node 资源情况，关注以下信息：\n Allocatable: 表示此节点能够申请的资源总和 Allocated resources: 表示此节点已分配的资源 (Allocatable 减去节点上所有 Pod 总的 Request)  前者与后者相减，可得出剩余可申请的资源。如果这个值小于 Pod 的 request，就不满足 Pod 的资源要求，Scheduler 在 Predicates (预选) 阶段就会剔除掉这个 Node，也就不会调度上去。\n不满足 nodeSelector 与 affinity 如果 Pod 包含 nodeSelector 指定了节点需要包含的 label，调度器将只会考虑将 Pod 调度到包含这些 label 的 Node 上，如果没有 Node 有这些 label 或者有这些 label 的 Node 其它条件不满足也将会无法调度。参考官方文档：https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n如果 Pod 包含 affinity（亲和性）的配置，调度器根据调度算法也可能算出没有满足条件的 Node，从而无法调度。affinity 有以下几类:\n nodeAffinity: 节点亲和性，可以看成是增强版的 nodeSelector，用于限制 Pod 只允许被调度到某一部分 Node。 podAffinity: Pod 亲和性，用于将一些有关联的 Pod 调度到同一个地方，同一个地方可以是指同一个节点或同一个可用区的节点等。 podAntiAffinity: Pod 反亲和性，用于避免将某一类 Pod 调度到同一个地方避免单点故障，比如将集群 DNS 服务的 Pod 副本都调度到不同节点，避免一个节点挂了造成整个集群 DNS 解析失败，使得业务中断。  Node 存在 Pod 没有容忍的污点 如果节点上存在污点 (Taints)，而 Pod 没有响应的容忍 (Tolerations)，Pod 也将不会调度上去。通过 describe node 可以看下 Node 有哪些 Taints:\n$ kubectl describe nodes host1 ... Taints: special=true:NoSchedule ... 通常解决方法有两个:\n 删除污点:  kubectl taint nodes host1 special- 给 Pod 加上这个污点的容忍:  tolerations: - key: \u0026#34;special\u0026#34; operator: \u0026#34;Equal\u0026#34; value: \u0026#34;true\u0026#34; effect: \u0026#34;NoSchedule\u0026#34; 我们通常使用后者的方法来解决。污点既可以是手动添加也可以是被自动添加，下面来深入分析一下。\n手动添加的污点 通过类似以下方式可以给节点添加污点:\n$ kubectl taint node host1 special=true:NoSchedule node \u0026#34;host1\u0026#34; tainted 另外，有些场景下希望新加的节点默认不调度 Pod，直到调整完节点上某些配置才允许调度，就给新加的节点都加上 node.kubernetes.io/unschedulable 这个污点。\n自动添加的污点 如果节点运行状态不正常，污点也可以被自动添加，从 v1.12 开始，TaintNodesByCondition 特性进入 Beta 默认开启，controller manager 会检查 Node 的 Condition，如果命中条件就自动为 Node 加上相应的污点，这些 Condition 与 Taints 的对应关系如下:\nConditon Value Taints -------- ----- ------ OutOfDisk True node.kubernetes.io/out-of-disk Ready False node.kubernetes.io/not-ready Ready Unknown node.kubernetes.io/unreachable MemoryPressure True node.kubernetes.io/memory-pressure PIDPressure True node.kubernetes.io/pid-pressure DiskPressure True node.kubernetes.io/disk-pressure NetworkUnavailable True node.kubernetes.io/network-unavailable 解释下上面各种条件的意思:\n OutOfDisk 为 True 表示节点磁盘空间不够了 Ready 为 False 表示节点不健康 Ready 为 Unknown 表示节点失联，在 node-monitor-grace-period 这么长的时间内没有上报状态 controller-manager 就会将 Node 状态置为 Unknown (默认 40s) MemoryPressure 为 True 表示节点内存压力大，实际可用内存很少 PIDPressure 为 True 表示节点上运行了太多进程，PID 数量不够用了 DiskPressure 为 True 表示节点上的磁盘可用空间太少了 NetworkUnavailable 为 True 表示节点上的网络没有正确配置，无法跟其它 Pod 正常通信  另外，在云环境下，比如腾讯云 TKE，添加新节点会先给这个 Node 加上 node.cloudprovider.kubernetes.io/uninitialized 的污点，等 Node 初始化成功后才自动移除这个污点，避免 Pod 被调度到没初始化好的 Node 上。\n低版本 kube-scheduler 的 bug 可能是低版本 kube-scheduler 的 bug, 可以升级下调度器版本。\nkube-scheduler 没有正常运行 检查 maser 上的 kube-scheduler 是否运行正常，异常的话可以尝试重启临时恢复。\n驱逐后其它可用节点与当前节点有状态应用不在同一个可用区 有时候服务部署成功运行过，但在某个时候节点突然挂了，此时就会触发驱逐，创建新的副本调度到其它节点上，对于已经挂载了磁盘的 Pod，它通常需要被调度到跟当前节点和磁盘在同一个可用区，如果集群中同一个可用区的节点不满足调度条件，即使其它可用区节点各种条件都满足，但不跟当前节点在同一个可用区，也是不会调度的。为什么需要限制挂载了磁盘的 Pod 不能漂移到其它可用区的节点？试想一下，云上的磁盘虽然可以被动态挂载到不同机器，但也只是相对同一个数据中心，通常不允许跨数据中心挂载磁盘设备，因为网络时延会极大的降低 IO 速率。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-terminating/",
	"title": "Pod 一直处于 Terminating 状态",
	"tags": [],
	"description": "",
	"content": "磁盘爆满 如果 docker 的数据目录所在磁盘被写满，docker 无法正常运行，无法进行删除和创建操作，所以 kubelet 调用 docker 删除容器没反应，看 event 类似这样：\nNormal Killing 39s (x735 over 15h) kubelet, 10.179.80.31 Killing container with id docker://apigateway:Need to kill Pod 处理建议是参考本书 处理实践：磁盘爆满\n存在 \u0026ldquo;i\u0026rdquo; 文件属性 如果容器的镜像本身或者容器启动后写入的文件存在 \u0026ldquo;i\u0026rdquo; 文件属性，此文件就无法被修改删除，而删除 Pod 时会清理容器目录，但里面包含有不可删除的文件，就一直删不了，Pod 状态也将一直保持 Terminating，kubelet 报错:\nSep 27 14:37:21 VM_0_7_centos kubelet[14109]: E0927 14:37:21.922965 14109 remote_runtime.go:250] RemoveContainer \u0026quot;19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\u0026quot; from runtime service failed: rpc error: code = Unknown desc = failed to remove container \u0026quot;19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\u0026quot;: Error response from daemon: container 19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257: driver \u0026quot;overlay2\u0026quot; failed to remove root filesystem: remove /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash: operation not permitted Sep 27 14:37:21 VM_0_7_centos kubelet[14109]: E0927 14:37:21.923027 14109 kuberuntime_gc.go:126] Failed to remove container \u0026quot;19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\u0026quot;: rpc error: code = Unknown desc = failed to remove container \u0026quot;19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\u0026quot;: Error response from daemon: container 19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257: driver \u0026quot;overlay2\u0026quot; failed to remove root filesystem: remove /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash: operation not permitted 通过 man chattr 查看 \u0026ldquo;i\u0026rdquo; 文件属性描述:\nA file with the \u0026#39;i\u0026#39; attribute cannot be modified: it cannot be deleted or renamed, no link can be created to this file and no data can be written to the file. Only the superuser or a process possessing the CAP_LINUX_IMMUTABLE capability can set or clear this attribute. 彻底解决当然是不要在容器镜像中或启动后的容器设置 \u0026ldquo;i\u0026rdquo; 文件属性，临时恢复方法： 复制 kubelet 日志报错提示的文件路径，然后执行 chattr -i \u0026lt;file\u0026gt;:\nchattr -i /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash 执行完后等待 kubelet 自动重试，Pod 就可以被自动删除了。\ndocker 17 的 bug docker hang 住，没有任何响应，看 event:\nWarning FailedSync 3m (x408 over 1h) kubelet, 10.179.80.31 error determining status: rpc error: code = DeadlineExceeded desc = context deadline exceeded 怀疑是17版本dockerd的BUG。可通过 kubectl -n cn-staging delete pod apigateway-6dc48bf8b6-clcwk --force --grace-period=0 强制删除pod，但 docker ps 仍看得到这个容器\n处置建议：\n 升级到docker 18. 该版本使用了新的 containerd，针对很多bug进行了修复。 如果出现terminating状态的话，可以提供让容器专家进行排查，不建议直接强行删除，会可能导致一些业务上问题。  存在 Finalizers k8s 资源的 metadata 里如果存在 finalizers，那么该资源一般是由某程序创建的，并且在其创建的资源的 metadata 里的 finalizers 加了一个它的标识，这意味着这个资源被删除时需要由创建资源的程序来做删除前的清理，清理完了它需要将标识从该资源的 finalizers 中移除，然后才会最终彻底删除资源。比如 Rancher 创建的一些资源就会写入 finalizers 标识。\n处理建议：kubectl edit 手动编辑资源定义，删掉 finalizers，这时再看下资源，就会发现已经删掉了\n低版本 kubelet list-watch 的 bug 之前遇到过使用 v1.8.13 版本的 k8s，kubelet 有时 list-watch 出问题，删除 pod 后 kubelet 没收到事件，导致 kubelet 一直没做删除操作，所以 pod 状态一直是 Terminating\ndockerd 与 containerd 的状态不同步 判断 dockerd 与 containerd 某个容器的状态不同步的方法：\n describe pod 拿到容器 id docker ps 查看的容器状态是 dockerd 中保存的状态 通过 docker-container-ctr 查看容器在 containerd 中的状态，比如: $ docker-container-ctr --namespace moby --address /var/run/docker/containerd/docker-containerd.sock task ls |grep a9a1785b81343c3ad2093ad973f4f8e52dbf54823b8bb089886c8356d4036fe0 a9a1785b81343c3ad2093ad973f4f8e52dbf54823b8bb089886c8356d4036fe0 30639 STOPPED   containerd 看容器状态是 stopped 或者已经没有记录，而 docker 看容器状态却是 runing，说明 dockerd 与 containerd 之间容器状态同步有问题，目前发现了 docker 在 aufs 存储驱动下如果磁盘爆满可能发生内核 panic :\naufs au_opts_verify:1597:dockerd[5347]: dirperm1 breaks the protection by the permission bits on the lower branch 如果磁盘爆满过，dockerd 一般会有下面类似的日志:\nSep 18 10:19:49 VM-1-33-ubuntu dockerd[4822]: time=\u0026quot;2019-09-18T10:19:49.903943652+08:00\u0026quot; level=error msg=\u0026quot;Failed to log msg \\\u0026quot;\\\u0026quot; for logger json-file: write /opt/docker/containers/54922ec8b1863bcc504f6dac41e40139047f7a84ff09175d2800100aaccbad1f/54922ec8b1863bcc504f6dac41e40139047f7a84ff09175d2800100aaccbad1f-json.log: no space left on device\u0026quot; 随后可能发生状态不同步，已提issue: https://github.com/docker/for-linux/issues/779\n 临时恢复: 执行 docker container prune 或重启 dockerd 长期方案: 运行时推荐直接使用 containerd，绕过 dockerd 避免 docker 本身的各种 BUG  Daemonset Controller 的 BUG 有个 k8s 的 bug 会导致 daemonset pod 无限 terminating，1.10 和 1.11 版本受影响，原因是 daemonset controller 复用 scheduler 的 predicates 逻辑，里面将 nodeAffinity 的 nodeSelector 数组做了排序（传的指针），spec 就会跟 apiserver 中的不一致，daemonset controller 又会为 rollingUpdate类型计算 hash (会用到spec)，用于版本控制，造成不一致从而无限启动和停止的循环。\n issue: https://github.com/kubernetes/kubernetes/issues/66298 修复的PR: https://github.com/kubernetes/kubernetes/pull/66480  升级集群版本可以彻底解决，临时规避可以给 rollingUpdate 类型 daemonset 不使用 nodeAffinity，改用 nodeSelector。\nmount 的目录被其它进程占用 dockerd 报错 device or resource busy:\nMay 09 09:55:12 VM_0_21_centos dockerd[6540]: time=\u0026#34;2020-05-09T09:55:12.774467604+08:00\u0026#34; level=error msg=\u0026#34;Handler for DELETE /v1.38/containers/b62c3796ea2ed5a0bd0eeed0e8f041d12e430a99469dd2ced6f94df911e35905 returned error: container b62c3796ea2ed5a0bd0eeed0e8f041d12e430a99469dd2ced6f94df911e35905: driver \\\u0026#34;overlay2\\\u0026#34; failed to remove root filesystem: remove /data/docker/overlay2/8bde3ec18c5a6915f40dd8adc3b2f296c1e40cc1b2885db4aee0a627ff89ef59/merged: device or resource busy\u0026#34; 查找还有谁在\u0026quot;霸占\u0026quot;此目录:\n$ grep 8bde3ec18c5a6915f40dd8adc3b2f296c1e40cc1b2885db4aee0a627ff89ef59 /proc/*/mountinfo /proc/27187/mountinfo:4500 4415 0:898 / /var/lib/docker/overlay2/8bde3ec18c5a6915f40dd8adc3b2f296c1e40cc1b2885db4aee0a627ff89ef59/merged rw,relatime - overlay overlay rw,lowerdir=/data/docker/overlay2/l/DNQH6VPJHFFANI36UDKS262BZK:/data/docker/overlay2/l/OAYZKUKWNH7GPT4K5MFI6B7OE5:/data/docker/overlay2/l/ANQD5O27DRMTZJG7CBHWUA65YT:/data/docker/overlay2/l/G4HYAKVIRVUXB6YOXRTBYUDVB3:/data/docker/overlay2/l/IRGHNAKBHJUOKGLQBFBQTYFCFU:/data/docker/overlay2/l/6QG67JLGKMFXGVB5VCBG2VYWPI:/data/docker/overlay2/l/O3X5VFRX2AO4USEP2ZOVNLL4ZK:/data/docker/overlay2/l/H5Q5QE6DMWWI75ALCIHARBA5CD:/data/docker/overlay2/l/LFISJNWBKSRTYBVBPU6PH3YAAZ:/data/docker/overlay2/l/JSF6H5MHJEC4VVAYOF5PYIMIBQ:/data/docker/overlay2/l/7D2F45I5MF2EHDOARROYPXCWHZ:/data/docker/overlay2/l/OUJDAGNIZXVBKBWNYCAUI5YSGG:/data/docker/overlay2/l/KZLUO6P3DBNHNUH2SNKPTFZOL7:/data/docker/overlay2/l/O2BPSFNCVXTE4ZIWGYSRPKAGU4,upperdir=/data/docker/overlay2/8bde3ec18c5a6915f40dd8adc3b2f296c1e40cc1b2885db4aee0a627ff89ef59/diff,workdir=/data/docker/overlay2/8bde3ec18c5a6915f40dd8adc3b2f296c1e40cc1b2885db4aee0a627ff89ef59/work /proc/27187/mountinfo:4688 4562 0:898 / /var/lib/docker/overlay2/81c322896bb06149c16786dc33c83108c871bb368691f741a1e3a9bfc0a56ab2/merged/data/docker/overlay2/8bde3ec18c5a6915f40dd8adc3b2f296c1e40cc1b2885db4aee0a627ff89ef59/merged rw,relatime - overlay overlay rw,lowerdir=/data/docker/overlay2/l/DNQH6VPJHFFANI36UDKS262BZK:/data/docker/overlay2/l/OAYZKUKWNH7GPT4K5MFI6B7OE5:/data/docker/overlay2/l/ANQD5O27DRMTZJG7CBHWUA65YT:/data/docker/overlay2/l/G4HYAKVIRVUXB6YOXRTBYUDVB3:/data/docker/overlay2/l/IRGHNAKBHJUOKGLQBFBQTYFCFU:/data/docker/overlay2/l/6QG67JLGKMFXGVB5VCBG2VYWPI:/data/docker/overlay2/l/O3X5VFRX2AO4USEP2ZOVNLL4ZK:/data/docker/overlay2/l/H5Q5QE6DMWWI75ALCIHARBA5CD:/data/docker/overlay2/l/LFISJNWBKSRTYBVBPU6PH3YAAZ:/data/docker/overlay2/l/JSF6H5MHJEC4VVAYOF5PYIMIBQ:/data/docker/overlay2/l/7D2F45I5MF2EHDOARROYPXCWHZ:/data/docker/overlay2/l/OUJDAGNIZXVBKBWNYCAUI5YSGG:/data/docker/overlay2/l/KZLUO6P3DBNHNUH2SNKPTFZOL7:/data/docker/overlay2/l/O2BPSFNCVXTE4ZIWGYSRPKAGU4,upperdir=/data/docker/overlay2/8bde3ec18c5a6915f40dd8adc3b2f296c1e40cc1b2885db4aee0a627ff89ef59/diff,workdir=/data/docker/overlay2/8bde3ec18c5a6915f40dd8adc3b2f296c1e40cc1b2885db4aee0a627ff89ef59/work  自行替换容器 id\n 找到进程号后查看此进程更多详细信息:\nps -f 27187 "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-unkown/",
	"title": "Pod 一直处于 Unknown 状态",
	"tags": [],
	"description": "",
	"content": "TODO: 完善\n通常是节点失联，没有上报状态给 apiserver，到达阀值后 controller-manager 认为节点失联并将其状态置为 Unknown。\n可能原因:\n 节点高负载导致无法上报 节点宕机 节点被关机 网络不通  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/healthcheck-failed/",
	"title": "Pod 健康检查失败",
	"tags": [],
	"description": "",
	"content": " Kubernetes 健康检查包含就绪检查(readinessProbe)和存活检查(livenessProbe) pod 如果就绪检查失败会将此 pod ip 从 service 中摘除，通过 service 访问，流量将不会被转发给就绪检查失败的 pod pod 如果存活检查失败，kubelet 将会杀死容器并尝试重启  健康检查失败的可能原因有多种，除了业务程序BUG导致不能响应健康检查导致 unhealthy，还能有有其它原因，下面我们来逐个排查。\n健康检查配置不合理 initialDelaySeconds 太短，容器启动慢，导致容器还没完全启动就开始探测，如果 successThreshold 是默认值 1，检查失败一次就会被 kill，然后 pod 一直这样被 kill 重启。\n节点负载过高 cpu 占用高（比如跑满）会导致进程无法正常发包收包，通常会 timeout，导致 kubelet 认为 pod 不健康。参考本书 处理实践: 高负载 一节。\n容器进程被木马进程杀死 参考本书 处理实践: 使用 systemtap 定位疑难杂症 进一步定位。\n容器内进程端口监听挂掉 使用 netstat -tunlp 检查端口监听是否还在，如果不在了，抓包可以看到会直接 reset 掉健康检查探测的连接:\n20:15:17.890996 IP 172.16.2.1.38074 \u0026gt; 172.16.2.23.8888: Flags [S], seq 96880261, win 14600, options [mss 1424,nop,nop,sackOK,nop,wscale 7], length 0 20:15:17.891021 IP 172.16.2.23.8888 \u0026gt; 172.16.2.1.38074: Flags [R.], seq 0, ack 96880262, win 0, length 0 20:15:17.906744 IP 10.0.0.16.54132 \u0026gt; 172.16.2.23.8888: Flags [S], seq 1207014342, win 14600, options [mss 1424,nop,nop,sackOK,nop,wscale 7], length 0 20:15:17.906766 IP 172.16.2.23.8888 \u0026gt; 10.0.0.16.54132: Flags [R.], seq 0, ack 1207014343, win 0, length 0 连接异常，从而健康检查失败。发生这种情况的原因可能在一个节点上启动了多个使用 hostNetwork 监听相同宿主机端口的 Pod，只会有一个 Pod 监听成功，但监听失败的 Pod 的业务逻辑允许了监听失败，并没有退出，Pod 又配了健康检查，kubelet 就会给 Pod 发送健康检查探测报文，但 Pod 由于没有监听所以就会健康检查失败。\nSYN backlog 设置过小 SYN backlog 大小即 SYN 队列大小，如果短时间内新建连接比较多，而 SYN backlog 设置太小，就会导致新建连接失败，通过 netstat -s | grep TCPBacklogDrop 可以看到有多少是因为 backlog 满了导致丢弃的新连接。\n如果确认是 backlog 满了导致的丢包，建议调高 backlog 的值，内核参数为 net.ipv4.tcp_max_syn_backlog。\n"
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/livenesprobe-failed-occasionally/",
	"title": "Pod 偶尔存活检查失败",
	"tags": [],
	"description": "",
	"content": "现象: Pod 偶尔会存活检查失败，导致 Pod 重启，业务偶尔连接异常。\n之前从未遇到这种情况，在自己测试环境尝试复现也没有成功，只有在用户这个环境才可以复现。这个用户环境流量较大，感觉跟连接数或并发量有关。\n用户反馈说在友商的环境里没这个问题。\n对比友商的内核参数发现有些区别，尝试将节点内核参数改成跟友商的一样，发现问题没有复现了。\n再对比分析下内核参数差异，最后发现是 backlog 太小导致的，节点的 net.ipv4.tcp_max_syn_backlog 默认是 1024，如果短时间内并发新建 TCP 连接太多，SYN 队列就可能溢出，导致部分新连接无法建立。\n解释一下:\nTCP 连接建立会经过三次握手，server 收到 SYN 后会将连接加入 SYN 队列，当收到最后一个 ACK 后连接建立，这时会将连接从 SYN 队列中移动到 ACCEPT 队列。在 SYN 队列中的连接都是没有建立完全的连接，处于半连接状态。如果 SYN 队列比较小，而短时间内并发新建的连接比较多，同时处于半连接状态的连接就多，SYN 队列就可能溢出，tcp_max_syn_backlog 可以控制 SYN 队列大小，用户节点的 backlog 大小默认是 1024，改成 8096 后就可以解决问题。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-crashloopbackoff/",
	"title": "Pod 处于 CrashLoopBackOff 状态",
	"tags": [],
	"description": "",
	"content": "Pod 如果处于 CrashLoopBackOff 状态说明之前是启动了，只是又异常退出了，只要 Pod 的 restartPolicy 不是 Never 就可能被重启拉起，此时 Pod 的 RestartCounts 通常是大于 0 的，可以先看下容器进程的退出状态码来缩小问题范围，参考本书 排错技巧: 分析 ExitCode 定位 Pod 异常退出原因\n容器进程主动退出 如果是容器进程主动退出，退出状态码一般在 0-128 之间，除了可能是业务程序 BUG，还有其它许多可能原因，参考: 容器进程主动退出\n系统 OOM 如果发生系统 OOM，可以看到 Pod 中容器退出状态码是 137，表示被 SIGKILL 信号杀死，同时内核会报错: Out of memory: Kill process ...。大概率是节点上部署了其它非 K8S 管理的进程消耗了比较多的内存，或者 kubelet 的 --kube-reserved 和 --system-reserved 配的比较小，没有预留足够的空间给其它非容器进程，节点上所有 Pod 的实际内存占用总量不会超过 /sys/fs/cgroup/memory/kubepods 这里 cgroup 的限制，这个限制等于 capacity - \u0026quot;kube-reserved\u0026quot; - \u0026quot;system-reserved\u0026quot;，如果预留空间设置合理，节点上其它非容器进程（kubelet, dockerd, kube-proxy, sshd 等) 内存占用没有超过 kubelet 配置的预留空间是不会发生系统 OOM 的，可以根据实际需求做合理的调整。\ncgroup OOM 如果是 cgrou OOM 杀掉的进程，从 Pod 事件的下 Reason 可以看到是 OOMKilled，说明容器实际占用的内存超过 limit 了，同时内核日志会报: Memory cgroup out of memory。 可以根据需求调整下 limit。\n节点内存碎片化 如果节点上内存碎片化严重，缺少大页内存，会导致即使总的剩余内存较多，但还是会申请内存失败，参考 处理实践: 内存碎片化\n健康检查失败 参考 Pod 健康检查失败 进一步定位。\n"
},
{
	"uri": "https://k8s.imroc.io/trick/shell/pod/",
	"title": "Pod 相关脚本",
	"tags": [],
	"description": "",
	"content": "清理 Evicted 的 pod kubectl get pod -o wide --all-namespaces | awk \u0026#39;{if($4==\u0026#34;Evicted\u0026#34;){cmd=\u0026#34;kubectl -n \u0026#34;$1\u0026#34; delete pod \u0026#34;$2; system(cmd)}}\u0026#39; 清理非 Running 的 pod kubectl get pod -o wide --all-namespaces | awk \u0026#39;{if($4!=\u0026#34;Running\u0026#34;){cmd=\u0026#34;kubectl -n \u0026#34;$1\u0026#34; delete pod \u0026#34;$2; system(cmd)}}\u0026#39; 升级镜像 NAMESPACE=\u0026#34;kube-system\u0026#34; WORKLOAD_TYPE=\u0026#34;daemonset\u0026#34; WORKLOAD_NAME=\u0026#34;ip-masq-agent\u0026#34; CONTAINER_NAME=\u0026#34;ip-masq-agent\u0026#34; IMAGE=\u0026#34;ccr.ccs.tencentyun.com/library/ip-masq-agent:v2.5.0\u0026#34; kubectl -n $NAMESPACE patch $WORKLOAD_TYPE $WORKLOAD_NAME --patch \u0026#39;{\u0026#34;spec\u0026#34;: {\u0026#34;template\u0026#34;: {\u0026#34;spec\u0026#34;: {\u0026#34;containers\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;$CONTAINER_NAME\u0026#34;,\u0026#34;image\u0026#34;: \u0026#34;$IMAGE\u0026#34; }]}}}}\u0026#39; "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/high-legacy-from-pod-to-another-apiserver/",
	"title": "Pod 访问另一个集群的 apiserver 有延时",
	"tags": [],
	"description": "",
	"content": "现象：集群 a 的 Pod 内通过 kubectl 访问集群 b 的内网地址，偶尔出现延时的情况，但直接在宿主机上用同样的方法却没有这个问题。\n提炼环境和现象精髓:\n 在 pod 内将另一个集群 apiserver 的 ip 写到了 hosts，因为 TKE apiserver 开启内网集群外内网访问创建的内网 LB 暂时没有支持自动绑内网 DNS 域名解析，所以集群外的内网访问 apiserver 需要加 hosts pod 内执行 kubectl 访问另一个集群偶尔延迟 5s，有时甚至10s  观察到 5s 延时，感觉跟之前 conntrack 的丢包导致 DNS 解析 5S 延时 有关，但是加了 hosts 呀，怎么还去解析域名？\n进入 pod netns 抓包: 执行 kubectl 时确实有 dns 解析，并且发生延时的时候 dns 请求没有响应然后做了重试。\n看起来延时应该就是之前已知 conntrack 丢包导致 dns 5s 超时重试导致的。但是为什么会去解析域名? 明明配了 hosts 啊，正常情况应该是优先查找 hosts，没找到才去请求 dns 呀，有什么配置可以控制查找顺序?\n搜了一下发现: /etc/nsswitch.conf 可以控制，但看有问题的 pod 里没有这个文件。然后观察到有问题的 pod 用的 alpine 镜像，试试其它镜像后发现只有基于 alpine 的镜像才会有这个问题。\n再一搜发现: musl libc 并不会使用 /etc/nsswitch.conf ，也就是说 alpine 镜像并没有实现用这个文件控制域名查找优先顺序，瞥了一眼 musl libc 的 gethostbyname 和 getaddrinfo 的实现，看起来也没有读这个文件来控制查找顺序，写死了先查 hosts，没找到再查 dns。\n这么说，那还是该先查 hosts 再查 dns 呀，为什么这里抓包看到是先查的 dns? (如果是先查 hosts 就能命中查询，不会再发起dns请求)\n访问 apiserver 的 client 是 kubectl，用 go 写的，会不会是 go 程序解析域名时压根没调底层 c 库的 gethostbyname 或 getaddrinfo?\n搜一下发现果然是这样: go runtime 用 go 实现了 glibc 的 getaddrinfo 的行为来解析域名，减少了 c 库调用 (应该是考虑到减少 cgo 调用带来的的性能损耗)\nissue: net: replicate DNS resolution behaviour of getaddrinfo(glibc) in the go dns resolver\n翻源码验证下:\nUnix 系的 OS 下，除了 openbsd， go runtime 会读取 /etc/nsswitch.conf (net/conf.go):\nif runtime.GOOS != \u0026#34;openbsd\u0026#34; { confVal.nss = parseNSSConfFile(\u0026#34;/etc/nsswitch.conf\u0026#34;) } hostLookupOrder 函数决定域名解析顺序的策略，Linux 下，如果没有 nsswitch.conf 文件就 dns 比 hosts 文件优先 (net/conf.go):\n// hostLookupOrder determines which strategy to use to resolve hostname. // The provided Resolver is optional. nil means to not consider its options. func (c *conf) hostLookupOrder(r *Resolver, hostname string) (ret hostLookupOrder) { ...... // If /etc/nsswitch.conf doesn\u0026#39;t exist or doesn\u0026#39;t specify any \t// sources for \u0026#34;hosts\u0026#34;, assume Go\u0026#39;s DNS will work fine. \tif os.IsNotExist(nss.err) || (nss.err == nil \u0026amp;\u0026amp; len(srcs) == 0) { ...... if c.goos == \u0026#34;linux\u0026#34; { // glibc says the default is \u0026#34;dns [!UNAVAIL=return] files\u0026#34; \t// https://www.gnu.org/software/libc/manual/html_node/Notes-on-NSS-Configuration-File.html. \treturn hostLookupDNSFiles } return hostLookupFilesDNS } 可以看到 hostLookupDNSFiles 的意思是 dns first (net/dnsclient_unix.go):\n// hostLookupOrder specifies the order of LookupHost lookup strategies. // It is basically a simplified representation of nsswitch.conf. // \u0026#34;files\u0026#34; means /etc/hosts. type hostLookupOrder int const ( // hostLookupCgo means defer to cgo. \thostLookupCgo hostLookupOrder = iota hostLookupFilesDNS // files first \thostLookupDNSFiles // dns first \thostLookupFiles // only files \thostLookupDNS // only DNS ) var lookupOrderName = map[hostLookupOrder]string{ hostLookupCgo: \u0026#34;cgo\u0026#34;, hostLookupFilesDNS: \u0026#34;files,dns\u0026#34;, hostLookupDNSFiles: \u0026#34;dns,files\u0026#34;, hostLookupFiles: \u0026#34;files\u0026#34;, hostLookupDNS: \u0026#34;dns\u0026#34;, } 所以虽然 alpine 用的 musl libc 不是 glibc，但 go 程序解析域名还是一样走的 glibc 的逻辑，而 alpine 没有 /etc/nsswitch.conf 文件，也就解释了为什么 kubectl 访问 apiserver 先做 dns 解析，没解析到再查的 hosts，导致每次访问都去请求 dns，恰好又碰到 conntrack 那个丢包问题导致 dns 5s 延时，在用户这里表现就是 pod 内用 kubectl 访问 apiserver 偶尔出现 5s 延时，有时出现 10s 是因为重试的那次 dns 请求刚好也遇到 conntrack 丢包导致延时又叠加了 5s 。\n解决方案:\n 换基础镜像，不用 alpine 挂载 nsswitch.conf 文件 (可以用 hostPath)  "
},
{
	"uri": "https://k8s.imroc.io/reference/",
	"title": "References",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/service-unrecheable/",
	"title": "Service 不通",
	"tags": [],
	"description": "",
	"content": "集群 dns 故障 TODO\n节点防火墙没放开集群容器网络 (iptables/安全组) TODO\nkube-proxy 没有工作，命中 netlink deadlock 的 bug  issue: https://github.com/kubernetes/kubernetes/issues/71071 1.14 版本已修复，修复的 PR: https://github.com/kubernetes/kubernetes/pull/72361  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/service-cannot-resolve/",
	"title": "Service 无法解析",
	"tags": [],
	"description": "",
	"content": "集群 DNS 没有正常运行(kube-dns或CoreDNS) 检查集群 DNS 是否运行正常:\n kubelet 启动参数 --cluster-dns 可以看到 dns 服务的 cluster ip:  $ ps -ef | grep kubelet ... /usr/bin/kubelet --cluster-dns=172.16.14.217 ...  找到 dns 的 service:  $ kubectl get svc -n kube-system | grep 172.16.14.217 kube-dns ClusterIP 172.16.14.217 \u0026lt;none\u0026gt; 53/TCP,53/UDP 47d  看是否存在 endpoint:  $ kubectl -n kube-system describe svc kube-dns | grep -i endpoints Endpoints: 172.16.0.156:53,172.16.0.167:53 Endpoints: 172.16.0.156:53,172.16.0.167:53  检查 endpoint 的 对应 pod 是否正常:  $ kubectl -n kube-system get pod -o wide | grep 172.16.0.156 kube-dns-898dbbfc6-hvwlr 3/3 Running 0 8d 172.16.0.156 10.0.0.3 Pod 与 DNS 服务之间网络不通 检查下 pod 是否连不上 dns 服务，可以在 pod 里 telnet 一下 dns 的 53 端口:\n# 连 dns service 的 cluster ip $ telnet 172.16.14.217 53 如果检查到是网络不通，就需要排查下网络设置:\n 检查节点的安全组设置，需要放开集群的容器网段 检查是否还有防火墙规则，检查 iptables  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/kernel-solft-lockup/",
	"title": "soft lockup (内核软死锁)",
	"tags": [],
	"description": "",
	"content": "内核报错 Oct 14 15:13:05 VM_1_6_centos kernel: NMI watchdog: BUG: soft lockup - CPU#5 stuck for 22s! [runc:[1:CHILD]:2274] 原因 发生这个报错通常是内核繁忙 (扫描、释放或分配大量对象)，分不出时间片给用户态进程导致的，也伴随着高负载，如果负载降低报错则会消失。\n什么情况下会导致内核繁忙  短时间内创建大量进程 (可能是业务需要，也可能是业务bug或用法不正确导致创建大量进程)  参考资料  What are all these \u0026ldquo;Bug: soft lockup\u0026rdquo; messages about : https://www.suse.com/support/kb/doc/?id=7017652  "
},
{
	"uri": "https://k8s.imroc.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/avoid/tcp_tw_recycle-causes-packet-loss/",
	"title": "tcp tw recycle 引发丢包",
	"tags": [],
	"description": "",
	"content": "tcp_tw_recycle 这个内核参数用来快速回收 TIME_WAIT 连接，不过如果在 NAT 环境下会引发问题。\nRFC1323 中有如下一段描述：\nAn additional mechanism could be added to the TCP, a per-host cache of the last timestamp received from any connection. This value could then be used in the PAWS mechanism to reject old duplicate segments from earlier incarnations of the connection, if the timestamp clock can be guaranteed to have ticked at least once since the old connection was open. This would require that the TIME-WAIT delay plus the RTT together must be at least one tick of the sender’s timestamp clock. Such an extension is not part of the proposal of this RFC.\n 大概意思是说TCP有一种行为，可以缓存每个连接最新的时间戳，后续请求中如果时间戳小于缓存的时间戳，即视为无效，相应的数据包会被丢弃。 Linux是否启用这种行为取决于tcp_timestamps和tcp_tw_recycle，因为tcp_timestamps缺省就是开启的，所以当tcp_tw_recycle被开启后，实际上这种行为就被激活了，当客户端或服务端以NAT方式构建的时候就可能出现问题，下面以客户端NAT为例来说明： 当多个客户端通过NAT方式联网并与服务端交互时，服务端看到的是同一个IP，也就是说对服务端而言这些客户端实际上等同于一个，可惜由于这些客户端的时间戳可能存在差异，于是乎从服务端的视角看，便可能出现时间戳错乱的现象，进而直接导致时间戳小的数据包被丢弃。如果发生了此类问题，具体的表现通常是是客户端明明发送的SYN，但服务端就是不响应ACK。 在4.12之后的内核已移除tcp_tw_recycle内核参数: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4396e46187ca5070219b81773c4e65088dac50cc https://github.com/torvalds/linux/commit/4396e46187ca5070219b81773c4e65088dac50cc  "
},
{
	"uri": "https://k8s.imroc.io/cluster/ingress/traefik/",
	"title": "Traefik Ingress",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/trick/yaml/",
	"title": "yaml 片段",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/trick/yaml/affnity/",
	"title": "亲和与反亲和",
	"tags": [],
	"description": "",
	"content": "尽量调度到不同节点 affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: k8s-app operator: In values: - kube-dns topologyKey: kubernetes.io/hostname 必须调度到不同节点 affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - weight: 100 labelSelector: matchExpressions: - key: k8s-app operator: In values: - kube-dns topologyKey: kubernetes.io/hostname 只调度到有指定 label 的节点 affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: matchExpressions: - key: ingress operator: In values: - true "
},
{
	"uri": "https://k8s.imroc.io/deploy/addons/kube-proxy/",
	"title": "以 Daemonset 方式部署 kube-proxy",
	"tags": [],
	"description": "",
	"content": "kube-proxy 可以用二进制部署，也可以用 kubelet 的静态 Pod 部署，但最简单使用 DaemonSet 部署。直接使用 ServiceAccount 的 token 认证，不需要签发证书，也就不用担心证书过期问题。\n先在终端设置下面的变量:\nAPISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; CLUSTER_CIDR=\u0026#34;10.10.0.0/16\u0026#34;  APISERVER 替换为 apiserver 对外暴露的访问地址。有同学想问为什么不直接用集群内的访问地址(kubernetes.default 或对应的 CLUSTER IP)，这是一个鸡生蛋还是蛋生鸡的问题，CLSUTER IP 本身就是由 kube-proxy 来生成 iptables 或 ipvs 规则转发 Service 对应 Endpoint 的 Pod IP，kube-proxy 刚启动还没有生成这些转发规则，生成规则的前提是 kube-proxy 需要访问 apiserver 获取 Service 与 Endpoint，而由于还没有转发规则，kube-proxy 访问 apiserver 的 CLUSTER IP 的请求无法被转发到 apiserver。 CLUSTER_CIDR 替换为集群 Pod IP 的 CIDR 范围，这个在部署 kube-controller-manager 时也设置过  为 kube-proxy 创建 RBAC 权限和配置文件:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: ServiceAccount metadata: name: kube-proxy namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: system:kube-proxy roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:node-proxier subjects: - kind: ServiceAccount name: kube-proxy namespace: kube-system --- kind: ConfigMap apiVersion: v1 metadata: name: kube-proxy namespace: kube-system labels: app: kube-proxy data: kubeconfig.conf: |- apiVersion: v1 kind: Config clusters: - cluster: certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt server: ${APISERVER} name: default contexts: - context: cluster: default namespace: default user: default name: default current-context: default users: - name: default user: tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token config.conf: |- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration bindAddress: 0.0.0.0 clientConnection: acceptContentTypes: \u0026#34;\u0026#34; burst: 10 contentType: application/vnd.kubernetes.protobuf kubeconfig: /var/lib/kube-proxy/kubeconfig.conf qps: 5 # 集群中 Pod IP 的 CIDR 范围 clusterCIDR: ${CLUSTER_CIDR} configSyncPeriod: 15m0s conntrack: # 每个核心最大能跟踪的NAT连接数，默认32768 maxPerCore: 32768 min: 131072 tcpCloseWaitTimeout: 1h0m0s tcpEstablishedTimeout: 24h0m0s enableProfiling: false healthzBindAddress: 0.0.0.0:10256 iptables: # SNAT 所有 Service 的 CLUSTER IP masqueradeAll: false masqueradeBit: 14 minSyncPeriod: 0s syncPeriod: 30s ipvs: minSyncPeriod: 0s # ipvs 调度类型，默认是 rr，支持的所有类型: # rr: round-robin # lc: least connection # dh: destination hashing # sh: source hashing # sed: shortest expected delay # nq: never queue scheduler: rr syncPeriod: 30s metricsBindAddress: 0.0.0.0:10249 # 使用 ipvs 模式转发 service mode: ipvs # 设置 kube-proxy 进程的 oom-score-adj 值，范围 [-1000,1000] # 值越低越不容易被杀死，这里设置为 —999 防止发生系统OOM时将 kube-proxy 杀死 oomScoreAdj: -999 EOF 在终端设置下面的变量:\nARCH=\u0026#34;amd64\u0026#34; VERSION=\u0026#34;v1.16.1\u0026#34;  VERSION 是 K8S 版本 ARCH 是节点的 cpu 架构，大多数用的 amd64，即 x86_64。其它常见的还有: arm64, arm, ppc64le, s390x，如果你的集群有不同 cpu 架构的节点，可以分别指定 ARCH 部署多个 daemonset (每个节点不会有多个 kube-proxy，nodeSelector 会根据 cpu 架构来选中节点)  使用 hostNetwork 以 Daemonset 方式部署 kube-proxy 到每个节点:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: apps/v1 kind: DaemonSet metadata: labels: k8s-app: kube-proxy-ds-${ARCH} name: kube-proxy-ds-${ARCH} namespace: kube-system spec: selector: matchLabels: k8s-app: kube-proxy-ds-${ARCH} updateStrategy: type: RollingUpdate template: metadata: labels: k8s-app: kube-proxy-ds-${ARCH} spec: priorityClassName: system-node-critical containers: - name: kube-proxy image: k8s.gcr.io/kube-proxy-${ARCH}:${VERSION} imagePullPolicy: IfNotPresent command: - /usr/local/bin/kube-proxy - --config=/var/lib/kube-proxy/config.conf - --hostname-override=\\$(NODE_NAME) securityContext: privileged: true volumeMounts: - mountPath: /var/lib/kube-proxy name: kube-proxy - mountPath: /run/xtables.lock name: xtables-lock readOnly: false - mountPath: /lib/modules name: lib-modules readOnly: true env: - name: NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName hostNetwork: true serviceAccountName: kube-proxy volumes: - name: kube-proxy configMap: name: kube-proxy - name: xtables-lock hostPath: path: /run/xtables.lock type: FileOrCreate - name: lib-modules hostPath: path: /lib/modules tolerations: - key: CriticalAddonsOnly operator: Exists - operator: Exists nodeSelector: beta.kubernetes.io/arch: ${ARCH} EOF "
},
{
	"uri": "https://k8s.imroc.io/dev/client-go/",
	"title": "使用 client-go 开发 k8s 应用",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/configuration/helm/",
	"title": "使用 Helm 管理集群资源",
	"tags": [],
	"description": "",
	"content": "  安装 Helm   Helm V2 迁移到 V3   Helm 常见问题   "
},
{
	"uri": "https://k8s.imroc.io/avoid/nodelocal-dns/",
	"title": "使用 NodeLocal DNS (缓存)",
	"tags": [],
	"description": "",
	"content": "为什么需要本地 DNS 缓存   减轻集群 DNS 解析压力，提高 DNS 性能\n  避免 netfilter 做 DNAT 导致 conntrack 冲突引发 DNS 5 秒延时\n 镜像底层库 DNS 解析行为默认使用 UDP 在同一个 socket 并发 A 和 AAAA 记录请求，由于 UDP 无状态，两个请求可能会并发创建 conntrack 表项，如果最终 DNAT 成同一个集群 DNS 的 Pod IP 就会导致 conntrack 冲突，由于 conntrack 的创建和插入是不加锁的，最终后面插入的 conntrack 表项就会被丢弃，从而请求超时，默认 5s 后重试，造成现象就是 DNS 5 秒延时; 底层库是 glibc 的容器镜像可以通过配 resolv.conf 参数来控制 DNS 解析行为，不用 TCP 或者避免相同五元组并发(使用串行解析 A 和 AAAA 避免并发或者使用不同 socket 发请求避免相同源端口)，但像基于 alpine 镜像的容器由于底层库是 musl libc，不支持这些 resolv.conf 参数，也就无法规避，所以最佳方案还是使用本地 DNS 缓存。\n   原理 本地 DNS 缓存以 DaemonSet 方式在每个节点部署一个使用 hostNetwork 的 Pod，创建一个网卡绑上本地 DNS 的 IP，本机的 Pod 的 DNS 请求路由到本地 DNS，然后取缓存或者继续使用 TCP 请求上游集群 DNS 解析。\nIPtables 模式下部署方法 IPVS 模式下需要修改 kubelet 参数 有两点需要注意下:\n ipvs 模式下需要改 kubelet --cluster-dns 参数，指向一个非 kube-dns service 的 IP，通常用 169.254.20.10，Daemonset 会在每个节点创建一个网卡绑这个 IP，Pod 向本节点这个 IP 发 DNS 请求，本机 DNS 再代理到上游集群 DNS iptables 模式下不需要改 kubelet --cluster-dns 参数，Pod 还是向原来的集群 DNS 请求，节点上有这个 IP 监听，被本机拦截，再请求集群上游 DNS (使用集群 DNS 的另一个 CLUSTER IP，来自事先创建好的 Service，跟原集群 DNS 的 Service 有相同的 selector 和 endpoint)  ipvs 模式下必须修改 kubelet 参数的原因是：如果不修改，DaemonSet Pod 在本机创建了网卡，会绑跟集群 DNS 的 CLUSTER IP， 但 kube-ipvs0 这个 dummy interface 上也会绑这个 IP (这是 ipvs 的机制，为了能让报文到达 INPUT 链被 ipvs 处理)，所以 Pod 请求集群 DNS 的报文最终还是会被 ipvs 处理, DNAT 成集群 DNS 的 Pod IP，最终路由到集群 DNS，相当于本机 DNS 就没有作用了。\nIPVS 模式下部署方法 这里我们假设是 ipvs 模式，下面给出本地 DNS 缓存部署方法。\n创建 ServiceAccount 与集群上游 DNS 的 Service:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: ServiceAccount metadata: name: node-local-dns namespace: kube-system labels: kubernetes.io/cluster-service: \u0026#34;true\u0026#34; addonmanager.kubernetes.io/mode: Reconcile --- apiVersion: v1 kind: Service metadata: name: kube-dns-upstream namespace: kube-system labels: k8s-app: kube-dns kubernetes.io/cluster-service: \u0026#34;true\u0026#34; addonmanager.kubernetes.io/mode: Reconcile kubernetes.io/name: \u0026#34;KubeDNSUpstream\u0026#34; spec: ports: - name: dns port: 53 protocol: UDP targetPort: 53 - name: dns-tcp port: 53 protocol: TCP targetPort: 53 selector: k8s-app: kube-dns EOF 获取 kube-dns-upstream 的 CLUSTER IP:\nUPSTREAM_CLUSTER_IP=$(kubectl -n kube-system get services kube-dns-upstream -o jsonpath=\u0026#34;{.spec.clusterIP}\u0026#34;) 部署 DaemonSet:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: ConfigMap metadata: name: node-local-dns namespace: kube-system labels: addonmanager.kubernetes.io/mode: Reconcile data: Corefile: | cluster.local:53 { errors cache { success 9984 30 denial 9984 5 } reload loop bind 169.254.20.10 forward . ${UPSTREAM_CLUSTER_IP} { force_tcp } prometheus :9253 health 169.254.20.10:8080 } in-addr.arpa:53 { errors cache 30 reload loop bind 169.254.20.10 forward . ${UPSTREAM_CLUSTER_IP} { force_tcp } prometheus :9253 } ip6.arpa:53 { errors cache 30 reload loop bind 169.254.20.10 forward . ${UPSTREAM_CLUSTER_IP} { force_tcp } prometheus :9253 } .:53 { errors cache 30 reload loop bind 169.254.20.10 forward . /etc/resolv.conf { force_tcp } prometheus :9253 } --- apiVersion: apps/v1 kind: DaemonSet metadata: name: node-local-dns namespace: kube-system labels: k8s-app: node-local-dns kubernetes.io/cluster-service: \u0026#34;true\u0026#34; addonmanager.kubernetes.io/mode: Reconcile spec: updateStrategy: rollingUpdate: maxUnavailable: 10% selector: matchLabels: k8s-app: node-local-dns template: metadata: labels: k8s-app: node-local-dns spec: priorityClassName: system-node-critical serviceAccountName: node-local-dns hostNetwork: true dnsPolicy: Default # Don\u0026#39;t use cluster DNS. tolerations: - key: \u0026#34;CriticalAddonsOnly\u0026#34; operator: \u0026#34;Exists\u0026#34; containers: - name: node-cache image: k8s.gcr.io/k8s-dns-node-cache:1.15.7 resources: requests: cpu: 25m memory: 5Mi args: [ \u0026#34;-localip\u0026#34;, \u0026#34;169.254.20.10\u0026#34;, \u0026#34;-conf\u0026#34;, \u0026#34;/etc/Corefile\u0026#34;, \u0026#34;-upstreamsvc\u0026#34;, \u0026#34;kube-dns-upstream\u0026#34; ] securityContext: privileged: true ports: - containerPort: 53 name: dns protocol: UDP - containerPort: 53 name: dns-tcp protocol: TCP - containerPort: 9253 name: metrics protocol: TCP livenessProbe: httpGet: host: 169.254.20.10 path: /health port: 8080 initialDelaySeconds: 60 timeoutSeconds: 5 volumeMounts: - mountPath: /run/xtables.lock name: xtables-lock readOnly: false - name: config-volume mountPath: /etc/coredns - name: kube-dns-config mountPath: /etc/kube-dns volumes: - name: xtables-lock hostPath: path: /run/xtables.lock type: FileOrCreate - name: kube-dns-config configMap: name: kube-dns optional: true - name: config-volume configMap: name: node-local-dns items: - key: Corefile path: Corefile.base EOF 验证是否启动:\n$ kubectl -n kube-system get pod -o wide | grep node-local-dns node-local-dns-2m9b6 1/1 Running 0 15m 10.0.0.28 10.0.0.28 node-local-dns-qgrwl 1/1 Running 0 15m 10.0.0.186 10.0.0.186 node-local-dns-s5mhw 1/1 Running 0 51s 10.0.0.76 10.0.0.76 我们需要替换 kubelet 的 --cluster-dns 参数，指向 169.254.20.10 这个 IP。\n在TKE上，对于存量节点，登录节点执行以下命令:\nsed -i \u0026#39;/CLUSTER_DNS/c\\CLUSTER_DNS=\u0026#34;--cluster-dns=169.254.20.10\u0026#34;\u0026#39; /etc/kubernetes/kubelet systemctl restart kubelet 对于增量节点，可以将上述命令放入新增节点的 user-data，以便加入节点后自动执行。\n后续新增才会用到本地 DNS 缓存，对于存量 Pod 可以销毁重建，比如改下 Deployment 中 template 里的 annotation，触发 Deployment 所有 Pod 滚动更新，如果怕滚动更新造成部分流量异常，可以参考 使用 preStopHook 和 readinessProbe 保证服务平滑更新不中断\n参考资料  https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns https://github.com/kubernetes/enhancements/blob/master/keps/sig-network/20190424-NodeLocalDNS-beta-proposal.md  "
},
{
	"uri": "https://k8s.imroc.io/avoid/handle-cgroup-oom-in-userspace-with-oom-guard/",
	"title": "使用 oom-guard 在用户态处理 cgroup OOM",
	"tags": [],
	"description": "",
	"content": "背景 由于 linux 内核对 cgroup OOM 的处理，存在很多 bug，经常有由于频繁 cgroup OOM 导致节点故障(卡死， 重启， 进程异常但无法杀死)，于是 TKE 团队开发了 oom-guard，在用户态处理 cgroup OOM 规避了内核 bug。\n原理 核心思想是在发生内核 cgroup OOM kill 之前，在用户空间杀掉超限的容器， 减少走到内核 cgroup 内存回收失败后的代码分支从而触发各种内核故障的机会。\nthreshold notify 参考文档: https://lwn.net/Articles/529927/\noom-guard 会给 memory cgroup 设置 threshold notify， 接受内核的通知。\n以一个例子来说明阀值计算通知原理: 一个 pod 设置的 memory limit 是 1000M， oom-guard 会根据配置参数计算出 margin:\nmargin = 1000M * margin_ratio = 20M // 缺省margin_ratio是0.02 margin 最小不小于 mim_margin(缺省1M)， 最大不大于 max_margin(缺省为30M)。如果超出范围，则取 mim_margin 或 max_margin。计算 threshold = limit - margin ，也就是 1000M - 20M = 980M，把 980M 作为阈值设置给内核。当这个 pod 的内存使用量达到 980M 时， oom-guard 会收到内核的通知。\n在触发阈值之前，oom-gurad 会先通过 memory.force_empty 触发相关 cgroup 的内存回收。 另外，如果触发阈值时，相关 cgroup 的 memory.stat 显示还有较多 cache， 则不会触发后续处理策略，这样当 cgroup 内存达到 limit 时，会内核会触发内存回收。 这个策略也会造成部分容器内存增长太快时，还是会触发内核 cgroup OOM\n达到阈值后的处理策略 通过 --policy 参数来控制处理策略。目前有三个策略， 缺省策略是 process。\n process: 采用跟内核cgroup OOM killer相同的策略，在该cgroup内部，选择一个 oom_score 得分最高的进程杀掉。 通过 oom-guard 发送 SIGKILL 来杀掉进程 container: 在该cgroup下选择一个 docker 容器，杀掉整个容器 noop: 只记录日志，并不采取任何措施  事件上报 通过 webhook reporter 上报 k8s event，便于分析统计，使用kubectl get event 可以看到:\nLAST SEEN FIRST SEEN COUNT NAME KIND SUBOBJECT TYPE REASON SOURCE MESSAGE 14s 14s 1 172.21.16.23.158b732d352bcc31 Node Warning OomGuardKillContainer oom-guard, 172.21.16.23 {\u0026#34;hostname\u0026#34;:\u0026#34;172.21.16.23\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-03-13T07:12:14.561650646Z\u0026#34;,\u0026#34;oomcgroup\u0026#34;:\u0026#34;/sys/fs/cgroup/memory/kubepods/burstable/pod3d6329e5-455f-11e9-a7e5-06925242d7ea/223d4795cc3b33e28e702f72e0497e1153c4a809de6b4363f27acc12a6781cdb\u0026#34;,\u0026#34;proccgroup\u0026#34;:\u0026#34;/sys/fs/cgroup/memory/kubepods/burstable/pod3d6329e5-455f-11e9-a7e5-06925242d7ea/223d4795cc3b33e28e702f72e0497e1153c4a809de6b4363f27acc12a6781cdb\u0026#34;,\u0026#34;threshold\u0026#34;:205520896,\u0026#34;usage\u0026#34;:206483456,\u0026#34;killed\u0026#34;:\u0026#34;16481(fakeOOM) \u0026#34;,\u0026#34;stats\u0026#34;:\u0026#34;cache 20480|rss 205938688|rss_huge 199229440|mapped_file 0|dirty 0|writeback 0|pgpgin 1842|pgpgout 104|pgfault 2059|pgmajfault 0|inactive_anon 8192|active_anon 203816960|inactive_file 0|active_file 0|unevictable 0|hierarchical_memory_limit 209715200|total_cache 20480|total_rss 205938688|total_rss_huge 199229440|total_mapped_file 0|total_dirty 0|total_writeback 0|total_pgpgin 1842|total_pgpgout 104|total_pgfault 2059|total_pgmajfault 0|total_inactive_anon 8192|total_active_anon 203816960|total_inactive_file 0|total_active_file 0|total_unevictable 0|\u0026#34;,\u0026#34;policy\u0026#34;:\u0026#34;Container\u0026#34;} 使用方法 部署 保存部署 yaml: oom-guard.yaml:\napiVersion: v1 kind: ServiceAccount metadata: name: oomguard namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: system:oomguard roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: oomguard namespace: kube-system --- apiVersion: apps/v1 kind: DaemonSet metadata: name: oom-guard namespace: kube-system labels: app: oom-guard spec: selector: matchLabels: app: oom-guard template: metadata: annotations: scheduler.alpha.kubernetes.io/critical-pod: \u0026#34;\u0026#34; labels: app: oom-guard spec: serviceAccountName: oomguard hostPID: true hostNetwork: true dnsPolicy: ClusterFirst containers: - name: k8s-event-writer image: ccr.ccs.tencentyun.com/paas/k8s-event-writer:v1.6 resources: limits: cpu: 10m memory: 60Mi requests: cpu: 10m memory: 30Mi args: - --logtostderr - --unix-socket=true env: - name: NODE_NAME valueFrom: fieldRef: fieldPath: status.hostIP volumeMounts: - name: unix mountPath: /unix - name: oomguard image: ccr.ccs.tencentyun.com/paas/oomguard:nosoft-v2 imagePullPolicy: Always securityContext: privileged: true resources: limits: cpu: 10m memory: 60Mi requests: cpu: 10m memory: 30Mi volumeMounts: - name: cgroupdir mountPath: /sys/fs/cgroup/memory - name: unix mountPath: /unix - name: kmsg mountPath: /dev/kmsg readOnly: true command: [\u0026#34;/oom-guard\u0026#34;] args: - --v=2 - --logtostderr - --root=/sys/fs/cgroup/memory - --walkIntervalSeconds=277 - --inotifyResetSeconds=701 - --port=0 - --margin-ratio=0.02 - --min-margin=1 - --max-margin=30 - --guard-ms=50 - --policy=container - --openSoftLimit=false - --webhook-url=http://localhost/message env: - name: NODE_NAME valueFrom: fieldRef: fieldPath: status.hostIP volumes: - name: cgroupdir hostPath: path: /sys/fs/cgroup/memory - name: unix emptyDir: {} - name: kmsg hostPath: path: /dev/kmsg 一键部署:\nkubectl apply -f oom-guard.yaml 检查是否部署成功：\n$ kubectl -n kube-system get ds oom-guard NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE oom-guard 2 2 2 2 2 \u0026lt;none\u0026gt; 6m 其中 AVAILABLE 数量跟节点数一致，说明所有节点都已经成功运行了 oom-guard。\n查看 oom-guard 日志 kubectl -n kube-system logs oom-guard-xxxxx oomguard 查看 oom 相关事件 kubectl get events |grep CgroupOOM kubectl get events |grep SystemOOM kubectl get events |grep OomGuardKillContainer kubectl get events |grep OomGuardKillProcess 卸载 kubectl delete -f oom-guard.yaml 这个操作可能有点慢，如果一直不返回 (有节点 NotReady 时可能会卡住)，ctrl+C 终止，然后执行下面的脚本:\nfor pod in `kubectl get pod -n kube-system | grep oom-guard | awk \u0026#39;{print $1}\u0026#39;` do kubectl delete pod $pod -n kube-system --grace-period=0 --force done 检查删除操作是否成功\nkubectl -n kube-system get ds oom-guard 提示 ...not found 就说明删除成功了\n关于开源 当前 oom-gaurd 暂未开源，正在做大量生产试验，后面大量反馈效果统计比较好的时候会考虑开源出来。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/trick/use-systemtap-to-locate-problems/",
	"title": "使用 Systemtap 定位疑难杂症",
	"tags": [],
	"description": "",
	"content": "安装 Ubuntu 安装 systemtap:\napt install -y systemtap 运行 stap-prep 检查还有什么需要安装:\n$ stap-prep Please install linux-headers-4.4.0-104-generic You need package linux-image-4.4.0-104-generic-dbgsym but it does not seem to be available Ubuntu -dbgsym packages are typically in a separate repository Follow https://wiki.ubuntu.com/DebuggingProgramCrash to add this repository apt install -y linux-headers-4.4.0-104-generic 提示需要 dbgsym 包但当前已有软件源中并不包含，需要使用第三方软件源安装，下面是 dbgsym 安装方法(参考官方wiki: https://wiki.ubuntu.com/Kernel/Systemtap):\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C8CAB6595FDFF622 codename=$(lsb_release -c | awk \u0026#39;{print $2}\u0026#39;) sudo tee /etc/apt/sources.list.d/ddebs.list \u0026lt;\u0026lt; EOF deb http://ddebs.ubuntu.com/ ${codename} main restricted universe multiverse deb http://ddebs.ubuntu.com/ ${codename}-security main restricted universe multiverse deb http://ddebs.ubuntu.com/ ${codename}-updates main restricted universe multiverse deb http://ddebs.ubuntu.com/ ${codename}-proposed main restricted universe multiverse EOF sudo apt-get update 配置好源后再运行下 stap-prep:\n$ stap-prep Please install linux-headers-4.4.0-104-generic Please install linux-image-4.4.0-104-generic-dbgsym 提示需要装这两个包，我们安装一下:\napt install -y linux-image-4.4.0-104-generic-dbgsym apt install -y linux-headers-4.4.0-104-generic CentOS 安装 systemtap:\nyum install -y systemtap 默认没装 debuginfo，我们需要装一下，添加软件源 /etc/yum.repos.d/CentOS-Debug.repo:\n[debuginfo] name=CentOS-$releasever - DebugInfo baseurl=http://debuginfo.centos.org/$releasever/$basearch/ gpgcheck=0 enabled=1 protect=1 priority=1 执行 stap-prep (会安装 kernel-debuginfo)\n最后检查确保 kernel-debuginfo 和 kernel-devel 均已安装并且版本跟当前内核版本相同，如果有多个版本，就删除跟当前内核版本不同的包(通过uname -r查看当前内核版本)。\n重点检查是否有多个版本的 kernel-devel:\n$ rpm -qa | grep kernel-devel kernel-devel-3.10.0-327.el7.x86_64 kernel-devel-3.10.0-514.26.2.el7.x86_64 kernel-devel-3.10.0-862.9.1.el7.x86_64 如果存在多个，保证只留跟当前内核版本相同的那个，假设当前内核版本是 3.10.0-862.9.1.el7.x86_64，那么使用 rpm 删除多余的版本:\nrpm -e kernel-devel-3.10.0-327.el7.x86_64 kernel-devel-3.10.0-514.26.2.el7.x86_64 使用 systemtap 揪出杀死容器的真凶 Pod 莫名其妙被杀死? 可以使用 systemtap 来监视进程的信号发送，原理是 systemtap 将脚本翻译成 C 代码然后调用 gcc 编译成 linux 内核模块，再通过 modprobe 加载到内核，根据脚本内容在内核做各种 hook，在这里我们就 hook 一下信号的发送，找出是谁 kill 掉了容器进程。\n首先，找到被杀死的 pod 又自动重启的容器的当前 pid，describe 一下 pod:\n...... Container ID: docker://5fb8adf9ee62afc6d3f6f3d9590041818750b392dff015d7091eaaf99cf1c945 ...... Last State: Terminated Reason: Error Exit Code: 137 Started: Thu, 05 Sep 2019 19:22:30 +0800 Finished: Thu, 05 Sep 2019 19:33:44 +0800 拿到容器 id 反查容器的主进程 pid:\n$ docker inspect -f \u0026#34;{{.State.Pid}}\u0026#34; 5fb8adf9ee62afc6d3f6f3d9590041818750b392dff015d7091eaaf99cf1c945 7942 通过 Exit Code 可以看出容器上次退出的状态码，如果进程是被外界中断信号杀死的，退出状态码将在 129-255 之间，137 表示进程是被 SIGKILL 信号杀死的，但我们从这里并不能看出是被谁杀死的。\n如果问题可以复现，我们可以使用下面的 systemtap 脚本来监视容器是被谁杀死的(保存为sg.stp):\nglobal target_pid = 7942 probe signal.send{ if (sig_pid == target_pid) { printf(\u0026#34;%s(%d) send %s to %s(%d)\\n\u0026#34;, execname(), pid(), sig_name, pid_name, sig_pid); printf(\u0026#34;parent of sender: %s(%d)\\n\u0026#34;, pexecname(), ppid()) printf(\u0026#34;task_ancestry:%s\\n\u0026#34;, task_ancestry(pid2task(pid()), 1)); } }  变量 pid 的值替换为查到的容器主进程 pid  运行脚本:\nstap sg.stp 当容器进程被杀死时，脚本捕捉到事件，执行输出:\npkill(23549) send SIGKILL to server(7942) parent of sender: bash(23495) task_ancestry:swapper/0(0m0.000000000s)=\u0026gt;systemd(0m0.080000000s)=\u0026gt;vGhyM0(19491m2.579563677s)=\u0026gt;sh(33473m38.074571885s)=\u0026gt;bash(33473m38.077072025s)=\u0026gt;bash(33473m38.081028267s)=\u0026gt;bash(33475m4.817798337s)=\u0026gt;pkill(33475m5.202486630s) 通过观察 task_ancestry 可以看到杀死进程的所有父进程，在这里可以看到有个叫 vGhyM0 的奇怪进程名，通常是中了木马，需要安全专家介入继续排查。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/memory-fragmentation/",
	"title": "内存碎片化",
	"tags": [],
	"description": "",
	"content": "判断是否内存碎片化严重 内存页分配失败，内核日志报类似下面的错：\nmysqld: page allocation failure. order:4, mode:0x10c0d0  mysqld 是被分配的内存的程序 order 表示需要分配连续页的数量(2^order)，这里 4 表示 2^4=16 个连续的页 mode 是内存分配模式的标识，定义在内核源码文件 include/linux/gfp.h 中，通常是多个标识相与运算的结果，不同版本内核可能不一样，比如在新版内核中 GFP_KERNEL 是 __GFP_RECLAIM | __GFP_IO | __GFP_FS 的运算结果，而 __GFP_RECLAIM 又是 ___GFP_DIRECT_RECLAIM|___GFP_KSWAPD_RECLAIM 的运算结果  当 order 为 0 时，说明系统以及完全没有可用内存了，order 值比较大时，才说明内存碎片化了，无法分配连续的大页内存。\n内存碎片化造成的问题 容器启动失败 K8S 会为每个 pod 创建 netns 来隔离 network namespace，内核初始化 netns 时会为其创建 nf_conntrack 表的 cache，需要申请大页内存，如果此时系统内存已经碎片化，无法分配到足够的大页内存内核就会报错(v2.6.33 - v4.6):\nrunc:[1:CHILD]: page allocation failure: order:6, mode:0x10c0d0 Pod 状态将会一直在 ContainerCreating，dockerd 启动容器失败，日志报错:\nJan 23 14:15:31 dc05 dockerd: time=\u0026#34;2019-01-23T14:15:31.288446233+08:00\u0026#34; level=error msg=\u0026#34;containerd: start container\u0026#34; error=\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\u0026#34;exit status 6\\\\\\\u0026#34;\\\u0026#34;\\n\u0026#34; id=5b9be8c5bb121264899fac8d9d36b02150269d41ce96ba6ad36d70b8640cb01c Jan 23 14:15:31 dc05 dockerd: time=\u0026#34;2019-01-23T14:15:31.317965799+08:00\u0026#34; level=error msg=\u0026#34;Create container failed with error: invalid header field value \\\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\\\\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\\\\\\\\\u0026#34;exit status 6\\\\\\\\\\\\\\\u0026#34;\\\\\\\u0026#34;\\\\n\\\u0026#34;\u0026#34; kubelet 日志报错:\nJan 23 14:15:31 dc05 kubelet: E0123 14:15:31.352386 26037 remote_runtime.go:91] RunPodSandbox from runtime service failed: rpc error: code = 2 desc = failed to start sandbox container for pod \u0026#34;matchdataserver-1255064836-t4b2w\u0026#34;: Error response from daemon: {\u0026#34;message\u0026#34;:\u0026#34;invalid header field value \\\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\\\\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\\\\\\\\\u0026#34;exit status 6\\\\\\\\\\\\\\\u0026#34;\\\\\\\u0026#34;\\\\n\\\u0026#34;\u0026#34;} Jan 23 14:15:31 dc05 kubelet: E0123 14:15:31.352496 26037 kuberuntime_sandbox.go:54] CreatePodSandbox for pod \u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34; failed: rpc error: code = 2 desc = failed to start sandbox container for pod \u0026#34;matchdataserver-1255064836-t4b2w\u0026#34;: Error response from daemon: {\u0026#34;message\u0026#34;:\u0026#34;invalid header field value \\\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\\\\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\\\\\\\\\u0026#34;exit status 6\\\\\\\\\\\\\\\u0026#34;\\\\\\\u0026#34;\\\\n\\\u0026#34;\u0026#34;} Jan 23 14:15:31 dc05 kubelet: E0123 14:15:31.352518 26037 kuberuntime_manager.go:618] createPodSandbox for pod \u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34; failed: rpc error: code = 2 desc = failed to start sandbox container for pod \u0026#34;matchdataserver-1255064836-t4b2w\u0026#34;: Error response from daemon: {\u0026#34;message\u0026#34;:\u0026#34;invalid header field value \\\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\\\\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\\\\\\\\\u0026#34;exit status 6\\\\\\\\\\\\\\\u0026#34;\\\\\\\u0026#34;\\\\n\\\u0026#34;\u0026#34;} Jan 23 14:15:31 dc05 kubelet: E0123 14:15:31.352580 26037 pod_workers.go:182] Error syncing pod 485fd485-1ed6-11e9-8661-0a587f8021ea (\u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34;), skipping: failed to \u0026#34;CreatePodSandbox\u0026#34; for \u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34; with CreatePodSandboxError: \u0026#34;CreatePodSandbox for pod \\\u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\\\u0026#34; failed: rpc error: code = 2 desc = failed to start sandbox container for pod \\\u0026#34;matchdataserver-1255064836-t4b2w\\\u0026#34;: Error response from daemon: {\\\u0026#34;message\\\u0026#34;:\\\u0026#34;invalid header field value \\\\\\\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\\\\\\\\\\\\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\u0026#34;exit status 6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\u0026#34;\\\\\\\\\\\\\\\u0026#34;\\\\\\\\n\\\\\\\u0026#34;\\\u0026#34;}\u0026#34; Jan 23 14:15:31 dc05 kubelet: I0123 14:15:31.372181 26037 kubelet.go:1916] SyncLoop (PLEG): \u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34;, event: \u0026amp;pleg.PodLifecycleEvent{ID:\u0026#34;485fd485-1ed6-11e9-8661-0a587f8021ea\u0026#34;, Type:\u0026#34;ContainerDied\u0026#34;, Data:\u0026#34;5b9be8c5bb121264899fac8d9d36b02150269d41ce96ba6ad36d70b8640cb01c\u0026#34;} Jan 23 14:15:31 dc05 kubelet: W0123 14:15:31.372225 26037 pod_container_deletor.go:77] Container \u0026#34;5b9be8c5bb121264899fac8d9d36b02150269d41ce96ba6ad36d70b8640cb01c\u0026#34; not found in pod\u0026#39;s containers Jan 23 14:15:31 dc05 kubelet: I0123 14:15:31.678211 26037 kuberuntime_manager.go:383] No ready sandbox for pod \u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34; can be found. Need to start a new one 查看slab (后面的0多表示伙伴系统没有大块内存了)：\n$ cat /proc/buddyinfo Node 0, zone DMA 1 0 1 0 2 1 1 0 1 1 3 Node 0, zone DMA32 2725 624 489 178 0 0 0 0 0 0 0 Node 0, zone Normal 1163 1101 932 222 0 0 0 0 0 0 0 系统 OOM 内存碎片化会导致即使当前系统总内存比较多，但由于无法分配足够的大页内存导致给进程分配内存失败，就认为系统内存不够用，需要杀掉一些进程来释放内存，从而导致系统 OOM\n解决方法  周期性地或者在发现大块内存不足时，先进行drop_cache操作:  echo 3 \u0026gt; /proc/sys/vm/drop_caches  必要时候进行内存整理，开销会比较大，会造成业务卡住一段时间(慎用):  echo 1 \u0026gt; /proc/sys/vm/compact_memory 如何防止内存碎片化 TODO\n附录 相关链接：\n https://huataihuang.gitbooks.io/cloud-atlas/content/os/linux/kernel/memory/drop_caches_and_compact_memory.html  "
},
{
	"uri": "https://k8s.imroc.io/best-practice/kernel/",
	"title": "内核参数优化",
	"tags": [],
	"description": "",
	"content": "# 允许的最大跟踪连接条目，是在内核内存中 netfilter 可以同时处理的“任务”（连接跟踪条目） net.netfilter.nf_conntrack_max=10485760 net.netfilter.nf_conntrack_tcp_timeout_established=300 # 哈希表大小（只读）（64位系统、8G内存默认 65536，16G翻倍，如此类推） net.netfilter.nf_conntrack_buckets=655360 # 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目 net.core.netdev_max_backlog=10000 # 表示socket监听(listen)的backlog上限，也就是就是socket的监听队列(accept queue)，当一个tcp连接尚未被处理或建立时(半连接状态)，会保存在这个监听队列，默认为 128，在高并发场景下偏小，优化到 32768。参考 https://imroc.io/posts/kubernetes-overflow-and-drop/ net.core.somaxconn=32768 # 没有启用syncookies的情况下，syn queue(半连接队列)大小除了受somaxconn限制外，也受这个参数的限制，默认1024，优化到8096，避免在高并发场景下丢包 net.ipv4.tcp_max_syn_backlog=8096 # 表示同一用户同时最大可以创建的 inotify 实例 (每个实例可以有很多 watch) fs.inotify.max_user_instances=8192 # max-file 表示系统级别的能够打开的文件句柄的数量， 一般如果遇到文件句柄达到上限时，会碰到 # Too many open files 或者 Socket/File: Can’t open so many files 等错误 fs.file-max=2097152 # 表示同一用户同时可以添加的watch数目（watch一般是针对目录，决定了同时同一用户可以监控的目录数量) 默认值 8192 在容器场景下偏小，在某些情况下可能会导致 inotify watch 数量耗尽，使得创建 Pod 不成功或者 kubelet 无法启动成功，将其优化到 524288 fs.inotify.max_user_watches=524288 net.core.bpf_jit_enable=1 net.core.bpf_jit_harden=1 net.core.bpf_jit_kallsyms=1 net.core.dev_weight_tx_bias=1 net.core.rmem_max=16777216 net.core.wmem_max=16777216 net.ipv4.tcp_rmem=4096 12582912 16777216 net.ipv4.tcp_wmem=4096 12582912 16777216 net.core.rps_sock_flow_entries=8192 # 以下三个参数是 arp 缓存的 gc 阀值，相比默认值提高了，当内核维护的 arp 表过于庞大时候，可以考虑优化下，避免在某些场景下arp缓存溢出导致网络超时，参考：https://k8s.imroc.io/avoid/cases/arp-cache-overflow-causes-healthcheck-failed # 存在于 ARP 高速缓存中的最少层数，如果少于这个数，垃圾收集器将不会运行。缺省值是 128 net.ipv4.neigh.default.gc_thresh1=2048 # 保存在 ARP 高速缓存中的最多的记录软限制。垃圾收集器在开始收集前，允许记录数超过这个数字 5 秒。缺省值是 512 net.ipv4.neigh.default.gc_thresh2=4096 # 保存在 ARP 高速缓存中的最多记录的硬限制，一旦高速缓存中的数目高于此，垃圾收集器将马上运行。缺省值是 1024 net.ipv4.neigh.default.gc_thresh3=8192 net.ipv4.tcp_max_orphans=32768 net.ipv4.tcp_max_tw_buckets=32768 vm.max_map_count=262144 kernel.threads-max=30058 net.ipv4.ip_forward=1 # 避免发生故障时没有 coredump kernel.core_pattern=core "
},
{
	"uri": "https://k8s.imroc.io/security/user/create-user-using-csr-api/",
	"title": "利用 CSR API 创建用户",
	"tags": [],
	"description": "",
	"content": "k8s 支持 CSR API，通过创建 CertificateSigningRequest 资源就可以发起 CSR 请求，管理员审批通过之后 kube-controller-manager 就会为我们签发证书，确保 kube-controller-manager 配了根证书密钥对:\n--cluster-signing-cert-file=/var/lib/kubernetes/ca.pem --cluster-signing-key-file=/var/lib/kubernetes/ca-key.pem 创建步骤 我们用 cfssl 来创建 key 和 csr 文件，所以需要先安装 cfssl:\ncurl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o cfssl curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o cfssljson curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o cfssl-certinfo chmod +x cfssl cfssljson cfssl-certinfo sudo mv cfssl cfssljson cfssl-certinfo /usr/local/bin/ 指定要创建的用户名:\nUSERNAME=\u0026#34;roc\u0026#34; 再创建 key 和 csr 文件:\ncat \u0026lt;\u0026lt;EOF | cfssl genkey - | cfssljson -bare ${USERNAME} { \u0026#34;CN\u0026#34;: \u0026#34;${USERNAME}\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 } } EOF 生成以下文件:\nroc.csr roc-key.pem 创建 CertificateSigningRequest(发起 CSR 请求):\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: certificates.k8s.io/v1beta1 kind: CertificateSigningRequest metadata: name: ${USERNAME} spec: request: $(cat ${USERNAME}.csr | base64 | tr -d \u0026#39;\\n\u0026#39;) usages: - digital signature - key encipherment - client auth EOF 管理员审批 CSR 请求:\n# 查看 csr # kubectl get csr # 审批 csr kubectl certificate approve ${USERNAME} 获取证书:\nkubectl get csr ${USERNAME} -o jsonpath={.status.certificate} | base64 --decode \u0026gt; ${USERNAME}.pem 得到证书文件:\nroc.pem 至此，我们已经创建好了用户，用户的证书密钥对文件:\nroc.pem roc-key.pem 配置 kubeconfig # 增加 user kubectl config set-credentials ${USERNAME} --embed-certs=true --client-certificate=${USERNAME}.pem --client-key=${USERNAME}-key.pem # 如果还没配 cluster，可以通过下面命令配一下 kubectl config set-cluster \u0026lt;cluster\u0026gt; --server=\u0026lt;apiserver-url\u0026gt; --certificate-authority=\u0026lt;ca-cert-file\u0026gt; # 增加 context，绑定 cluster 和 user kubectl config set-context \u0026lt;context\u0026gt; --cluster=\u0026lt;cluster\u0026gt; --user=${USERNAME} # 使用刚增加的 context kubectl config use-context \u0026lt;context\u0026gt; 配置用户权限 我们可以用 RBAC 控制用户权限，参考 使用 RBAC 控制用户权限\n参考资料  Manage TLS Certificates in a Cluster: https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/  "
},
{
	"uri": "https://k8s.imroc.io/monitoring/alerting/",
	"title": "告警",
	"tags": [],
	"description": "",
	"content": "先将 alertmanager 配置文件 dump 下来:\nkubectl -n monitoring get secret alertmanager-main -o jsonpath=\u0026#39;{.data.alertmanager\\.yaml}\u0026#39; | base64 -d \u0026gt; alertmanager-main.yaml "
},
{
	"uri": "https://k8s.imroc.io/trick/perf-in-container/",
	"title": "在容器内使用 perf",
	"tags": [],
	"description": "",
	"content": "条件 运行 perf 主要会用到 perf_event_open 系统调用，要在容器内使用，需要满足以下条件:\n 设置内核参数：kernel.perf_event_paranoid = -1 把系统调用perf_event_open放到白名单中（获取dockerd 默认的seccomp profile，然后把系统调用perf_event_open从CAP_SYS_ADMIN移出放到白名单）或者设置seccomp=unconfined 而在k8s场景下，由于kubelet默认会给pod配置seccomp=unconfined的SecurityOpt选项，所以只需要满足第一个条件即可  "
},
{
	"uri": "https://k8s.imroc.io/cluster/runtime/containerd/install-containerd/",
	"title": "安装 containerd",
	"tags": [],
	"description": "",
	"content": "二进制部署  下载二进制:\nwget -q --show-progress --https-only --timestamping \\  https://github.com/opencontainers/runc/releases/download/v1.0.0-rc8/runc.amd64 \\  https://github.com/containerd/containerd/releases/download/v1.3.0/containerd-1.3.0.linux-amd64.tar.gz \\  https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.16.1/crictl-v1.16.1-linux-amd64.tar.gz sudo mv runc.amd64 runc 安装二进制:\ntar -xvf crictl-v1.16.1-linux-amd64.tar.gz chmod +x crictl runc sudo cp crictl runc /usr/local/bin/ mkdir containerd tar -xvf containerd-1.3.0.linux-amd64.tar.gz -C containerd sudo cp containerd/bin/* /bin/ 创建 containerd 启动配置 config.toml:\nsudo mkdir -p /etc/containerd/ cat \u0026lt;\u0026lt; EOF | sudo tee /etc/containerd/config.toml [plugins] [plugins.cri.containerd] snapshotter = \u0026#34;overlayfs\u0026#34; [plugins.cri.containerd.default_runtime] runtime_type = \u0026#34;io.containerd.runtime.v1.linux\u0026#34; runtime_engine = \u0026#34;/usr/local/bin/runc\u0026#34; runtime_root = \u0026#34;\u0026#34; EOF 创建 systemd 配置 containerd.service:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/containerd.service [Unit] Description=containerd container runtime Documentation=https://containerd.io After=network.target [Service] ExecStartPre=/sbin/modprobe overlay ExecStart=/bin/containerd Restart=always RestartSec=5 Delegate=yes KillMode=process OOMScoreAdjust=-999 LimitNOFILE=1048576 LimitNPROC=infinity LimitCORE=infinity [Install] WantedBy=multi-user.target EOF 启动:\nsudo systemctl daemon-reload sudo systemctl enable containerd sudo systemctl start containerd 配置 crictl (方便后面使用 crictl 管理与调试 containerd 的容器与镜像):\ncrictl config runtime-endpoint unix:///var/run/containerd/containerd.sock "
},
{
	"uri": "https://k8s.imroc.io/deploy/appendix/install-kubectl/",
	"title": "安装 kubectl",
	"tags": [],
	"description": "",
	"content": "二进制安装 指定K8S版本与节点cpu架构:\nVERSION=\u0026#34;v1.16.1\u0026#34; ARCH=\u0026#34;amd64\u0026#34; 下载安装:\nwget -q --show-progress --https-only --timestamping \\  https://storage.googleapis.com/kubernetes-release/release/${VERSION}/bin/linux/${ARCH}/kubectl chmod +x kubectl mv kubectl /usr/local/bin/ "
},
{
	"uri": "https://k8s.imroc.io/cluster/metrics/install-metrics-server/",
	"title": "安装 metrics server",
	"tags": [],
	"description": "",
	"content": "官方 yaml 安装 下载:\ngit clone --depth 1 https://github.com/kubernetes-sigs/metrics-server.git cd metrics-server 修改 deploy/1.8+/metrics-server-deployment.yaml，在 args 里增加 --kubelet-insecure-tls (防止 metrics server 访问 kubelet 采集指标时报证书问题 x509: certificate signed by unknown authority):\ncontainers: - name: metrics-server image: k8s.gcr.io/metrics-server-amd64:v0.3.6 args: - --cert-dir=/tmp - --secure-port=4443 - --kubelet-insecure-tls # 这里是新增的一行 安装:\nkubectl apply -f deploy/1.8+/ 参考资料  Github 主页: https://github.com/kubernetes-sigs/metrics-server  "
},
{
	"uri": "https://k8s.imroc.io/cluster/ingress/nginx/install-nginx-ingress/",
	"title": "安装 nginx ingress controller",
	"tags": [],
	"description": "",
	"content": "最佳安装方案 如何暴露 ingress 访问入口? 最佳方案是使用 LoadBalancer 类型的 Service 来暴露，即创建外部负载均衡器来暴露流量，后续访问 ingress 的流量都走这个负载均衡器的地址，ingress 规则里面配的域名也要配置解析到这个负载均衡器的 IP 地址。\n这种方式需要集群支持 LoadBalancer 类型的 Service，如果是云厂商提供的 k8s 服务，或者在云上自建集群并使用了云厂商提供的 cloud provider，也都是支持的，创建 LoadBalancer 类型的 Service 的时候会自动调云厂商的接口创建云厂商提供的负载均衡器产品(通常公网类型的负载均衡器是付费的)；如果你的集群不是前面说的情况，是自建集群并且有自己的负载均衡器方案，并部署了相关插件来适配，比如 MetalLB 和 Porter，这样也是可以支持 LoadBalancer 类型的 Service 的。\n使用 helm 安装 helm install stable/nginx-ingress \\  --name nginx \\  --namespace kube-system \\  --set controller.ingressClass=nginx \\  --set controller.publishService.enabled=true \\  controller.ingressClass: 创建的 ingress 中包含 kubernetes.io/ingress.class 这个 annotation 并且值与这里配置的一致，这个 nginx ingress controller 才会处理 (生成转发规则) controller.publishService.enabled: 这个置为 true 主要是为了让 ingress 的外部地址正确显示 (显示为负载均衡器的地址)，因为如果不配置这个，默认情况下会将 ingress controller 所有实例的节点 ip 写到 ingress 的 address 里  安装完成后如何获取负载均衡器的 IP 地址？查看 nginx ingress controller 的 service 的 EXTERNAL-IP 就可以:\n$ kubectl -n kube-system get service nginx-nginx-ingress-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-nginx-ingress-controller LoadBalancer 172.16.255.194 119.28.123.174 80:32348/TCP,443:32704/TCP 10m 如果需要新的流量入口，可以按照同样的方法用 helm 安装新的 release，注意要设置不同的 controller.ingressClass，将希望用新流量入口暴露的 ingress 的 kubernetes.io/ingress.class annotation 设置成这里的值就可以。\n如果转发性能跟不上，可以增加 controller 的副本，设置 controller.replicaCount 的值，或者启用 HPA 自动伸缩，将 controller.autoscaling.enabled 置为 true，更多细节控制请参考官方文档。\n配置优化 配置更改如果比较多推荐使用覆盖 values.yaml 的方式来安装 nginx ingress:\n 导出默认的 values.yaml:  helm inspect values stable/nginx-ingress \u0026gt; values.yaml 修改 values.yaml 中的配置 执行 helm install 的时候去掉 --set 的方式设置的变量，替换为使用 -f values.yaml  有时可能更新 nginx ingress 的部署，滚动更新时可能造成部分连接异常，可以参考服务平滑更新最佳实践 使用 preStopHook 和 readinessProbe 保证服务平滑更新不中断，nginx ingress 默认加了 readinessProbe，但 preStop 没有加，我们可以修改 values.yaml 中 controller.lifecycle，加上 preStop，示例:\nlifecycle: preStop: exec: command: [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sleep 30\u0026#34;] 还可以 使用反亲和性避免单点故障，修改 controller.affinity 字段示例:\naffinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - weight: 100 labelSelector: matchExpressions: - key: app operator: In values: - nginx-ingress - key: component operator: In values: - controller - key: release operator: In values: - nginx topologyKey: kubernetes.io/hostname 参考资料  Github 主页: https://github.com/kubernetes/ingress-nginx helm hub 主页: https://hub.helm.sh/charts/nginx/nginx-ingress 官方文档: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/  "
},
{
	"uri": "https://k8s.imroc.io/ingress/nginx-ingress/install-nginx-ingress/",
	"title": "安装 nginx ingress controller",
	"tags": [],
	"description": "",
	"content": "最佳安装方案 如何暴露 ingress 访问入口? 最佳方案是使用 LoadBalancer 类型的 Service 来暴露，即创建外部负载均衡器来暴露流量，后续访问 ingress 的流量都走这个负载均衡器的地址，ingress 规则里面配的域名也要配置解析到这个负载均衡器的 IP 地址。\n这种方式需要集群支持 LoadBalancer 类型的 Service，如果是云厂商提供的 k8s 服务，或者在云上自建集群并使用了云厂商提供的 cloud provider，也都是支持的，创建 LoadBalancer 类型的 Service 的时候会自动调云厂商的接口创建云厂商提供的负载均衡器产品(通常公网类型的负载均衡器是付费的)；如果你的集群不是前面说的情况，是自建集群并且有自己的负载均衡器方案，并部署了相关插件来适配，比如 MetalLB 和 Porter，这样也是可以支持 LoadBalancer 类型的 Service 的。\n使用 helm 安装 helm install stable/nginx-ingress \\  --name nginx \\  --namespace kube-system \\  --set controller.ingressClass=nginx \\  --set controller.publishService.enabled=true \\  controller.ingressClass: 创建的 ingress 中包含 kubernetes.io/ingress.class 这个 annotation 并且值与这里配置的一致，这个 nginx ingress controller 才会处理 (生成转发规则) controller.publishService.enabled: 这个置为 true 主要是为了让 ingress 的外部地址正确显示 (显示为负载均衡器的地址)，因为如果不配置这个，默认情况下会将 ingress controller 所有实例的节点 ip 写到 ingress 的 address 里  安装完成后如何获取负载均衡器的 IP 地址？查看 nginx ingress controller 的 service 的 EXTERNAL-IP 就可以:\n$ kubectl -n kube-system get service nginx-nginx-ingress-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-nginx-ingress-controller LoadBalancer 172.16.255.194 119.28.123.174 80:32348/TCP,443:32704/TCP 10m 如果需要新的流量入口，可以按照同样的方法用 helm 安装新的 release，注意要设置不同的 controller.ingressClass，将希望用新流量入口暴露的 ingress 的 kubernetes.io/ingress.class annotation 设置成这里的值就可以。\n如果转发性能跟不上，可以增加 controller 的副本，设置 controller.replicaCount 的值，或者启用 HPA 自动伸缩，将 controller.autoscaling.enabled 置为 true，更多细节控制请参考官方文档。\n配置优化 配置更改如果比较多推荐使用覆盖 values.yaml 的方式来安装 nginx ingress:\n 导出默认的 values.yaml:  helm inspect values stable/nginx-ingress \u0026gt; values.yaml 修改 values.yaml 中的配置 执行 helm install 的时候去掉 --set 的方式设置的变量，替换为使用 -f values.yaml  有时可能更新 nginx ingress 的部署，滚动更新时可能造成部分连接异常，可以参考服务平滑更新最佳实践 使用 preStopHook 和 readinessProbe 保证服务平滑更新不中断，nginx ingress 默认加了 readinessProbe，但 preStop 没有加，我们可以修改 values.yaml 中 controller.lifecycle，加上 preStop，示例:\nlifecycle: preStop: exec: command: [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sleep 30\u0026#34;] 还可以 使用反亲和性避免单点故障，修改 controller.affinity 字段示例:\naffinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - weight: 100 labelSelector: matchExpressions: - key: app operator: In values: - nginx-ingress - key: component operator: In values: - controller - key: release operator: In values: - nginx topologyKey: kubernetes.io/hostname 参考资料  Github 主页: https://github.com/kubernetes/ingress-nginx helm hub 主页: https://hub.helm.sh/charts/nginx/nginx-ingress 官方文档: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/  "
},
{
	"uri": "https://k8s.imroc.io/cluster/ingress/traefik/install-traefik-ingress/",
	"title": "安装 traefik ingress controller",
	"tags": [],
	"description": "",
	"content": "最佳安装方案 如何暴露 ingress 访问入口? 最佳方案是使用 LoadBalancer 类型的 Service 来暴露，即创建外部负载均衡器来暴露流量，后续访问 ingress 的流量都走这个负载均衡器的地址，ingress 规则里面配的域名也要配置解析到这个负载均衡器的 IP 地址。\n这种方式需要集群支持 LoadBalancer 类型的 Service，如果是云厂商提供的 k8s 服务，或者在云上自建集群并使用了云厂商提供的 cloud provider，也都是支持的，创建 LoadBalancer 类型的 Service 的时候会自动调云厂商的接口创建云厂商提供的负载均衡器产品(通常公网类型的负载均衡器是付费的)；如果你的集群不是前面说的情况，是自建集群并且有自己的负载均衡器方案，并部署了相关插件来适配，比如 MetalLB 和 Porter，这样也是可以支持 LoadBalancer 类型的 Service 的。\n使用 helm 安装 helm install stable/traefik \\  --name traefik \\  --namespace kube-system \\  --set kubernetes.ingressClass=traefik \\  --set kubernetes.ingressEndpoint.useDefaultPublishedService=true \\  --set rbac.enabled=true  kubernetes.ingressClass=traefik: 创建的 ingress 中包含 kubernetes.io/ingress.class 这个 annotation 并且值与这里配置的一致，这个 traefik ingress controller 才会处理 (生成转发规则) kubernetes.ingressEndpoint.useDefaultPublishedService=true: 这个置为 true 主要是为了让 ingress 的外部地址正确显示 (显示为负载均衡器的地址)，因为如果不配置这个，默认情况下会将 ingress controller 所有实例的节点 ip 写到 ingress 的 address 里 rbac.enabled 默认为 false，如果没有事先给 default 的 service account 绑足够权限就会报错，通常置为 true，自动创建 rbac 规则  参考资料  Github 主页: https://github.com/containous/traefik helm hub 主页: https://hub.helm.sh/charts/stable/traefik 官方文档: https://docs.traefik.io  "
},
{
	"uri": "https://k8s.imroc.io/trick/shell/",
	"title": "实用命令与脚本",
	"tags": [],
	"description": "",
	"content": "目录：  Pod 相关脚本   网络调试相关脚本   节点相关脚本   "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/trick/capture-packets-in-container/",
	"title": "容器内抓包定位网络问题",
	"tags": [],
	"description": "",
	"content": "在使用 kubernetes 跑应用的时候，可能会遇到一些网络问题，比较常见的是服务端无响应(超时)或回包内容不正常，如果没找出各种配置上有问题，这时我们需要确认数据包到底有没有最终被路由到容器里，或者报文到达容器的内容和出容器的内容符不符合预期，通过分析报文可以进一步缩小问题范围。那么如何在容器内抓包呢？本文提供实用的脚本一键进入容器网络命名空间(netns)，使用宿主机上的tcpdump进行抓包。\n使用脚本一键进入 pod netns 抓包  发现某个服务不通，最好将其副本数调为1，并找到这个副本 pod 所在节点和 pod 名称  kubectl get pod -o wide  登录 pod 所在节点，将如下脚本粘贴到 shell (注册函数到当前登录的 shell，我们后面用)  function e() { set -eu ns=${2-\u0026#34;default\u0026#34;} pod=`kubectl -n $ns describe pod $1 | grep -A10 \u0026#34;^Containers:\u0026#34; | grep -Eo \u0026#39;docker://.*$\u0026#39; | head -n 1 | sed \u0026#39;s/docker:\\/\\/\\(.*\\)$/\\1/\u0026#39;` pid=`docker inspect -f {{.State.Pid}} $pod` echo \u0026#34;entering pod netns for $ns/$1\u0026#34; cmd=\u0026#34;nsenter -n --target $pid\u0026#34; echo $cmd $cmd }  一键进入 pod 所在的 netns，格式：e POD_NAME NAMESPACE，示例：  e istio-galley-58c7c7c646-m6568 istio-system e proxy-5546768954-9rxg6 # 省略 NAMESPACE 默认为 default  这时已经进入 pod 的 netns，可以执行宿主机上的 ip a 或 ifconfig 来查看容器的网卡，执行 netstat -tunlp 查看当前容器监听了哪些端口，再通过 tcpdump 抓包：  tcpdump -i eth0 -w test.pcap port 80  ctrl-c 停止抓包，再用 scp 或 sz 将抓下来的包下载到本地使用 wireshark 分析，提供一些常用的 wireshark 过滤语法：  # 使用 telnet 连上并发送一些测试文本，比如 \u0026#34;lbtest\u0026#34;， # 用下面语句可以看发送的测试报文有没有到容器 tcp contains \u0026#34;lbtest\u0026#34; # 如果容器提供的是http服务，可以使用 curl 发送一些测试路径的请求， # 通过下面语句过滤 uri 看报文有没有都容器 http.request.uri==\u0026#34;/mytest\u0026#34; 脚本原理 我们解释下步骤二中用到的脚本的原理\n 查看指定 pod 运行的容器 ID  kubectl describe pod \u0026lt;pod\u0026gt; -n mservice  获得容器进程的 pid  docker inspect -f {{.State.Pid}} \u0026lt;container\u0026gt;  进入该容器的 network namespace  nsenter -n --target \u0026lt;PID\u0026gt; 依赖宿主机的命名：kubectl, docker, nsenter, grep, head, sed\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/container-proccess-exit-by-itself/",
	"title": "容器进程主动退出",
	"tags": [],
	"description": "",
	"content": "容器进程如果是自己主动退出(不是被外界中断杀死)，退出状态码一般在 0-128 之间，根据约定，正常退出时状态码为 0，1-127 说明是程序发生异常，主动退出了，比如检测到启动的参数和条件不满足要求，或者运行过程中发生 panic 但没有捕获处理导致程序退出。除了可能是业务程序 BUG，还有其它许多可能原因，这里我们一一列举下。\nDNS 无法解析 可能程序依赖 集群 DNS 服务，比如启动时连接数据库，数据库使用 service 名称或外部域名都需要 DNS 解析，如果解析失败程序将报错并主动退出。解析失败的可能原因:\n 集群网络有问题，Pod 连不上集群 DNS 服务 集群 DNS 服务挂了，无法响应解析请求 Service 或域名地址配置有误，本身是无法解析的地址  程序配置有误  配置文件格式错误，程序启动解析配置失败报错退出 配置内容不符合规范，比如配置中某个字段是必选但没有填写，配置校验不通过，程序报错主动退出  "
},
{
	"uri": "https://k8s.imroc.io/cluster/network/understanding/",
	"title": "彻底理解集群网络",
	"tags": [],
	"description": "",
	"content": "什么是集群网络 TODO\nK8S 网络模型 TODO\n如何实现 K8S 集群网络 TODO\n公有云 K8S 服务是如何实现集群网络的 TODO\nCNI 插件 TODO\n开源网络方案 TODO\n参考资料  Cluster Networking: https://kubernetes.io/docs/concepts/cluster-administration/networking/  "
},
{
	"uri": "https://k8s.imroc.io/security/permission/app/",
	"title": "控制应用权限",
	"tags": [],
	"description": "",
	"content": "不仅用户 (人) 可以操作集群，应用 (程序) 也可以操作集群，通过给 Pod 设置 Serivce Account 来对应用进行授权，如果不设置会默认配置一个 \u0026ldquo;default\u0026rdquo; 的 Service Account，几乎没有权限。\n原理 创建 Pod 时，在 apiserver 中的 service account admission controller 检测 Pod 是否指定了 ServiceAccount，如果没有就自动设置一个 \u0026ldquo;default\u0026rdquo;，如果指定了会检测指定的 ServiceAccount 是否存在，不存在的话会拒绝该 Pod，存在话就将此 ServiceAccount 对应的 Secret 挂载到 Pod 中每个容器的 /var/run/secrets/kubernetes.io/serviceaccount 这个路径，这个 Secret 是 controller manager 中 token controller 去 watch ServiceAccount，为每个 ServiceAccount 生成对应的 token 类型的 Secret 得来的。\nPod 内的程序如果要调用 apiserver 接口操作集群，会使用 SDK，通常是 client-go ， SDK 使用 in-cluster 的方式调用 apiserver，从固定路径 /var/run/secrets/kubernetes.io/serviceaccount 读取认证配置信息去连 apiserver，从而实现认证，再结合 RBAC 配置可以实现权限控制。\n使用 RBAC 细化应用权限 ServiceAccount 仅针对某个命名空间，所以 Pod 指定的 ServiceAccount 只能引用当前命名空间的 ServiceAccount 的，即便是 \u0026ldquo;default\u0026rdquo; 每个命名空间也都是相互独立的，下面给出几个 RBAC 定义示例。\nbuild-robot 这个 ServiceAccount 可以读取 build 命名空间中 Pod 的信息和 log:\napiVersion: v1 kind: ServiceAccount metadata: name: build-robot namespace: build --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: namespace: build name: pod-reader rules: - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;pods\u0026#34;, \u0026#34;pods/log\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: read-pods namespace: build subjects: - kind: ServiceAccount name: build-robot apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io 为 Pod 指定 ServiceAccount 示例:\napiVersion: v1 kind: Pod metadata: name: build namespace: build spec: containers: - image: imroc/build-robot:v1 name: builder serviceAccountName: build-robot 为应用默认指定 imagePullSecrets  ServiceAccount 中也可以指定 imagePullSecrets，也就是只要给 Pod 指定了这个 ServiceAccount，就有对应的 imagePullSecrets，而如果不指定 ServiceAccount 会默认指定 \u0026ldquo;default\u0026rdquo;，我们可以给 \u0026ldquo;default\u0026rdquo; 这个 ServiceAccount 指定 imagePullSecrets 来实现给某个命名空间指定默认的 imagePullSecrets\n创建 imagePullSecrets:\nkubectl create secret docker-registry \u0026lt;secret-name\u0026gt; --docker-server=\u0026lt;your-registry-server\u0026gt; --docker-username=\u0026lt;your-name\u0026gt; --docker-password=\u0026lt;your-password\u0026gt; --docker-email=\u0026lt;your-email\u0026gt; -n \u0026lt;namespace\u0026gt;  \u0026lt;secret-name\u0026gt;: 是要创建的 imagePullSecrets 的名称 \u0026lt;namespace\u0026gt;: 是要创建的 imagePullSecrets 所在命名空间 \u0026lt;your-registry-server\u0026gt;: 是你的私有仓库的地址 \u0026lt;your-name\u0026gt;: 是你的 Docker 用户名 \u0026lt;your-password\u0026gt; 是你的 Docker 密码 \u0026lt;your-email\u0026gt; 是你的 Docker 邮箱  指定默认 imagePullSecrets:\nkubectl patch serviceaccount default -p \u0026#39;{\u0026#34;imagePullSecrets\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;\u0026lt;secret-name\u0026gt;\u0026#34;}]}\u0026#39; -n \u0026lt;namespace\u0026gt;  \u0026lt;secret-name\u0026gt;: 是 ServiceAccount 要关联的 imagePullSecrets 的名称 \u0026lt;namespace\u0026gt;: 是 ServiceAccount 所在的命名空间，跟 imagePullSecrets 在同一个命名空间  参考资料  Configure Service Accounts for Pods: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/  "
},
{
	"uri": "https://k8s.imroc.io/security/permission/user/",
	"title": "控制用户权限",
	"tags": [],
	"description": "",
	"content": "为了简单方便，小集群或测试环境集群我们通常使用最高权限的 admin 账号，可以做任何操作，但是如果是重要的生产环境集群，可以操作集群的人比较多，如果这时还用这个账号可能就会比较危险，一旦有人误操作或故意搞事就可能酿成大错，即使 apiserver 开启审计也无法知道是谁做的操作，所以最好控制下权限，根据人的级别或角色创建拥有对应权限的账号，这个可以通过 RBAC 来实现(确保 kube-apiserver 启动参数 --authorization-mode=RBAC)，基本思想是创建 User 或 ServiceAccount 绑定 Role 或 ClusterRole 来控制权限。\nUser 来源 User 的来源有多种:\n token 文件: 给 kube-apiserver 启动参数 --token-auth-file 传一个 token 认证文件，比如: --token-auth-file=/etc/kubernetes/known_tokens.csv  token 文件每一行表示一个用户，示例: wJmq****PPWj,admin,admin,system:masters 第一个字段是 token 的值，最后一个字段是用户组，token 认证用户名不重要，不会识别   证书: 通过使用 CA 证书给用户签发证书，签发的证书中 CN 字段是用户名，O 是用户组  使用 RBAC 控制用户权限  下面给出几个 RBAC 定义示例。\n给 roc 授权 test 命名空间所有权限，istio-system 命名空间的只读权限:\nkind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: admin namespace: test rules: - apiGroups: [\u0026#34;*\u0026#34;] resources: [\u0026#34;*\u0026#34;] verbs: [\u0026#34;*\u0026#34;] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: admin-to-roc namespace: test subjects: - kind: User name: roc apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: admin apiGroup: rbac.authorization.k8s.io --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: readonly namespace: istio-system rules: - apiGroups: [\u0026#34;*\u0026#34;] resources: [\u0026#34;*\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: readonly-to-roc namespace: istio-system subjects: - kind: User name: roc apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: readonly apiGroup: rbac.authorization.k8s.io 给 roc 授权整个集群的只读权限:\nkind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: readonly rules: - apiGroups: [\u0026#34;*\u0026#34;] resources: [\u0026#34;*\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: readonly-to-roc subjects: - kind: User name: roc apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: readonly apiGroup: rbac.authorization.k8s.io 给 manager 用户组里所有用户授权 secret 读权限:\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: secret-reader rules: - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;secrets\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: read-secrets-global subjects: - kind: Group name: manager apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 配置 kubeconfig # 如果使用证书认证，使用下面命令配置用户认证信息 kubectl config set-credentials \u0026lt;user\u0026gt; --embed-certs=true --client-certificate=\u0026lt;client-cert-file\u0026gt; --client-key=\u0026lt;client-key-file\u0026gt; # 如果使用 token 认证，使用下面命令配置用户认证信息 # kubectl config set-credentials \u0026lt;user\u0026gt; --token=\u0026#39;\u0026lt;token\u0026gt;\u0026#39; # 配置cluster entry kubectl config set-cluster \u0026lt;cluster\u0026gt; --server=\u0026lt;apiserver-url\u0026gt; --certificate-authority=\u0026lt;ca-cert-file\u0026gt; # 配置context entry kubectl config set-context \u0026lt;context\u0026gt; --cluster=\u0026lt;cluster\u0026gt; --user=\u0026lt;user\u0026gt; # 配置当前使用的context kubectl config use-context \u0026lt;context\u0026gt; # 查看 kubectl config view 参考资料  https://kubernetes.io/zh/docs/reference/access-authn-authz/service-accounts-admin/ https://kubernetes.io/docs/reference/access-authn-authz/rbac/  "
},
{
	"uri": "https://k8s.imroc.io/trick/wildcard-domain-forward/",
	"title": "泛域名动态转发 Service",
	"tags": [],
	"description": "",
	"content": "需求 集群对外暴露了一个公网IP作为流量入口(可以是 Ingress 或 Service)，DNS 解析配置了一个泛域名指向该IP（比如 *.test.imroc.io），现希望根据请求中不同 Host 转发到不同的后端 Service。比如 a.test.imroc.io 的请求被转发到 my-svc-a，b.test.imroc.io 的请求转发到 my-svc-b。当前 K8S 的 Ingress 并不原生支持这种泛域名转发规则，本文将给出一个解决方案来实现泛域名转发。\n简单做法 先说一种简单的方法，这也是大多数人的第一反应：配置 Ingress 规则\n假如泛域名有两个不同 Host 分别转发到不同 Service，Ingress 类似这样写:\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: my-ingress spec: rules: - host: a.test.imroc.io http: paths: - backend: serviceName: my-svc-a servicePort: 80 path: / - host: b.test.imroc.io http: paths: - backend: serviceName: my-svc-b servicePort: 80 path: / 但是！如果 Host 非常多会怎样？（比如200+）\n 每次新增 Host 都要改 Ingress 规则，太麻烦 单个 Ingress 上面的规则越来越多，更改规则对 LB 的压力变大，可能会导致偶尔访问不了  正确姿势 我们可以约定请求中泛域名 Host 通配符的 * 号匹配到的字符跟 Service 的名字相关联（可以是相等，或者 Service 统一在前面加个前缀，比如 a.test.imroc.io 转发到 my-svc-a 这个 Service)，集群内起一个反向代理服务，匹配泛域名的请求全部转发到这个代理服务上，这个代理服务只做一件简单的事，解析 Host，正则匹配抓取泛域名中 * 号这部分，把它转换为 Service 名字，然后在集群里转发（集群 DNS 解析)\n这个反向代理服务可以是 Nginx+Lua脚本 来实现，或者自己写个简单程序来做反向代理，这里我用 OpenResty 来实现，它可以看成是 Nginx 的发行版，自带 lua 支持。\n有几点需要说明下：\n 我们使用 nginx 的 proxy_pass 来反向代理到后端服务，proxy_pass 后面跟的变量，我们需要用 lua 来判断 Host 修改变量 nginx 的 proxy_pass 后面跟的如果是可变的域名（非IP，需要 dns 解析)，它需要一个域名解析器，不会走默认的 dns 解析，需要在 nginx.conf 里添加 resolver 配置项来设置一个外部的 dns 解析器 这个解析器我们是用 go-dnsmasq 来实现，它可以将集群的 dns 解析代理给 nginx，以 sidecar 的形式注入到 pod 中，监听 53 端口  nginx.conf 里关键的配置如下图所示：\n下面给出完整的 yaml 示例\nproxy.yaml:\napiVersion: apps/v1beta1 kind: Deployment metadata: labels: component: nginx name: proxy spec: replicas: 1 selector: matchLabels: component: nginx template: metadata: labels: component: nginx spec: containers: - name: nginx image: \u0026#34;openresty/openresty:centos\u0026#34; ports: - name: http containerPort: 80 protocol: TCP volumeMounts: - mountPath: /usr/local/openresty/nginx/conf/nginx.conf name: config subPath: nginx.conf - name: dnsmasq image: \u0026#34;janeczku/go-dnsmasq:release-1.0.7\u0026#34; args: - --listen - \u0026#34;127.0.0.1:53\u0026#34; - --default-resolver - --append-search-domains - --hostsfile=/etc/hosts - --verbose volumes: - name: config configMap: name: configmap-nginx --- apiVersion: v1 kind: ConfigMap metadata: labels: component: nginx name: configmap-nginx data: nginx.conf: |- worker_processes 1; error_log /error.log; events { accept_mutex on; multi_accept on; use epoll; worker_connections 1024; } http { include mime.types; default_type application/octet-stream; log_format main \u0026#39;$time_local $remote_user $remote_addr $host $request_uri $request_method $http_cookie \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34; \u0026#39; \u0026#39;$request_time $upstream_response_time \u0026#34;$upstream_cache_status\u0026#34;\u0026#39;; log_format browser \u0026#39;$time_iso8601 $cookie_km_uid $remote_addr $host $request_uri $request_method \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34; \u0026#39; \u0026#39;$request_time $upstream_response_time \u0026#34;$upstream_cache_status\u0026#34; $http_x_requested_with $http_x_real_ip $upstream_addr $request_body\u0026#39;; log_format client \u0026#39;{\u0026#34;@timestamp\u0026#34;:\u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;time_local\u0026#34;:\u0026#34;$time_local\u0026#34;,\u0026#39; \u0026#39;\u0026#34;remote_user\u0026#34;:\u0026#34;$remote_user\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_x_forwarded_for\u0026#34;:\u0026#34;$http_x_forwarded_for\u0026#34;,\u0026#39; \u0026#39;\u0026#34;host\u0026#34;:\u0026#34;$server_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;remote_addr\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_x_real_ip\u0026#34;:\u0026#34;$http_x_real_ip\u0026#34;,\u0026#39; \u0026#39;\u0026#34;body_bytes_sent\u0026#34;:$body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;request_time\u0026#34;:$request_time,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;:$status,\u0026#39; \u0026#39;\u0026#34;upstream_response_time\u0026#34;:\u0026#34;$upstream_response_time\u0026#34;,\u0026#39; \u0026#39;\u0026#34;upstream_response_status\u0026#34;:\u0026#34;$upstream_status\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request\u0026#34;:\u0026#34;$request\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_referer\u0026#34;:\u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_user_agent\u0026#34;:\u0026#34;$http_user_agent\u0026#34;}\u0026#39;; access_log /access.log main; sendfile on; keepalive_timeout 120s 100s; keepalive_requests 500; send_timeout 60000s; client_header_buffer_size 4k; proxy_ignore_client_abort on; proxy_buffers 16 32k; proxy_buffer_size 64k; proxy_busy_buffers_size 64k; proxy_send_timeout 60000; proxy_read_timeout 60000; proxy_connect_timeout 60000; proxy_cache_valid 200 304 2h; proxy_cache_valid 500 404 2s; proxy_cache_key $host$request_uri$cookie_user; proxy_cache_methods GET HEAD POST; proxy_redirect off; proxy_http_version 1.1; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Frame-Options SAMEORIGIN; server_tokens off; client_max_body_size 50G; add_header X-Cache $upstream_cache_status; autoindex off; resolver 127.0.0.1:53 ipv6=off; server { listen 80; location / { set $service \u0026#39;\u0026#39;; rewrite_by_lua \u0026#39; local host = ngx.var.host local m = ngx.re.match(host, \u0026#34;(.+).test.imroc.io\u0026#34;) if m then ngx.var.service = \u0026#34;my-svc-\u0026#34; .. m[1] end \u0026#39;; proxy_pass http://$service; } } } 让该代理服务暴露公网访问可以用 Service 或 Ingress\n用 Service 的示例 (service.yaml):\napiVersion: v1 kind: Service metadata: labels: component: nginx name: service-nginx spec: type: LoadBalancer ports: - name: http port: 80 targetPort: http selector: component: nginx 用 Ingress 的示例 (ingress.yaml):\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: ingress-nginx spec: rules: - host: \u0026#34;*.test.imroc.io\u0026#34; http: paths: - backend: serviceName: service-nginx servicePort: 80 path: / "
},
{
	"uri": "https://k8s.imroc.io/security/user/",
	"title": "用户管理",
	"tags": [],
	"description": "",
	"content": "目录  利用 CSR API 创建用户     "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/disk-full/",
	"title": "磁盘爆满",
	"tags": [],
	"description": "",
	"content": "什么情况下磁盘可能会爆满 ？ kubelet 有 gc 和驱逐机制，通过 --image-gc-high-threshold, --image-gc-low-threshold, --eviction-hard, --eviction-soft, --eviction-minimum-reclaim 等参数控制 kubelet 的 gc 和驱逐策略来释放磁盘空间，如果配置正确的情况下，磁盘一般不会爆满。\n通常导致爆满的原因可能是配置不正确或者节点上有其它非 K8S 管理的进程在不断写数据到磁盘占用大量空间导致磁盘爆满。\n磁盘爆满会有什么影响 ？ 影响 K8S 运行我们主要关注 kubelet 和容器运行时这两个最关键的组件，它们所使用的目录通常不一样，kubelet 一般不会单独挂盘，直接使用系统磁盘，因为通常占用空间不会很大，容器运行时单独挂盘的场景比较多，当磁盘爆满的时候我们也要看 kubelet 和 容器运行时使用的目录是否在这个磁盘，通过 df 命令可以查看磁盘挂载点。\n容器运行时使用的目录所在磁盘爆满 如果容器运行时使用的目录所在磁盘空间爆满，可能会造成容器运行时无响应，比如 docker，执行 docker 相关的命令一直 hang 住， kubelet 日志也可以看到 PLEG unhealthy，因为 CRI 调用 timeout，当然也就无法创建或销毁容器，通常表现是 Pod 一直 ContainerCreating 或 一直 Terminating。\ndocker 默认使用的目录主要有:\n /var/run/docker: 用于存储容器运行状态，通过 dockerd 的 --exec-root 参数指定。 /var/lib/docker: 用于持久化容器相关的数据，比如容器镜像、容器可写层数据、容器标准日志输出、通过 docker 创建的 volume 等  Pod 启动可能报类似下面的事件:\nWarning FailedCreatePodSandBox 53m kubelet, 172.22.0.44 Failed create pod sandbox: rpc error: code = DeadlineExceeded desc = context deadline exceeded Warning FailedCreatePodSandBox 2m (x4307 over 16h) kubelet, 10.179.80.31 (combined from similar events): Failed create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod \u0026#34;apigateway-6dc48bf8b6-l8xrw\u0026#34;: Error response from daemon: mkdir /var/lib/docker/aufs/mnt/1f09d6c1c9f24e8daaea5bf33a4230de7dbc758e3b22785e8ee21e3e3d921214-init: no space left on device Warning Failed 5m1s (x3397 over 17h) kubelet, ip-10-0-151-35.us-west-2.compute.internal (combined from similar events): Error: container create failed: container_linux.go:336: starting container process caused \u0026#34;process_linux.go:399: container init caused \\\u0026#34;rootfs_linux.go:58: mounting \\\\\\\u0026#34;/sys\\\\\\\u0026#34; to rootfs \\\\\\\u0026#34;/var/lib/dockerd/storage/overlay/051e985771cc69f3f699895a1dada9ef6483e912b46a99e004af7bb4852183eb/merged\\\\\\\u0026#34; at \\\\\\\u0026#34;/var/lib/dockerd/storage/overlay/051e985771cc69f3f699895a1dada9ef6483e912b46a99e004af7bb4852183eb/merged/sys\\\\\\\u0026#34; caused \\\\\\\u0026#34;no space left on device\\\\\\\u0026#34;\\\u0026#34;\u0026#34; Pod 删除可能报类似下面的事件:\nNormal Killing 39s (x735 over 15h) kubelet, 10.179.80.31 Killing container with id docker://apigateway:Need to kill Pod kubelet 使用的目录所在磁盘爆满 如果 kubelet 使用的目录所在磁盘空间爆满(通常是系统盘)，新建 Pod 时连 Sandbox 都无法创建成功，因为 mkdir 将会失败，通常会有类似这样的 Pod 事件:\nWarning UnexpectedAdmissionError 44m kubelet, 172.22.0.44 Update plugin resources failed due to failed to write checkpoint file \u0026#34;kubelet_internal_checkpoint\u0026#34;: write /var/lib/kubelet/device-plugins/.728425055: no space left on device, which is unexpected. kubelet 默认使用的目录是 /var/lib/kubelet， 用于存储插件信息、Pod 相关的状态以及挂载的 volume (比如 emptyDir, ConfigMap, Secret)，通过 kubelet 的 --root-dir 参数指定。\n如何分析磁盘占用 ?  如果运行时使用的是 Docker，请参考本书 排错技巧: 分析 Docker 磁盘占用 (TODO)  如何恢复 ？ 如果容器运行时使用的 Docker，我们无法直接重启 dockerd 来释放一些空间，因为磁盘爆满后 dockerd 无法正常响应，停止的时候也会卡住。我们需要先手动清理一点文件腾出空间好让 dockerd 能够停止并重启。\n可以手动删除一些 docker 的 log 文件或可写层文件，通常删除 log:\n$ cd /var/lib/docker/containers $ du -sh * # 找到比较大的目录 $ cd dda02c9a7491fa797ab730c1568ba06cba74cecd4e4a82e9d90d00fa11de743c $ cat /dev/null \u0026gt; dda02c9a7491fa797ab730c1568ba06cba74cecd4e4a82e9d90d00fa11de743c-json.log.9 # 删除log文件  注意: 使用 cat /dev/null \u0026gt; 方式删除而不用 rm，因为用 rm 删除的文件，docker 进程可能不会释放文件，空间也就不会释放；log 的后缀数字越大表示越久远，先删除旧日志。  然后将该 node 标记不可调度，并将其已有的 pod 驱逐到其它节点，这样重启 dockerd 就会让该节点的 pod 对应的容器删掉，容器相关的日志(标准输出)与容器内产生的数据文件(没有挂载 volume, 可写层)也会被清理：\nkubectl drain \u0026lt;node-name\u0026gt; 重启 dockerd:\nsystemctl restart dockerd # or systemctl restart docker 等重启恢复，pod 调度到其它节点，排查磁盘爆满原因并清理和规避，然后取消节点不可调度标记:\nkubectl uncordon \u0026lt;node-name\u0026gt; 如何规避 ？ 正确配置 kubelet gc 和 驱逐相关的参数，即便到达爆满地步，此时节点上的 pod 也都早就自动驱逐到其它节点了，不会存在 Pod 一直 ContainerCreating 或 Terminating 的问题。\n"
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/kubernetes-overflow-and-drop/",
	"title": "神秘的溢出与丢包",
	"tags": [],
	"description": "",
	"content": "问题描述 有用户反馈大量图片加载不出来。\n图片下载走的 k8s ingress，这个 ingress 路径对应后端 service 是一个代理静态图片文件的 nginx deployment，这个 deployment 只有一个副本，静态文件存储在 nfs 上，nginx 通过挂载 nfs 来读取静态文件来提供图片下载服务，所以调用链是：client \u0026ndash;\u0026gt; k8s ingress \u0026ndash;\u0026gt; nginx \u0026ndash;\u0026gt; nfs。\n猜测 猜测: ingress 图片下载路径对应的后端服务出问题了。\n验证：在 k8s 集群直接 curl nginx 的 pod ip，发现不通，果然是后端服务的问题！\n抓包 继续抓包测试观察，登上 nginx pod 所在节点，进入容器的 netns 中：\n# 拿到 pod 中 nginx 的容器 id $ kubectl describe pod tcpbench-6484d4b457-847gl | grep -A10 \u0026#34;^Containers:\u0026#34; | grep -Eo \u0026#39;docker://.*$\u0026#39; | head -n 1 | sed \u0026#39;s/docker:\\/\\/\\(.*\\)$/\\1/\u0026#39; 49b4135534dae77ce5151c6c7db4d528f05b69b0c6f8b9dd037ec4e7043c113e # 通过容器 id 拿到 nginx 进程 pid $ docker inspect -f {{.State.Pid}} 49b4135534dae77ce5151c6c7db4d528f05b69b0c6f8b9dd037ec4e7043c113e 3985 # 进入 nginx 进程所在的 netns $ nsenter -n -t 3985 # 查看容器 netns 中的网卡信息，确认下 $ ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 3: eth0@if11: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 56:04:c7:28:b0:3c brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.26.0.8/26 scope global eth0 valid_lft forever preferred_lft forever 使用 tcpdump 指定端口 24568 抓容器 netns 中 eth0 网卡的包:\ntcpdump -i eth0 -nnnn -ttt port 24568 在其它节点准备使用 nc 指定源端口为 24568 向容器发包：\nnc -u 24568 172.16.1.21 80 观察抓包结果：\n00:00:00.000000 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000206334 ecr 0,nop,wscale 9], length 0 00:00:01.032218 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000207366 ecr 0,nop,wscale 9], length 0 00:00:02.011962 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000209378 ecr 0,nop,wscale 9], length 0 00:00:04.127943 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000213506 ecr 0,nop,wscale 9], length 0 00:00:08.192056 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000221698 ecr 0,nop,wscale 9], length 0 00:00:16.127983 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000237826 ecr 0,nop,wscale 9], length 0 00:00:33.791988 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000271618 ecr 0,nop,wscale 9], length 0 SYN 包到容器内网卡了，但容器没回 ACK，像是报文到达容器内的网卡后就被丢了。看样子跟防火墙应该也没什么关系，也检查了容器 netns 内的 iptables 规则，是空的，没问题。\n排除是 iptables 规则问题，在容器 netns 中使用 netstat -s 检查下是否有丢包统计:\n$ netstat -s | grep -E \u0026#39;overflow|drop\u0026#39; 12178939 times the listen queue of a socket overflowed 12247395 SYNs to LISTEN sockets dropped 果然有丢包，为了理解这里的丢包统计，我深入研究了一下，下面插播一些相关知识。\nsyn queue 与 accept queue Linux 进程监听端口时，内核会给它对应的 socket 分配两个队列：\n syn queue: 半连接队列。server 收到 SYN 后，连接会先进入 SYN_RCVD 状态，并放入 syn queue，此队列的包对应还没有完全建立好的连接（TCP 三次握手还没完成）。 accept queue: 全连接队列。当 TCP 三次握手完成之后，连接会进入 ESTABELISHED 状态并从 syn queue 移到 accept queue，等待被进程调用 accept() 系统调用 \u0026ldquo;拿走\u0026rdquo;。   注意：这两个队列的连接都还没有真正被应用层接收到，当进程调用 accept() 后，连接才会被应用层处理，具体到我们这个问题的场景就是 nginx 处理 HTTP 请求。\n 为了更好理解，可以看下这张 TCP 连接建立过程的示意图：\nlisten 与 accept 不管使用什么语言和框架，在写 server 端应用时，它们的底层在监听端口时最终都会调用 listen() 系统调用，处理新请求时都会先调用 accept() 系统调用来获取新的连接，然后再处理请求，只是有各自不同的封装而已，以 go 语言为例：\n// 调用 listen 监听端口 l, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:80\u0026#34;) if err != nil { panic(err) } for { // 不断调用 accept 获取新连接，如果 accept queue 为空就一直阻塞 \tconn, err := l.Accept() if err != nil { log.Println(\u0026#34;accept error:\u0026#34;, err) continue } // 每来一个新连接意味着一个新请求，启动协程处理请求 \tgo handle(conn) } Linux 的 backlog 内核既然给监听端口的 socket 分配了 syn queue 与 accept queue 两个队列，那它们有大小限制吗？可以无限往里面塞数据吗？当然不行！ 资源是有限的，尤其是在内核态，所以需要限制一下这两个队列的大小。那么它们的大小是如何确定的呢？我们先来看下 listen 这个系统调用:\nint listen(int sockfd, int backlog) 可以看到，能够传入一个整数类型的 backlog 参数，我们再通过 man listen 看下解释：\nThe behavior of the backlog argument on TCP sockets changed with Linux 2.2. Now it specifies the queue length for completely established sockets waiting to be accepted, instead of the number of incomplete connection requests. The maximum length of the queue for incomplete sockets can be set using /proc/sys/net/ipv4/tcp_max_syn_backlog. When syncookies are enabled there is no logical maximum length and this setting is ignored. See tcp(7) for more information. \nIf the backlog argument is greater than the value in /proc/sys/net/core/somaxconn, then it is silently truncated to that value; the default value in this file is 128. In kernels before 2.4.25, this limit was a hard coded value, SOMAXCONN, with the value 128.\n继续深挖了一下源码，结合这里的解释提炼一下：\n listen 的 backlog 参数同时指定了 socket 的 syn queue 与 accept queue 大小。 accept queue 最大不能超过 net.core.somaxconn 的值，即: max accept queue size = min(backlog, net.core.somaxconn)  如果启用了 syncookies (net.ipv4.tcp_syncookies=1)，当 syn queue 满了，server 还是可以继续接收 SYN 包并回复 SYN+ACK 给 client，只是不会存入 syn queue 了。因为会利用一套巧妙的 syncookies 算法机制生成隐藏信息写入响应的 SYN+ACK 包中，等 client 回 ACK 时，server 再利用 syncookies 算法校验报文，校验通过后三次握手就顺利完成了。所以如果启用了 syncookies，syn queue 的逻辑大小是没有限制的， syncookies 通常都是启用了的，所以一般不用担心 syn queue 满了导致丢包。syncookies 是为了防止 SYN Flood 攻击 (一种常见的 DDoS 方式)，攻击原理就是 client 不断发 SYN 包但不回最后的 ACK，填满 server 的 syn queue 从而无法建立新连接，导致 server 拒绝服务。 如果 syncookies 没有启用，syn queue 的大小就有限制，除了跟 accept queue 一样受 net.core.somaxconn 大小限制之外，还会受到 net.ipv4.tcp_max_syn_backlog 的限制，即: max syn queue size = min(backlog, net.core.somaxconn, net.ipv4.tcp_max_syn_backlog)   4.3 及其之前版本的内核，syn queue 的大小计算方式跟现在新版内核这里还不一样，详细请参考 commit ef547f2ac16b\n队列溢出 毫无疑问，在队列大小有限制的情况下，如果队列满了，再有新连接过来肯定就有问题。\n翻下 linux 源码，看下处理 SYN 包的部分，在 net/ipv4/tcp_input.c 的 tcp_conn_request 函数:\nif ((net-\u0026gt;ipv4.sysctl_tcp_syncookies == 2 || inet_csk_reqsk_queue_is_full(sk)) \u0026amp;\u0026amp; !isn) { want_cookie = tcp_syn_flood_action(sk, rsk_ops-\u0026gt;slab_name); if (!want_cookie) goto drop; } if (sk_acceptq_is_full(sk)) { NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS); goto drop; } goto drop 最终会走到 tcp_listendrop 函数，实际上就是将 ListenDrops 计数器 +1:\nstatic inline void tcp_listendrop(const struct sock *sk) { atomic_inc(\u0026amp;((struct sock *)sk)-\u0026gt;sk_drops); __NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENDROPS); } 大致可以看出来，对于 SYN 包：\n 如果 syn queue 满了并且没有开启 syncookies 就丢包，并将 ListenDrops 计数器 +1。 如果 accept queue 满了也会丢包，并将 ListenOverflows 和 ListenDrops 计数器 +1。  而我们前面排查问题通过 netstat -s 看到的丢包统计，其实就是对应的 ListenOverflows 和 ListenDrops 这两个计数器。\n除了用 netstat -s，还可以使用 nstat -az 直接看系统内各个计数器的值:\n$ nstat -az | grep -E \u0026#39;TcpExtListenOverflows|TcpExtListenDrops\u0026#39; TcpExtListenOverflows 12178939 0.0 TcpExtListenDrops 12247395 0.0 另外，对于低版本内核，当 accept queue 满了，并不会完全丢弃 SYN 包，而是对 SYN 限速。把内核源码切到 3.10 版本，看 net/ipv4/tcp_ipv4.c 中 tcp_v4_conn_request 函数:\n/* Accept backlog is full. If we have already queued enough * of warm entries in syn queue, drop request. It is better than * clogging syn queue with openreqs with exponentially increasing * timeout. */ if (sk_acceptq_is_full(sk) \u0026amp;\u0026amp; inet_csk_reqsk_queue_young(sk) \u0026gt; 1) { NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS); goto drop; } 其中 inet_csk_reqsk_queue_young(sk) \u0026gt; 1 的条件实际就是用于限速，仿佛在对 client 说: 哥们，你慢点！我的 accept queue 都满了，即便咱们握手成功，连接也可能放不进去呀。\n回到问题上来 总结之前观察到两个现象：\n 容器内抓包发现收到 client 的 SYN，但 nginx 没回包。 通过 netstat -s 发现有溢出和丢包的统计 (ListenOverflows 与 ListenDrops)。  根据之前的分析，我们可以推测是 syn queue 或 accept queue 满了。\n先检查下 syncookies 配置:\n$ cat /proc/sys/net/ipv4/tcp_syncookies 1 确认启用了 syncookies，所以 syn queue 大小没有限制，不会因为 syn queue 满而丢包，并且即便没开启 syncookies，syn queue 有大小限制，队列满了也不会使 ListenOverflows 计数器 +1。\n从计数器结果来看，ListenOverflows 和 ListenDrops 的值差别不大，所以推测很有可能是 accept queue 满了，因为当 accept queue 满了会丢 SYN 包，并且同时将 ListenOverflows 与 ListenDrops 计数器分别 +1。\n如何验证 accept queue 满了呢？可以在容器的 netns 中执行 ss -lnt 看下:\n$ ss -lnt State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 129 128 *:80 *:* 通过这条命令我们可以看到当前 netns 中监听 tcp 80 端口的 socket，Send-Q 为 128，Recv-Q 为 129。\n什么意思呢？通过调研得知：\n 对于 LISTEN 状态，Send-Q 表示 accept queue 的最大限制大小，Recv-Q 表示其实际大小。 对于 ESTABELISHED 状态，Send-Q 和 Recv-Q 分别表示发送和接收数据包的 buffer。  所以，看这里输出结果可以得知 accept queue 满了，当 Recv-Q 的值比 Send-Q 大 1 时表明 accept queue 溢出了，如果再收到 SYN 包就会丢弃掉。\n导致 accept queue 满的原因一般都是因为进程调用 accept() 太慢了，导致大量连接不能被及时 \u0026ldquo;拿走\u0026rdquo;。\n那么什么情况下进程调用 accept() 会很慢呢？猜测可能是进程连接负载高，处理不过来。\n而负载高不仅可能是 CPU 繁忙导致，还可能是 IO 慢导致，当文件 IO 慢时就会有很多 IO WAIT，在 IO WAIT 时虽然 CPU 不怎么干活，但也会占据 CPU 时间片，影响 CPU 干其它活。\n最终进一步定位发现是 nginx pod 挂载的 nfs 服务对应的 nfs server 负载较高，导致 IO 延时较大，从而使 nginx 调用 accept() 变慢，accept queue 溢出，使得大量代理静态图片文件的请求被丢弃，也就导致很多图片加载不出来。\n虽然根因不是 k8s 导致的问题，但也从中挖出一些在高并发场景下值得优化的点，请继续往下看。\nsomaxconn 的默认值很小 我们再看下之前 ss -lnt 的输出:\n$ ss -lnt State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 129 128 *:80 *:* 仔细一看，Send-Q 表示 accept queue 最大的大小，才 128 ？也太小了吧！\n根据前面的介绍我们知道，accept queue 的最大大小会受 net.core.somaxconn 内核参数的限制，我们看下 pod 所在节点上这个内核参数的大小:\n$ cat /proc/sys/net/core/somaxconn 32768 是 32768，挺大的，为什么这里 accept queue 最大大小就只有 128 了呢？\nnet.core.somaxconn 这个内核参数是 namespace 隔离了的，我们在容器 netns 中再确认了下：\n$ cat /proc/sys/net/core/somaxconn 128 为什么只有 128？看下 stackoverflow 这里 的讨论:\nThe \u0026quot;net/core\u0026quot; subsys is registered per network namespace. And the initial value for somaxconn is set to 128.\n原来新建的 netns 中 somaxconn 默认就为 128，在 include/linux/socket.h 中可以看到这个常量的定义:\n/* Maximum queue length specifiable by listen. */ #define SOMAXCONN\t128 很多人在使用 k8s 时都没太在意这个参数，为什么大家平常在较高并发下也没发现有问题呢？\n因为通常进程 accept() 都是很快的，所以一般 accept queue 基本都没什么积压的数据，也就不会溢出导致丢包了。\n对于并发量很高的应用，还是建议将 somaxconn 调高。虽然可以进入容器 netns 后使用 sysctl -w net.core.somaxconn=1024 或 echo 1024 \u0026gt; /proc/sys/net/core/somaxconn 临时调整，但调整的意义不大，因为容器内的进程一般在启动的时候才会调用 listen()，然后 accept queue 的大小就被决定了，并且不再改变。\n下面介绍几种调整方式:\n方式一: 使用 k8s sysctls 特性直接给 pod 指定内核参数 示例 yaml:\napiVersion: v1 kind: Pod metadata: name: sysctl-example spec: securityContext: sysctls: - name: net.core.somaxconn value: \u0026#34;8096\u0026#34; 有些参数是 unsafe 类型的，不同环境不一样，我的环境里是可以直接设置 pod 的 net.core.somaxconn 这个 sysctl 的。如果你的环境不行，请参考官方文档 Using sysctls in a Kubernetes Cluster 启用 unsafe 类型的 sysctl。\n 注：此特性在 k8s v1.12 beta，默认开启。\n 方式二: 使用 initContainers 设置内核参数 示例 yaml:\napiVersion: v1 kind: Pod metadata: name: sysctl-example-init spec: initContainers: - image: busybox command: - sh - -c - echo 1024 \u0026gt; /proc/sys/net/core/somaxconn imagePullPolicy: Always name: setsysctl securityContext: privileged: true Containers: ...  注: init container 需要 privileged 权限。\n 方式三: 安装 tuning CNI 插件统一设置 sysctl tuning plugin 地址: https://github.com/containernetworking/plugins/tree/master/plugins/meta/tuning\nCNI 配置示例:\n{ \u0026#34;name\u0026#34;: \u0026#34;mytuning\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;tuning\u0026#34;, \u0026#34;sysctl\u0026#34;: { \u0026#34;net.core.somaxconn\u0026#34;: \u0026#34;1024\u0026#34; } } nginx 的 backlog 我们使用方式一尝试给 nginx pod 的 somaxconn 调高到 8096 后观察:\n$ ss -lnt State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 512 511 *:80 *:* WTF? 还是溢出了，而且调高了 somaxconn 之后虽然 accept queue 的最大大小 (Send-Q) 变大了，但跟 8096 还差很远呀！\n在经过一番研究，发现 nginx 在 listen() 时并没有读取 somaxconn 作为 backlog 默认值传入，它有自己的默认值，也支持在配置里改。通过 ngx_http_core_module 的官方文档我们可以看到它在 linux 下的默认值就是 511:\nbacklog=number sets the backlog parameter in the listen() call that limits the maximum length for the queue of pending connections. By default, backlog is set to -1 on FreeBSD, DragonFly BSD, and macOS, and to 511 on other platforms. 配置示例:\nlisten 80 default backlog=1024; 所以，在容器中使用 nginx 来支撑高并发的业务时，记得要同时调整下 net.core.somaxconn 内核参数和 nginx.conf 中的 backlog 配置。\n参考资料  Using sysctls in a Kubernetes Cluster: https://kubernetes-io-vnext-staging.netlify.com/docs/tasks/administer-cluster/sysctl-cluster/ SYN packet handling in the wild: https://blog.cloudflare.com/syn-packet-handling-in-the-wild/ "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/low-throughput/",
	"title": "网络性能差",
	"tags": [],
	"description": "",
	"content": "IPVS 模式吞吐性能低 内核参数关闭 conn_reuse_mode:\nsysctl net.ipv4.vs.conn_reuse_mode=0 参考 issue: https://github.com/kubernetes/kubernetes/issues/70747\n"
},
{
	"uri": "https://k8s.imroc.io/cluster/network/",
	"title": "网络方案",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/trick/shell/network/",
	"title": "网络调试相关脚本",
	"tags": [],
	"description": "",
	"content": "进入容器 netns 粘贴脚本到命令行:\nfunction e() { set -eu ns=${2-\u0026#34;default\u0026#34;} pod=`kubectl -n $ns describe pod $1 | grep -A10 \u0026#34;^Containers:\u0026#34; | grep -Eo \u0026#39;docker://.*$\u0026#39; | head -n 1 | sed \u0026#39;s/docker:\\/\\/\\(.*\\)$/\\1/\u0026#39;` pid=`docker inspect -f {{.State.Pid}} $pod` echo \u0026#34;entering pod netns for $ns/$1\u0026#34; cmd=\u0026#34;nsenter -n --target $pid\u0026#34; echo $cmd $cmd } 进入在当前节点上运行的某个 pod 的 netns:\n# 进入 kube-system 命名空间下名为 metrics-server-6cf9685556-rclw5 的 pod 所在的 netns e metrics-server-6cf9685556-rclw5 kube-system 进入 pod 的 netns 后就使用节点上的工具在该 netns 中做操作，比如用 ip a 查询网卡和ip、用 ip route 查询路由、用 tcpdump 抓容器内的包等。\n不断尝试建立TCP连接测试网络连通性 while true; do echo \u0026#34;\u0026#34; | telnet 10.0.0.3 443; sleep 0.1; done  ctrl+c 终止测试 替换 10.0.0.3 与 443 为需要测试的 IP/域名 和端口  "
},
{
	"uri": "https://k8s.imroc.io/trick/shell/node/",
	"title": "节点相关脚本",
	"tags": [],
	"description": "",
	"content": "表格输出各节点占用的 podCIDR kubectl get no -o=custom-columns=INTERNAL-IP:.metadata.name,EXTERNAL-IP:.status.addresses[1].address,CIDR:.spec.podCIDR 示例输出:\nINTERNAL-IP EXTERNAL-IP CIDR 10.100.12.194 152.136.146.157 10.101.64.64/27 10.100.16.11 10.100.16.11 10.101.66.224/27 10.100.16.24 10.100.16.24 10.101.64.32/27 10.100.16.26 10.100.16.26 10.101.65.0/27 10.100.16.37 10.100.16.37 10.101.64.0/27 表格输出各节点总可用资源 (Allocatable) kubectl get no -o=custom-columns=\u0026#34;NODE:.metadata.name,ALLOCATABLE CPU:.status.allocatable.cpu,ALLOCATABLE MEMORY:.status.allocatable.memory\u0026#34; 示例输出：\nNODE ALLOCATABLE CPU ALLOCATABLE MEMORY 10.0.0.2 3920m 7051692Ki 10.0.0.3 3920m 7051816Ki 输出各节点已分配资源的情况 所有种类的资源已分配情况概览：\nkubectl get nodes --no-headers | awk \u0026#39;{print $1}\u0026#39; | xargs -I {} sh -c \u0026#34;echo {} ; kubectl describe node {} | grep Allocated -A 5 | grep -ve Event -ve Allocated -ve percent -ve --;\u0026#34; 示例输出:\n10.0.0.2 Resource Requests Limits cpu 3040m (77%) 19800m (505%) memory 4843402752 (67%) 15054901888 (208%) 10.0.0.3 Resource Requests Limits cpu 300m (7%) 1 (25%) memory 250M (3%) 2G (27%) 表格输出 cpu 已分配情况:\nkubectl get nodes --no-headers | awk \u0026#39;{print $1}\u0026#39; | xargs -I {} sh -c \u0026#39;echo -n \u0026#34;{}\\t\u0026#34; ; kubectl describe node {} | grep Allocated -A 5 | grep -ve Event -ve Allocated -ve percent -ve -- | grep cpu | awk \u0026#39;\\\u0026#39;\u0026#39;{print $2$3}\u0026#39;\\\u0026#39;\u0026#39;;\u0026#39; 示例输出：\n10.0.0.2\t3040m(77%) 10.0.0.3\t300m(7%) 表格输出 memory 已分配情况:\nkubectl get nodes --no-headers | awk \u0026#39;{print $1}\u0026#39; | xargs -I {} sh -c \u0026#39;echo -n \u0026#34;{}\\t\u0026#34; ; kubectl describe node {} | grep Allocated -A 5 | grep -ve Event -ve Allocated -ve percent -ve -- | grep memory | awk \u0026#39;\\\u0026#39;\u0026#39;{print $2$3}\u0026#39;\\\u0026#39;\u0026#39;;\u0026#39; 示例输出：\n10.0.0.2\t4843402752(67%) 10.0.0.3\t250M(3%) 线程数排名统计 printf \u0026#34; NUM PID\\t\\tCOMMAND\\n\u0026#34; \u0026amp;\u0026amp; ps -eLf | awk \u0026#39;{$1=null;$3=null;$4=null;$5=null;$6=null;$7=null;$8=null;$9=null;print}\u0026#39; | sort |uniq -c |sort -rn | head -10 示例输出:\nNUM PID\tCOMMAND 594 14418 java -server -Dspring.profiles.active=production -Xms2048M -Xmx2048M -Xss256k -Dinfo.app.version=33 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/gather-server/gather-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/gather-server -Dserver.tomcat.accesslog.directory=/home/log/gather-server -jar /home/app/gather-server.jar --server.port=8080 --management.port=10086 449 7088 java -server -Dspring.profiles.active=production -Dspring.cloud.config.token=nLfe-bQ0CcGnNZ_Q4Pt9KTizgRghZrGUVVqaDZYHU3R-Y_-U6k7jkm8RrBn7LPJD -Xms4256M -Xmx4256M -Xss256k -XX:+PrintFlagsFinal -XX:+UseG1GC -XX:+UseStringDeduplication -XX:MaxGCPauseMillis=200 -XX:MetaspaceSize=128M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -verbosegc -XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=15 -XX:GCLogFileSize=50M -XX:AutoBoxCacheMax=520 -Xloggc:/home/log/oauth-server/oauth-server-gac.log -Dinfo.app.version=12 -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.config=classpath:log4j2-spring-prod.xml -Dlogging.path=/home/log/oauth-server -Dserver.tomcat.accesslog.directory=/home/log/oauth-server -jar /home/app/oauth-server.jar --server.port=8080 --management.port=10086 --zuul.server.netty.threads.worker=14 --zuul.server.netty.socket.epoll=true 394 516 java -server -Dspring.profiles.active=production -Xms2048M -Xmx2048M -Xss1024k -Dinfo.app.version=43 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/asset-server/asset-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/asset-server -Dserver.tomcat.accesslog.directory=/home/log/asset-server -jar /home/app/asset-server.jar --server.port=8080 --management.port=10086 305 14668 java -server -Dspring.profiles.active=production -Xms1024M -Xmx1024M -Xss256k -Dinfo.app.version=3 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/talent-adapter-distribute/talent-adapter-distribute-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/talent-adapter-distribute -Dserver.tomcat.accesslog.directory=/home/log/talent-adapter-distribute -jar /home/app/talent-adapter-distribute.jar --server.port=8080 --management.port=10086 250 3979 java -server -Dspring.profiles.active=production -Xms2048M -Xmx2048M -Xss256k -Dinfo.app.version=20 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/uc-facade-server/uc-facade-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/uc-facade-server -Dserver.tomcat.accesslog.directory=/home/log/uc-facade-server -jar /home/app/uc-facade-server.jar --server.port=8080 --management.port=10086 246 12468 java -server -Dspring.profiles.active=production -Xms2048M -Xmx2048M -Xss256k -Dinfo.app.version=7 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/talent-user-server/talent-user-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/talent-user-server -Dserver.tomcat.accesslog.directory=/home/log/talent-user-server -jar /home/app/talent-user-server.jar --server.port=8080 --management.port=10086 242 19401 java -server -Dspring.profiles.active=production -Xms1024M -Xmx1024M -Xss256k -Dinfo.app.version=25 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/job-admin-server/job-admin-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/job-admin-server -Dserver.tomcat.accesslog.directory=/home/log/job-admin-server -jar /home/app/job-admin-server.jar --server.port=8080 --management.port=10086 213 539 java -server -Dspring.profiles.active=production -Xms512M -Xmx3072M -Xss256k -Dinfo.app.version=1 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/family-aplus-web/family-aplus-web-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/family-aplus-web -Dserver.tomcat.accesslog.directory=/home/log/family-aplus-web -jar /home/app/family-aplus-web.jar --server.port=8080 --management.port=10086 187 9357 java -server -Dspring.profiles.active=production -Xms2048M -Xmx2048M -Xss256k -Dinfo.app.version=2 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/orion-panel-server/orion-panel-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/orion-panel-server -Dserver.tomcat.accesslog.directory=/home/log/orion-panel-server -jar /home/app/orion-panel-server.jar --server.port=8080 --management.port=10086 181 14267 java -server -Dspring.profiles.active=production -Xms1024M -Xmx1024M -Xss256k -Dinfo.app.version=6 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/talent-mission-server/talent-mission-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/talent-mission-server -Dserver.tomcat.accesslog.directory=/home/log/talent-mission-server -jar /home/app/talent-mission-server.jar --server.port=8080 --management.port=10086  第一列表示线程数 第二列表示进程 PID 第三列是进程启动命令  "
},
{
	"uri": "https://k8s.imroc.io/avoid/scale-keepalive-service/",
	"title": "解决长连接服务扩容失效",
	"tags": [],
	"description": "",
	"content": "在现网运营中，有很多场景为了提高效率，一般都采用建立长连接的方式来请求。我们发现在客户端以长连接请求服务端的场景下，K8S的自动扩容会失效。原因是客户端长连接一直保留在老的Pod容器中，新扩容的Pod没有新的连接过来，导致K8S按照步长扩容第一批Pod之后就停止了扩容操作，而且新扩容的Pod没能承载请求，进而出现服务过载的情况，自动扩容失去了意义。\n对长连接扩容失效的问题，我们的解决方法是将长连接转换为短连接。我们参考了 nginx keepalive 的设计，nginx 中 keepalive_requests 这个配置项设定了一个TCP连接能处理的最大请求数，达到设定值(比如1000)之后服务端会在 http 的 Header 头标记 “Connection:close”，通知客户端处理完当前的请求后关闭连接，新的请求需要重新建立TCP连接，所以这个过程中不会出现请求失败，同时又达到了将长连接按需转换为短连接的目的。通过这个办法客户端和云K8S服务端处理完一批请求后不断的更新TCP连接，自动扩容的新Pod能接收到新的连接请求，从而解决了自动扩容失效的问题。\n由于Golang并没有提供方法可以获取到每个连接处理过的请求数，我们重写了 net.Listener 和 net.Conn，注入请求计数器，对每个连接处理的请求做计数，并通过 net.Conn.LocalAddr() 获得计数值，判断达到阈值 1000 后在返回的 Header 中插入 “Connection:close” 通知客户端关闭连接，重新建立连接来发起请求。以上处理逻辑用 Golang 实现示例代码如下：\npackage main import ( \u0026#34;net\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) // 重新定义net.Listener type counterListener struct { net.Listener } // 重写net.Listener.Accept(),对接收到的连接注入请求计数器 func (c *counterListener) Accept() (net.Conn, error) { conn, err := c.Listener.Accept() if err != nil { return nil, err } return \u0026amp;counterConn{Conn: conn}, nil } // 定义计数器counter和计数方法Increment() type counter int func (c *counter) Increment() int { *c++ return int(*c) } // 重新定义net.Conn,注入计数器ct type counterConn struct { net.Conn ct counter } // 重写net.Conn.LocalAddr()，返回本地网络地址的同时返回该连接累计处理过的请求数 func (c *counterConn) LocalAddr() net.Addr { return \u0026amp;counterAddr{c.Conn.LocalAddr(), \u0026amp;c.ct} } // 定义TCP连接计数器,指向连接累计请求的计数器 type counterAddr struct { net.Addr *counter } func main() { r := gin.New() r.Use(func(c *gin.Context) { localAddr := c.Request.Context().Value(http.LocalAddrContextKey) if ct, ok := localAddr.(interface{ Increment() int }); ok { if ct.Increment() \u0026gt;= 1000 { c.Header(\u0026#34;Connection\u0026#34;, \u0026#34;close\u0026#34;) } } c.Next() }) r.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.String(200, \u0026#34;plain/text\u0026#34;, \u0026#34;hello\u0026#34;) }) l, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8080\u0026#34;) if err != nil { panic(err) } err = http.Serve(\u0026amp;counterListener{l}, r) if err != nil { panic(err) } } "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/lb-with-local-externaltrafficpolicy-timeout-occasionally/",
	"title": "访问 externalTrafficPolicy 为 Local 的 Service 对应 LB 有时超时",
	"tags": [],
	"description": "",
	"content": "现象：用户在 TKE 创建了公网 LoadBalancer 类型的 Service，externalTrafficPolicy 设为了 Local，访问这个 Service 对应的公网 LB 有时会超时。\nexternalTrafficPolicy 为 Local 的 Service 用于在四层获取客户端真实源 IP，官方参考文档：Source IP for Services with Type=LoadBalancer\nTKE 的 LoadBalancer 类型 Service 实现是使用 CLB 绑定所有节点对应 Service 的 NodePort，CLB 不做 SNAT，报文转发到 NodePort 时源 IP 还是真实的客户端 IP，如果 NodePort 对应 Service 的 externalTrafficPolicy 不是 Local 的就会做 SNAT，到 pod 时就看不到客户端真实源 IP 了，但如果是 Local 的话就不做 SNAT，如果本机 node 有这个 Service 的 endpoint 就转到对应 pod，如果没有就直接丢掉，因为如果转到其它 node 上的 pod 就必须要做 SNAT，不然无法回包，而 SNAT 之后就无法获取真实源 IP 了。\nLB 会对绑定节点的 NodePort 做健康检查探测，检查 LB 的健康检查状态: 发现这个 NodePort 的所有节点都不健康 !!!\n那么问题来了:\n 为什么会全不健康，这个 Service 有对应的 pod 实例，有些节点上是有 endpoint 的，为什么它们也不健康? LB 健康检查全不健康，但是为什么有时还是可以访问后端服务?  跟 LB 的同学确认: 如果后端 rs 全不健康会激活 LB 的全死全活逻辑，也就是所有后端 rs 都可以转发。\n那么有 endpoint 的 node 也是不健康这个怎么解释?\n在有 endpoint 的 node 上抓 NodePort 的包: 发现很多来自 LB 的 SYN，但是没有响应 ACK。\n看起来报文在哪被丢了，继续抓下 cbr0 看下: 发现没有来自 LB 的包，说明报文在 cbr0 之前被丢了。\n再观察用户集群环境信息:\n k8s 版本1.12 启用了 ipvs 只有 local 的 service 才有异常  尝试新建一个 1.12 启用 ipvs 和一个没启用 ipvs 的测试集群。也都创建 Local 的 LoadBalancer Service，发现启用 ipvs 的测试集群复现了那个问题，没启用 ipvs 的集群没这个问题。\n再尝试创建 1.10 的集群，也启用 ipvs，发现没这个问题。\n看起来跟集群版本和是否启用 ipvs 有关。\n1.12 对比 1.10 启用 ipvs 的集群: 1.12 的会将 LB 的 EXTERNAL-IP 绑到 kube-ipvs0 上，而 1.10 的不会:\n$ ip a show kube-ipvs0 | grep -A2 170.106.134.124 inet 170.106.134.124/32 brd 170.106.134.124 scope global kube-ipvs0 valid_lft forever preferred_lft forever  170.106.134.124 是 LB 的公网 IP 1.12 启用 ipvs 的集群将 LB 的公网 IP 绑到了 kube-ipvs0 网卡上  kube-ipvs0 是一个 dummy interface，实际不会接收报文，可以看到它的网卡状态是 DOWN，主要用于绑 ipvs 规则的 VIP，因为 ipvs 主要工作在 netfilter 的 INPUT 链，报文通过 PREROUTING 链之后需要决定下一步该进入 INPUT 还是 FORWARD 链，如果是本机 IP 就会进入 INPUT，如果不是就会进入 FORWARD 转发到其它机器。所以 k8s 利用 kube-ipvs0 这个网卡将 service 相关的 VIP 绑在上面以便让报文进入 INPUT 进而被 ipvs 转发。\n当 IP 被绑到 kube-ipvs0 上，内核会自动将上面的 IP 写入 local 路由:\n$ ip route show table local | grep 170.106.134.124 local 170.106.134.124 dev kube-ipvs0 proto kernel scope host src 170.106.134.124 内核认为在 local 路由里的 IP 是本机 IP，而 linux 默认有个行为: 忽略任何来自非回环网卡并且源 IP 是本机 IP 的报文。而 LB 的探测报文源 IP 就是 LB IP，也就是 Service 的 EXTERNAL-IP 猜想就是因为这个 IP 被绑到 kube-ipvs0，自动加进 local 路由导致内核直接忽略了 LB 的探测报文。\n带着猜想做实现， 试一下将 LB IP 从 local 路由中删除:\nip route del table local local 170.106.134.124 dev kube-ipvs0 proto kernel scope host src 170.106.134.124 发现这个 node 的在 LB 的健康检查的状态变成健康了! 看来就是因为这个 LB IP 被绑到 kube-ipvs0 导致内核忽略了来自 LB 的探测报文，然后 LB 收不到回包认为不健康。\n那为什么其它厂商没反馈这个问题？应该是 LB 的实现问题，腾讯云的公网 CLB 的健康探测报文源 IP 就是 LB 的公网 IP，而大多数厂商的 LB 探测报文源 IP 是保留 IP 并非 LB 自身的 VIP。\n如何解决呢? 发现一个内核参数: accept_local 可以让 linux 接收源 IP 是本机 IP 的报文。\n试了开启这个参数，确实在 cbr0 收到来自 LB 的探测报文了，说明报文能被 pod 收到，但抓 eth0 还是没有给 LB 回包。\n为什么没有回包? 分析下五元组，要给 LB 回包，那么 目的IP:目的Port 必须是探测报文的 源IP:源Port，所以目的 IP 就是 LB IP，由于容器不在主 netns，发包经过 veth pair 到 cbr0 之后需要再经过 netfilter 处理，报文进入 PREROUTING 链然后发现目的 IP 是本机 IP，进入 INPUT 链，所以报文就出不去了。再分析下进入 INPUT 后会怎样，因为目的 Port 跟 LB 探测报文源 Port 相同，是一个随机端口，不在 Service 的端口列表，所以没有对应的 IPVS 规则，IPVS 也就不会转发它，而 kube-ipvs0 上虽然绑了这个 IP，但它是一个 dummy interface，不会收包，所以报文最后又被忽略了。\n再看看为什么 1.12 启用 ipvs 会绑 EXTERNAL-IP 到 kube-ipvs0，翻翻 k8s 的 kube-proxy 支持 ipvs 的 proposal，发现有个地方说法有点漏洞:\nLB 类型 Service 的 status 里有 ingress IP，实际就是 kubectl get service 看到的 EXTERNAL-IP，这里说不会绑定这个 IP 到 kube-ipvs0，但后面又说会给它创建 ipvs 规则，既然没有绑到 kube-ipvs0，那么这个 IP 的报文根本不会进入 INPUT 被 ipvs 模块转发，创建的 ipvs 规则也是没用的。\n后来找到作者私聊，思考了下，发现设计上确实有这个问题。\n看了下 1.10 确实也是这么实现的，但是为什么 1.12 又绑了这个 IP 呢? 调研后发现是因为 #59976 这个 issue 发现一个问题，后来引入 #63066 这个 PR 修复的，而这个 PR 的行为就是让 LB IP 绑到 kube-ipvs0，这个提交影响 1.11 及其之后的版本。\n#59976 的问题是因为没绑 LB IP到 kube-ipvs0 上，在自建集群使用 MetalLB 来实现 LoadBalancer 类型的 Service，而有些网络环境下，pod 是无法直接访问 LB 的，导致 pod 访问 LB IP 时访问不了，而如果将 LB IP 绑到 kube-ipvs0 上就可以通过 ipvs 转发到 LB 类型 Service 对应的 pod 去， 而不需要真正经过 LB，所以引入了 #63066 这个PR。\n临时方案: 将 #63066 这个 PR 的更改回滚下，重新编译 kube-proxy，提供升级脚本升级存量 kube-proxy。\n如果是让 LB 健康检查探测支持用保留 IP 而不是自身的公网 IP ，也是可以解决，但需要跨团队合作，而且如果多个厂商都遇到这个问题，每家都需要为解决这个问题而做开发调整，代价较高，所以长期方案需要跟社区沟通一起推进，所以我提了 issue，将问题描述的很清楚: #79783\n小思考: 为什么 CLB 可以不做 SNAT ? 回包目的 IP 就是真实客户端 IP，但客户端是直接跟 LB IP 建立的连接，如果回包不经过 LB 是不可能发送成功的呀。\n是因为 CLB 的实现是在母机上通过隧道跟 CVM 互联的，多了一层封装，回包始终会经过 LB。\n就是因为 CLB 不做 SNAT，正常来自客户端的报文是可以发送到 nodeport，但健康检查探测报文由于源 IP 是 LB IP 被绑到 kube-ipvs0 导致被忽略，也就解释了为什么健康检查失败，但通过LB能访问后端服务，只是有时会超时。那么如果要做 SNAT 的 LB 岂不是更糟糕，所有报文都变成 LB IP，所有报文都会被忽略?\n我提的 issue 有回复指出，AWS 的 LB 会做 SNAT，但它们不将 LB 的 IP 写到 Service 的 Status 里，只写了 hostname，所以也不会绑 LB IP 到 kube-ipvs0:\n但是只写 hostname 也得 LB 支持自动绑域名解析，并且个人觉得只写 hostname 很别扭，通过 kubectl get svc 或者其它 k8s 管理系统无法直接获取 LB IP，这不是一个好的解决方法。\n我提了 #79976 这个 PR 可以解决问题: 给 kube-proxy 加 --exclude-external-ip 这个 flag 控制是否为 LB IP 创建 ipvs 规则和绑定 kube-ipvs0。\n但有人担心增加 kube-proxy flag 会增加 kube-proxy 的调试复杂度，看能否在 iptables 层面解决: 仔细一想，确实可行，打算有空实现下，重新提个 PR: "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/no-route-to-host/",
	"title": "诡异的 No route to host",
	"tags": [],
	"description": "",
	"content": "问题反馈 有用户反馈 Deployment 滚动更新的时候，业务日志偶尔会报 \u0026ldquo;No route to host\u0026rdquo; 的错误。\n分析 之前没遇到滚动更新会报 \u0026ldquo;No route to host\u0026rdquo; 的问题，我们先看下滚动更新导致连接异常有哪些常见的报错:\n  Connection reset by peer: 连接被重置。通常是连接建立过，但 server 端发现 client 发的包不对劲就返回 RST，应用层就报错连接被重置。比如在 server 滚动更新过程中，client 给 server 发的请求还没完全结束，或者本身是一个类似 grpc 的多路复用长连接，当 server 对应的旧 Pod 删除(没有做优雅结束，停止时没有关闭连接)，新 Pod 很快创建启动并且刚好有跟之前旧 Pod 一样的 IP，这时 kube-proxy 也没感知到这个 IP 其实已经被删除然后又被重建了，针对这个 IP 的规则就不会更新，旧的连接依然发往这个 IP，但旧 Pod 已经不在了，后面继续发包时依然转发给这个 Pod IP，最终会被转发到这个有相同 IP 的新 Pod 上，而新 Pod 收到此包时检查报文发现不对劲，就返回 RST 给 client 告知将连接重置。针对这种情况，建议应用自身处理好优雅结束：Pod 进入 Terminating 状态后会发送 SIGTERM 信号给业务进程，业务进程的代码需处理这个信号，在进程退出前关闭所有连接。\n  Connection refused: 连接被拒绝。通常是连接还没建立，client 正在发 SYN 包请求建立连接，但到了 server 之后发现端口没监听，内核就返回 RST 包，然后应用层就报错连接被拒绝。比如在 server 滚动更新过程中，旧的 Pod 中的进程很快就停止了(网卡还未完全销毁)，但 client 所在节点的 iptables/ipvs 规则还没更新，包就可能会被转发到了这个停止的 Pod (由于 k8s 的 controller 模式，从 Pod 删除到 service 的 endpoint 更新，再到 kube-proxy watch 到更新并更新 节点上的 iptables/ipvs 规则，这个过程是异步的，中间存在一点时间差，所以有可能存在 Pod 中的进程已经监听，但 iptables/ipvs 规则还没更新的情况)。针对这种情况，建议给容器加一个 preStop，在真正销毁 Pod 之前等待一段时间，留时间给 kube-proxy 更新转发规则，更新完之后就不会再有新连接往这个旧 Pod 转发了，preStop 示例:\nlifecycle: preStop: exec: command: - /bin/bash - -c - sleep 30 另外，还可能是新的 Pod 启动比较慢，虽然状态已经 Ready，但实际上可能端口还没监听，新的请求被转发到这个还没完全启动的 Pod 就会报错连接被拒绝。针对这种情况，建议给容器加就绪检查 (readinessProbe)，让容器真正启动完之后才将其状态置为 Ready，然后 kube-proxy 才会更新转发规则，这样就能保证新的请求只被转发到完全启动的 Pod，readinessProbe 示例:\nreadinessProbe: httpGet: path: /healthz port: 80 httpHeaders: - name: X-Custom-Header value: Awesome initialDelaySeconds: 15 timeoutSeconds: 1   Connection timed out: 连接超时。通常是连接还没建立，client 发 SYN 请求建立连接一直等到超时时间都没有收到 ACK，然后就报错连接超时。这个可能场景跟前面 Connection refused 可能的场景类似，不同点在于端口有监听，但进程无法正常响应了: 转发规则还没更新，旧 Pod 的进程正在停止过程中，虽然端口有监听，但已经不响应了；或者转发规则更新了，新 Pod 端口也监听了，但还没有真正就绪，还没有能力处理新请求。针对这些情况的建议跟前面一样：加 preStop 和 readinessProbe。\n  下面我们来继续分析下滚动更新时发生 No route to host 的可能情况。\n这个报错很明显，IP 无法路由，通常是将报文发到了一个已经彻底销毁的 Pod (网卡已经不在)。不可能发到一个网卡还没创建好的 Pod，因为即便不加存活检查，也是要等到 Pod 网络初始化完后才可能 Ready，然后 kube-proxy 才会更新转发规则。\n什么情况下会转发到一个已经彻底销毁的 Pod？ 借鉴前面几种滚动更新的报错分析，我们推测应该是 Pod 很快销毁了但转发规则还没更新，从而新的请求被转发了这个已经销毁的 Pod，最终报文到达这个 Pod 所在 PodCIDR 的 Node 上时，Node 发现本机已经没有这个 IP 的容器，然后 Node 就返回 ICMP 包告知 client 这个 IP 不可达，client 收到 ICMP 后，应用层就会报错 \u0026ldquo;No route to host\u0026rdquo;。\n所以根据我们的分析，关键点在于 Pod 销毁太快，转发规则还没来得及更新，导致后来的请求被转发到已销毁的 Pod。针对这种情况，我们可以给容器加一个 preStop，留时间给 kube-proxy 更新转发规则来解决，参考 《Kubernetes实践指南》中的部分章节: https://k8s.imroc.io/best-practice/high-availability-deployment-of-applications#smooth-update-using-prestophook-and-readinessprobe\n问题没有解决 我们自己没有复现用户的 \u0026ldquo;No route to host\u0026rdquo; 的问题，可能是复现条件比较苛刻，最后将我们上面理论上的分析结论作为解决方案给到了用户。\n但用户尝试加了 preStop 之后，问题依然存在，服务滚动更新时偶尔还是会出现 \u0026ldquo;No route to host\u0026rdquo;。\n深入分析 为了弄清楚根本原因，我们请求用户协助搭建了一个可以复现问题的测试环境，最终这个问题在测试环境中可以稳定复现。\n仔细观察，实际是部署两个服务：ServiceA 和 ServiceB。使用 ab 压测工具去压测 ServiceA （短连接），然后 ServiceA 会通过 RPC 调用 ServiceB (短连接)，滚动更新的是 ServiceB，报错发生在 ServiceA 调用 ServiceB 这条链路。\n在 ServiceB 滚动更新期间，新的 Pod Ready 了之后会被添加到 IPVS 规则的 RS 列表，但旧的 Pod 不会立即被踢掉，而是将新的 Pod 权重置为1，旧的置为 0，通过在 client 所在节点查看 IPVS 规则可以看出来:\nroot@VM-0-3-ubuntu:~# ipvsadm -ln -t 172.16.255.241:80 Prot LocalAddress:Port Scheduler Flags -\u0026gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 172.16.255.241:80 rr -\u0026gt; 172.16.8.106:80 Masq 0 5 14048 -\u0026gt; 172.16.8.107:80 Masq 1 2 243 为什么不立即踢掉旧的 Pod 呢？因为要支持优雅结束，让存量的连接处理完，等存量连接全部结束了再踢掉它(ActiveConn+InactiveConn=0)，这个逻辑可以通过这里的代码确认：https://github.com/kubernetes/kubernetes/blob/v1.17.0/pkg/proxy/ipvs/graceful_termination.go#L170\n然后再通过 ipvsadm -lnc | grep 172.16.8.106 发现旧 Pod 上的连接大多是 TIME_WAIT 状态，这个也容易理解：因为 ServiceA 作为 client 发起短连接请求调用 ServiceB，调用完成就会关闭连接，TCP 三次挥手后进入 TIME_WAIT 状态，等待 2*MSL (2 分钟) 的时长再清理连接。\n经过上面的分析，看起来都是符合预期的，那为什么还会出现 \u0026ldquo;No route to host\u0026rdquo; 呢？难道权重被置为 0 之后还有新连接往这个旧 Pod 转发？我们来抓包看下：\nroot@VM-0-3-ubuntu:~# tcpdump -i eth0 host 172.16.8.106 -n -tttt tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 2019-12-13 11:49:47.319093 IP 10.0.0.3.36708 \u0026gt; 172.16.8.106.80: Flags [S], seq 3988339656, win 29200, options [mss 1460,sackOK,TS val 3751111666 ecr 0,nop,wscale 9], length 0 2019-12-13 11:49:47.319133 IP 10.0.0.3.36706 \u0026gt; 172.16.8.106.80: Flags [S], seq 109196945, win 29200, options [mss 1460,sackOK,TS val 3751111666 ecr 0,nop,wscale 9], length 0 2019-12-13 11:49:47.319144 IP 10.0.0.3.36704 \u0026gt; 172.16.8.106.80: Flags [S], seq 1838682063, win 29200, options [mss 1460,sackOK,TS val 3751111666 ecr 0,nop,wscale 9], length 0 2019-12-13 11:49:47.319153 IP 10.0.0.3.36702 \u0026gt; 172.16.8.106.80: Flags [S], seq 1591982963, win 29200, options [mss 1460,sackOK,TS val 3751111666 ecr 0,nop,wscale 9], length 0 果然是！即使权重为 0，仍然会尝试发 SYN 包跟这个旧 Pod 建立连接，但永远无法收到 ACK，因为旧 Pod 已经销毁了。为什么会这样呢？难道是 IPVS 内核模块的调度算法有问题？尝试去看了下 linux 内核源码，并没有发现哪个调度策略的实现函数会将新连接调度到权重为 0 的 rs 上。\n这就奇怪了，可能不是调度算法的问题？继续尝试看更多的代码，主要是 net/netfilter/ipvs/ip_vs_core.c 中的 ip_vs_in 函数，也就是 IPVS 模块处理报文的主要入口，发现它会先在本地连接转发表看这个包是否已经有对应的连接了（匹配五元组），如果有就说明它不是新连接也就不会调度，直接发给这个连接对应的之前已经调度过的 rs (也不会判断权重)；如果没匹配到说明这个包是新的连接，就会走到调度这里 (rr, wrr 等调度策略)，这个逻辑看起来也没问题。\n那为什么会转发到权重为 0 的 rs ？难道是匹配连接这里出问题了？新的连接匹配到了旧的连接？我开始做实验验证这个猜想，修改一下这里的逻辑：检查匹配到的连接对应的 rs 如果权重为 0，则重新调度。然后重新编译和加载 IPVS 内核模块，再重新压测一下，发现问题解决了！没有报 \u0026ldquo;No route to host\u0026rdquo; 了。\n虽然通过改内核源码解决了，但我知道这不是一个好的解决方案，它会导致 IPVS 不支持连接的优雅结束，因为不再转发包给权重为 0 的 rs，存量的连接就会立即中断。\n继续陷入深思\u0026hellip;\u0026hellip;\n这个实验只是证明了猜想：新连接匹配到了旧连接。那为什么会这样呢？难道新连接报文的五元组跟旧连接的相同了？\n经过一番思考，发现这个是有可能的。因为 ServiceA 作为 client 请求 ServiceB，不同请求的源 IP 始终是相同的，关键点在于源端口是否可能相同。由于 ServiceA 向 ServiceB 发起大量短连接，ServiceA 所在节点就会有大量 TIME_WAIT 状态的连接，需要等 2 分钟 (2*MSL) 才会清理，而由于连接量太大，每次发起的连接都会占用一个源端口，当源端口不够用了，就会重用 TIME_WAIT 状态连接的源端口，这个时候当报文进入 IPVS 模块，检测到它的五元组跟本地连接转发表中的某个连接一致(TIME_WAIT 状态)，就以为它是一个存量连接，然后直接将报文转发给这个连接之前对应的 rs 上，然而这个 rs 对应的 Pod 早已销毁，所以抓包看到的现象是将 SYN 发给了旧 Pod，并且无法收到 ACK，伴随着返回 ICMP 告知这个 IP 不可达，也被应用解释为 \u0026ldquo;No route to host\u0026rdquo;。\n后来无意间又发现一个还在 open 状态的 issue，虽然还没提到 \u0026ldquo;No route to host\u0026rdquo; 关键字，但讨论的跟我们这个其实是同一个问题。我也参与了讨论，有兴趣的同学可以看下：https://github.com/kubernetes/kubernetes/issues/81775\n总结 这个问题通常发生的场景就是类似于我们测试环境这种：ServiceA 对外提供服务，当外部发起请求，ServiceA 会通过 rpc 或 http 调用 ServiceB，如果外部请求量变大，ServiceA 调用 ServiceB 的量也会跟着变大，大到一定程度，ServiceA 所在节点源端口不够用，复用 TIME_WAIT 状态连接的源端口，导致五元组跟 IPVS 里连接转发表中的 TIME_WAIT 连接相同，IPVS 就认为这是一个存量连接的报文，就不判断权重直接转发给之前的 rs，导致转发到已销毁的 Pod，从而发生 \u0026ldquo;No route to host\u0026rdquo;。\n如何规避？集群规模小可以使用 iptables 模式，如果需要使用 ipvs 模式，可以增加 ServiceA 的副本，并且配置反亲和性 (podAntiAffinity)，让 ServiceA 的 Pod 部署到不同节点，分摊流量，避免流量集中到某一个节点，导致调用 ServiceB 时源端口复用。\n如何彻底解决？暂时还没有一个完美的方案。\nIssue 85517 讨论让 kube-proxy 支持自定义配置几种连接状态的超时时间，但这对 TIME_WAIT 状态无效。\nIssue 81308 讨论 IVPS 的优雅结束是否不考虑不活跃的连接 (包括 TIME_WAIT 状态的连接)，也就是只考虑活跃连接，当活跃连接数为 0 之后立即踢掉 rs。这个确实可以更快的踢掉 rs，但无法让优雅结束做到那么优雅了，并且有人测试了，即便是不考虑不活跃连接，当请求量很大，还是不能很快踢掉 rs，因为源端口复用还是会导致不断有新的连接占用旧的连接，在较新的内核版本，SYN_RECV 状态也被视为活跃连接，所以活跃连接数还是不会很快降到 0。\n这个问题的终极解决方案该走向何方，我们拭目以待，感兴趣的同学可以持续关注 issue 81775 并参与讨论。想学习更多 K8S 知识，可以关注本人的开源书《Kubernetes实践指南》: https://k8s.imroc.io\n"
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/cross-vpc-connect-nodeport-timeout/",
	"title": "跨 VPC 访问 NodePort 经常超时",
	"tags": [],
	"description": "",
	"content": "现象: 从 VPC a 访问 VPC b 的 TKE 集群的某个节点的 NodePort，有时候正常，有时候会卡住直到超时。\n原因怎么查？\n当然是先抓包看看啦，抓 server 端 NodePort 的包，发现异常时 server 能收到 SYN，但没响应 ACK:\n反复执行 netstat -s | grep LISTEN 发现 SYN 被丢弃数量不断增加:\n分析：\n 两个VPC之间使用对等连接打通的，CVM 之间通信应该就跟在一个内网一样可以互通。 为什么同一 VPC 下访问没问题，跨 VPC 有问题? 两者访问的区别是什么?  再仔细看下 client 所在环境，发现 client 是 VPC a 的 TKE 集群节点，捋一下:\n client 在 VPC a 的 TKE 集群的节点 server 在 VPC b 的 TKE 集群的节点  因为 TKE 集群中有个叫 ip-masq-agent 的 daemonset，它会给 node 写 iptables 规则，默认 SNAT 目的 IP 是 VPC 之外的报文，所以 client 访问 server 会做 SNAT，也就是这里跨 VPC 相比同 VPC 访问 NodePort 多了一次 SNAT，如果是因为多了一次 SNAT 导致的这个问题，直觉告诉我这个应该跟内核参数有关，因为是 server 收到包没回包，所以应该是 server 所在 node 的内核参数问题，对比这个 node 和 普通 TKE node 的默认内核参数，发现这个 node net.ipv4.tcp_tw_recycle = 1，这个参数默认是关闭的，跟用户沟通后发现这个内核参数确实在做压测的时候调整过。\n解释一下，TCP 主动关闭连接的一方在发送最后一个 ACK 会进入 TIME_AWAIT 状态，再等待 2 个 MSL 时间后才会关闭(因为如果 server 没收到 client 第四次挥手确认报文，server 会重发第三次挥手 FIN 报文，所以 client 需要停留 2 MSL的时长来处理可能会重复收到的报文段；同时等待 2 MSL 也可以让由于网络不通畅产生的滞留报文失效，避免新建立的连接收到之前旧连接的报文)，了解更详细的过程请参考 TCP 四次挥手。\n参数 tcp_tw_recycle 用于快速回收 TIME_AWAIT 连接，通常在增加连接并发能力的场景会开启，比如发起大量短连接，快速回收可避免 tw_buckets 资源耗尽导致无法建立新连接 (time wait bucket table overflow)\n查得 tcp_tw_recycle 有个坑，在 RFC1323 有段描述:\nAn additional mechanism could be added to the TCP, a per-host cache of the last timestamp received from any connection. This value could then be used in the PAWS mechanism to reject old duplicate segments from earlier incarnations of the connection, if the timestamp clock can be guaranteed to have ticked at least once since the old connection was open. This would require that the TIME-WAIT delay plus the RTT together must be at least one tick of the sender’s timestamp clock. Such an extension is not part of the proposal of this RFC.\n大概意思是说 TCP 有一种行为，可以缓存每个连接最新的时间戳，后续请求中如果时间戳小于缓存的时间戳，即视为无效，相应的数据包会被丢弃。\nLinux 是否启用这种行为取决于 tcp_timestamps 和 tcp_tw_recycle，因为 tcp_timestamps 缺省开启，所以当 tcp_tw_recycle 被开启后，实际上这种行为就被激活了，当客户端或服务端以 NAT 方式构建的时候就可能出现问题。\n当多个客户端通过 NAT 方式联网并与服务端交互时，服务端看到的是同一个 IP，也就是说对服务端而言这些客户端实际上等同于一个，可惜由于这些客户端的时间戳可能存在差异，于是乎从服务端的视角看，便可能出现时间戳错乱的现象，进而直接导致时间戳小的数据包被丢弃。如果发生了此类问题，具体的表现通常是是客户端明明发送的 SYN，但服务端就是不响应 ACK。\n回到我们的问题上，client 所在节点上可能也会有其它 pod 访问到 server 所在节点，而它们都被 SNAT 成了 client 所在节点的 NODE IP，但时间戳存在差异，server 就会看到时间戳错乱，因为开启了 tcp_tw_recycle 和 tcp_timestamps 激活了上述行为，就丢掉了比缓存时间戳小的报文，导致部分 SYN 被丢弃，这也解释了为什么之前我们抓包发现异常时 server 收到了 SYN，但没有响应 ACK，进而说明为什么 client 的请求部分会卡住直到超时。\n由于 tcp_tw_recycle 坑太多，在内核 4.12 之后已移除: remove tcp_tw_recycle\n"
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/",
	"title": "踩坑分享",
	"tags": [],
	"description": "",
	"content": "  ARP 缓存爆满导致健康检查失败   DNS 5 秒延时   DNS 解析异常   kubectl edit 或者 apply 报 SchemaError   LB 压测 NodePort CPS 低   Pod 偶尔存活检查失败   Pod 访问另一个集群的 apiserver 有延时   神秘的溢出与丢包   访问 externalTrafficPolicy 为 Local 的 Service 对应 LB 有时超时   诡异的 No route to host   跨 VPC 访问 NodePort 经常超时   驱逐导致服务中断   "
},
{
	"uri": "https://k8s.imroc.io/cluster/runtime/",
	"title": "运行时方案",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/deploy/addons/coredns/",
	"title": "部署 CoreDNS",
	"tags": [],
	"description": "",
	"content": "下载部署脚本 $ git clone https://github.com/coredns/deployment.git $ cd deployment/kubernetes $ ls CoreDNS-k8s_version.md FAQs.md README.md Scaling_CoreDNS.md Upgrading_CoreDNS.md coredns.yaml.sed corefile-tool deploy.sh migration rollback.sh 部署脚本用法 查看 help:\n$ ./deploy.sh -h usage: ./deploy.sh [ -r REVERSE-CIDR ] [ -i DNS-IP ] [ -d CLUSTER-DOMAIN ] [ -t YAML-TEMPLATE ] -r : Define a reverse zone for the given CIDR. You may specifcy this option more than once to add multiple reverse zones. If no reverse CIDRs are defined, then the default is to handle all reverse zones (i.e. in-addr.arpa and ip6.arpa) -i : Specify the cluster DNS IP address. If not specificed, the IP address of the existing \u0026#34;kube-dns\u0026#34; service is used, if present. -s : Skips the translation of kube-dns configmap to the corresponding CoreDNS Corefile configuration. 部署 总体流程是我们使用 deploy.sh 生成 yaml 并保存成 coredns.yaml 文件并执行 kubectl apply -f coredns.yaml 进行部署 ，如果要卸载，执行 kubectl delete -f coredns.yaml。\ndeploy.sh 脚本依赖 jq 命令，所以先确保 jq 已安装:\napt install -y jq 全新部署 如果集群中没有 kube-dns 或低版本 coredns，我们直接用 -i 参数指定集群 DNS 的 CLUSTER IP，这个 IP 是安装集群时就确定好的，示例:\n./deploy.sh -i 10.32.0.255 \u0026gt; coredns.yaml kubectl apply -f coredns.yaml "
},
{
	"uri": "https://k8s.imroc.io/cluster/network/flannel/deploy/",
	"title": "部署 Flannel",
	"tags": [],
	"description": "",
	"content": "记集群网段为 CLUSTER_CIDR:\nCLUSTER_CIDR=10.10.0.0/16 创建 flannel 资源文件:\ncat \u0026lt;\u0026lt;EOF | sudo tee kube-flannel.yml apiVersion: policy/v1beta1 kind: PodSecurityPolicy metadata: name: psp.flannel.unprivileged annotations: seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default spec: privileged: false volumes: - configMap - secret - emptyDir - hostPath allowedHostPaths: - pathPrefix: \u0026#34;/etc/cni/net.d\u0026#34; - pathPrefix: \u0026#34;/etc/kube-flannel\u0026#34; - pathPrefix: \u0026#34;/run/flannel\u0026#34; readOnlyRootFilesystem: false # Users and groups runAsUser: rule: RunAsAny supplementalGroups: rule: RunAsAny fsGroup: rule: RunAsAny # Privilege Escalation allowPrivilegeEscalation: false defaultAllowPrivilegeEscalation: false # Capabilities allowedCapabilities: [\u0026#39;NET_ADMIN\u0026#39;] defaultAddCapabilities: [] requiredDropCapabilities: [] # Host namespaces hostPID: false hostIPC: false hostNetwork: true hostPorts: - min: 0 max: 65535 # SELinux seLinux: # SELinux is unsed in CaaSP rule: \u0026#39;RunAsAny\u0026#39; --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: flannel rules: - apiGroups: [\u0026#39;extensions\u0026#39;] resources: [\u0026#39;podsecuritypolicies\u0026#39;] verbs: [\u0026#39;use\u0026#39;] resourceNames: [\u0026#39;psp.flannel.unprivileged\u0026#39;] - apiGroups: - \u0026#34;\u0026#34; resources: - pods verbs: - get - apiGroups: - \u0026#34;\u0026#34; resources: - nodes verbs: - list - watch - apiGroups: - \u0026#34;\u0026#34; resources: - nodes/status verbs: - patch --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: flannel roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: flannel subjects: - kind: ServiceAccount name: flannel namespace: kube-system --- apiVersion: v1 kind: ServiceAccount metadata: name: flannel namespace: kube-system --- kind: ConfigMap apiVersion: v1 metadata: name: kube-flannel-cfg namespace: kube-system labels: tier: node app: flannel data: cni-conf.json: | { \u0026#34;cniVersion\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;cbr0\u0026#34;, \u0026#34;plugins\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;flannel\u0026#34;, \u0026#34;delegate\u0026#34;: { \u0026#34;hairpinMode\u0026#34;: true, \u0026#34;isDefaultGateway\u0026#34;: true } }, { \u0026#34;type\u0026#34;: \u0026#34;portmap\u0026#34;, \u0026#34;capabilities\u0026#34;: { \u0026#34;portMappings\u0026#34;: true } } ] } net-conf.json: | { \u0026#34;Network\u0026#34;: \u0026#34;${CLUSTER_CIDR}\u0026#34;, \u0026#34;Backend\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;vxlan\u0026#34; } } --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds-amd64 namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/os operator: In values: - linux - key: beta.kubernetes.io/arch operator: In values: - amd64 hostNetwork: true tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.11.0-amd64 command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-amd64 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds-arm64 namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/os operator: In values: - linux - key: beta.kubernetes.io/arch operator: In values: - arm64 hostNetwork: true tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.11.0-arm64 command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-arm64 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds-arm namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/os operator: In values: - linux - key: beta.kubernetes.io/arch operator: In values: - arm hostNetwork: true tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.11.0-arm command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-arm command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds-ppc64le namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/os operator: In values: - linux - key: beta.kubernetes.io/arch operator: In values: - ppc64le hostNetwork: true tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.11.0-ppc64le command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-ppc64le command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds-s390x namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/os operator: In values: - linux - key: beta.kubernetes.io/arch operator: In values: - s390x hostNetwork: true tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.11.0-s390x command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-s390x command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg EOF 部署:\nkubectl apply -f kube-flannel.yml  以上资源文件参考 flannel 官方: https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml (仅提取了 CLUSTER_CIDR 变量)\n "
},
{
	"uri": "https://k8s.imroc.io/deploy/appendix/",
	"title": "附录",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/security/permission/",
	"title": "集群权限控制",
	"tags": [],
	"description": "",
	"content": "账户类型 K8S 主要有以下两种账户类型概念:\n 用户账户 (User): 控制人的权限。 服务账户 (ServiceAccount): 控制应用程序的权限  如果开启集群审计，就可以区分某个操作是哪个用户或哪个应程序执行的。\n"
},
{
	"uri": "https://k8s.imroc.io/security/cert/",
	"title": "集群证书管理",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/eviction-leads-to-service-disruption/",
	"title": "驱逐导致服务中断",
	"tags": [],
	"description": "",
	"content": "TODO 优化\n案例 TKE 一客户的某个节点有问题，无法挂载nfs，通过新加节点，驱逐故障节点的 pod 来规避，但导致了业务 10min 服务不可用，排查发现其它节点 pod 很多集体出现了重启，主要是连不上 kube-dns 无法解析 service，业务调用不成功，从而对外表现为服务不可用。\n为什么会中断？驱逐的原理是先封锁节点，然后将旧的 node 上的 pod 删除，replicaset 控制器检测到 pod 减少，会重新创建一个 pod，调度到新的 node上，这个过程是先删除，再创建，并非是滚动更新，因此更新过程中，如果一个deployment的所有 pod 都在被驱逐的节点上，则可能导致该服务不可用。\n那为什么会影响其它 pod？分析kubelet日志，kube-dns 有两个副本，都在这个被驱逐的节点上，所以驱逐的时候 kube-dns 不通，影响了其它 pod 解析 service，导致服务集体不可用。\n那为什么会中断这么久？通常在新的节点应该很会快才是，通过进一步分析新节点的 kubelet 日志，发现 kube-dns 从拉镜像到容器启动之间花了很长时间，检查节点上的镜像发现有很多大镜像(1~2GB)，猜测是拉取镜像有并发限制，kube-dns 的镜像虽小，但在排队等大镜像下载完，检查 kubelet 启动参数，确实有 --registry-burst 这个参数控制镜像下载并发数限制。但最终发现其实应该是 --serialize-image-pulls 这个参数导致的，kubelet 启动参数没有指定该参数，而该参数默认值为 true，即默认串行下载镜像，不并发下载，所以导致镜像下载排队，是的 kube-dns 延迟了很长时间才启动。\n解决方案  避免服务单点故障，多副本，并加反亲和性 设置 preStop hook 与 readinessProbe，更新路由规则  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/high-load/",
	"title": "高负载",
	"tags": [],
	"description": "",
	"content": "TODO 优化\n节点高负载会导致进程无法获得足够的 cpu 时间片来运行，通常表现为网络 timeout，健康检查失败，服务不可用。\n过多 IO 等待 有时候即便 cpu ‘us’ (user) 不高但 cpu ‘id’ (idle) 很高的情况节点负载也很高，这是为什么呢？通常是文件 IO 性能达到瓶颈导致 IO WAIT 过多，从而使得节点整体负载升高，影响其它进程的性能。\n使用 top 命令看下当前负载：\ntop - 19:42:06 up 23:59, 2 users, load average: 34.64, 35.80, 35.76 Tasks: 679 total, 1 running, 678 sleeping, 0 stopped, 0 zombie Cpu(s): 15.6%us, 1.7%sy, 0.0%ni, 74.7%id, 7.9%wa, 0.0%hi, 0.1%si, 0.0%st Mem: 32865032k total, 30989168k used, 1875864k free, 370748k buffers Swap: 8388604k total, 5440k used, 8383164k free, 7982424k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 9783 mysql 20 0 17.3g 16g 8104 S 186.9 52.3 3752:33 mysqld 5700 nginx 20 0 1330m 66m 9496 S 8.9 0.2 0:20.82 php-fpm 6424 nginx 20 0 1330m 65m 8372 S 8.3 0.2 0:04.97 php-fpm 6573 nginx 20 0 1330m 64m 7368 S 8.3 0.2 0:01.49 php-fpm 5927 nginx 20 0 1320m 56m 9272 S 7.6 0.2 0:12.54 php-fpm 5956 nginx 20 0 1330m 65m 8500 S 7.6 0.2 0:12.70 php-fpm 6126 nginx 20 0 1321m 57m 8964 S 7.3 0.2 0:09.72 php-fpm 6127 nginx 20 0 1319m 54m 9520 S 6.6 0.2 0:08.73 php-fpm 6131 nginx 20 0 1320m 56m 9404 S 6.6 0.2 0:09.43 php-fpm 6174 nginx 20 0 1321m 56m 8444 S 6.3 0.2 0:08.92 php-fpm 5790 nginx 20 0 1319m 54m 9468 S 5.6 0.2 0:17.33 php-fpm 6575 nginx 20 0 1320m 55m 8212 S 5.6 0.2 0:02.11 php-fpm 6160 nginx 20 0 1310m 44m 8296 S 4.0 0.1 0:10.05 php-fpm 5597 nginx 20 0 1310m 46m 9556 S 3.6 0.1 0:21.03 php-fpm 5786 nginx 20 0 1310m 45m 8528 S 3.6 0.1 0:15.53 php-fpm 5797 nginx 20 0 1310m 46m 9444 S 3.6 0.1 0:14.02 php-fpm 6158 nginx 20 0 1310m 45m 8324 S 3.6 0.1 0:10.20 php-fpm 5698 nginx 20 0 1310m 46m 9184 S 3.3 0.1 0:20.62 php-fpm 5779 nginx 20 0 1309m 44m 8336 S 3.3 0.1 0:15.34 php-fpm 6540 nginx 20 0 1306m 40m 7884 S 3.3 0.1 0:02.46 php-fpm 5553 nginx 20 0 1300m 36m 9568 S 3.0 0.1 0:21.58 php-fpm 5722 nginx 20 0 1310m 45m 8552 S 3.0 0.1 0:17.25 php-fpm 5920 nginx 20 0 1302m 36m 8208 S 3.0 0.1 0:14.23 php-fpm 6432 nginx 20 0 1310m 45m 8420 S 3.0 0.1 0:05.86 php-fpm 5285 nginx 20 0 1302m 38m 9696 S 2.7 0.1 0:23.41 php-fpm wa (wait) 表示 IO WAIT 的 cpu 占用，默认看到的是所有核的平均值，要看每个核的 wa 值需要按下 \u0026ldquo;1\u0026rdquo;:\ntop - 19:42:08 up 23:59, 2 users, load average: 34.64, 35.80, 35.76 Tasks: 679 total, 1 running, 678 sleeping, 0 stopped, 0 zombie Cpu0 : 29.5%us, 3.7%sy, 0.0%ni, 48.7%id, 17.9%wa, 0.0%hi, 0.1%si, 0.0%st Cpu1 : 29.3%us, 3.7%sy, 0.0%ni, 48.9%id, 17.9%wa, 0.0%hi, 0.1%si, 0.0%st Cpu2 : 26.1%us, 3.1%sy, 0.0%ni, 64.4%id, 6.0%wa, 0.0%hi, 0.3%si, 0.0%st Cpu3 : 25.9%us, 3.1%sy, 0.0%ni, 65.5%id, 5.4%wa, 0.0%hi, 0.1%si, 0.0%st Cpu4 : 24.9%us, 3.0%sy, 0.0%ni, 66.8%id, 5.0%wa, 0.0%hi, 0.3%si, 0.0%st Cpu5 : 24.9%us, 2.9%sy, 0.0%ni, 67.0%id, 4.8%wa, 0.0%hi, 0.3%si, 0.0%st Cpu6 : 24.2%us, 2.7%sy, 0.0%ni, 68.3%id, 4.5%wa, 0.0%hi, 0.3%si, 0.0%st Cpu7 : 24.3%us, 2.6%sy, 0.0%ni, 68.5%id, 4.2%wa, 0.0%hi, 0.3%si, 0.0%st Cpu8 : 23.8%us, 2.6%sy, 0.0%ni, 69.2%id, 4.1%wa, 0.0%hi, 0.3%si, 0.0%st Cpu9 : 23.9%us, 2.5%sy, 0.0%ni, 69.3%id, 4.0%wa, 0.0%hi, 0.3%si, 0.0%st Cpu10 : 23.3%us, 2.4%sy, 0.0%ni, 68.7%id, 5.6%wa, 0.0%hi, 0.0%si, 0.0%st Cpu11 : 23.3%us, 2.4%sy, 0.0%ni, 69.2%id, 5.1%wa, 0.0%hi, 0.0%si, 0.0%st Cpu12 : 21.8%us, 2.4%sy, 0.0%ni, 60.2%id, 15.5%wa, 0.0%hi, 0.0%si, 0.0%st Cpu13 : 21.9%us, 2.4%sy, 0.0%ni, 60.6%id, 15.2%wa, 0.0%hi, 0.0%si, 0.0%st Cpu14 : 21.4%us, 2.3%sy, 0.0%ni, 72.6%id, 3.7%wa, 0.0%hi, 0.0%si, 0.0%st Cpu15 : 21.5%us, 2.2%sy, 0.0%ni, 73.2%id, 3.1%wa, 0.0%hi, 0.0%si, 0.0%st Cpu16 : 21.2%us, 2.2%sy, 0.0%ni, 73.6%id, 3.0%wa, 0.0%hi, 0.0%si, 0.0%st Cpu17 : 21.2%us, 2.1%sy, 0.0%ni, 73.8%id, 2.8%wa, 0.0%hi, 0.0%si, 0.0%st Cpu18 : 20.9%us, 2.1%sy, 0.0%ni, 74.1%id, 2.9%wa, 0.0%hi, 0.0%si, 0.0%st Cpu19 : 21.0%us, 2.1%sy, 0.0%ni, 74.4%id, 2.5%wa, 0.0%hi, 0.0%si, 0.0%st Cpu20 : 20.7%us, 2.0%sy, 0.0%ni, 73.8%id, 3.4%wa, 0.0%hi, 0.0%si, 0.0%st Cpu21 : 20.8%us, 2.0%sy, 0.0%ni, 73.9%id, 3.2%wa, 0.0%hi, 0.0%si, 0.0%st Cpu22 : 20.8%us, 2.0%sy, 0.0%ni, 74.4%id, 2.8%wa, 0.0%hi, 0.0%si, 0.0%st Cpu23 : 20.8%us, 1.9%sy, 0.0%ni, 74.4%id, 2.8%wa, 0.0%hi, 0.0%si, 0.0%st Mem: 32865032k total, 30209248k used, 2655784k free, 370748k buffers Swap: 8388604k total, 5440k used, 8383164k free, 7986552k cached wa 通常是 0%，如果经常在 1 之上，说明存储设备的速度已经太慢，无法跟上 cpu 的处理速度。\n使用 atop 看下当前磁盘 IO 状态:\nATOP - lemp 2017/01/23 19:42:32 --------- 10s elapsed PRC | sys 3.18s | user 33.24s | #proc 679 | #tslpu 28 | #zombie 0 | #exit 0 | CPU | sys 29% | user 330% | irq 1% | idle 1857% | wait 182% | curscal 69% | CPL | avg1 33.00 | avg5 35.29 | avg15 35.59 | csw 62610 | intr 76926 | numcpu 24 | MEM | tot 31.3G | free 2.1G | cache 7.6G | dirty 41.0M | buff 362.1M | slab 1.2G | SWP | tot 8.0G | free 8.0G | | | vmcom 23.9G | vmlim 23.7G | DSK | sda | busy 100% | read 4 | write 1789 | MBw/s 2.84 | avio 5.58 ms | NET | transport | tcpi 10357 | tcpo 9065 | udpi 0 | udpo 0 | tcpao 174 | NET | network | ipi 10360 | ipo 9065 | ipfrw 0 | deliv 10359 | icmpo 0 | NET | eth0 4% | pcki 6649 | pcko 6136 | si 1478 Kbps | so 4115 Kbps | erro 0 | NET | lo ---- | pcki 4082 | pcko 4082 | si 8967 Kbps | so 8967 Kbps | erro 0 | PID TID THR SYSCPU USRCPU VGROW RGROW RDDSK WRDSK ST EXC S CPUNR CPU CMD 1/12 9783 - 156 0.21s 19.44s 0K -788K 4K 1344K -- - S 4 197% mysqld 5596 - 1 0.10s 0.62s 47204K 47004K 0K 220K -- - S 18 7% php-fpm 6429 - 1 0.06s 0.34s 19840K 19968K 0K 0K -- - S 21 4% php-fpm 6210 - 1 0.03s 0.30s -5216K -5204K 0K 0K -- - S 19 3% php-fpm 5757 - 1 0.05s 0.27s 26072K 26012K 0K 4K -- - S 13 3% php-fpm 6433 - 1 0.04s 0.28s -2816K -2816K 0K 0K -- - S 11 3% php-fpm 5846 - 1 0.06s 0.22s -2560K -2660K 0K 0K -- - S 7 3% php-fpm 5791 - 1 0.05s 0.21s 5764K 5692K 0K 0K -- - S 22 3% php-fpm 5860 - 1 0.04s 0.21s 48088K 47724K 0K 0K -- - S 1 3% php-fpm 6231 - 1 0.04s 0.20s -256K -4K 0K 0K -- - S 1 2% php-fpm 6154 - 1 0.03s 0.21s -3004K -3184K 0K 0K -- - S 21 2% php-fpm 6573 - 1 0.04s 0.20s -512K -168K 0K 0K -- - S 4 2% php-fpm 6435 - 1 0.04s 0.19s -3216K -2980K 0K 0K -- - S 15 2% php-fpm 5954 - 1 0.03s 0.20s 0K 164K 0K 4K -- - S 0 2% php-fpm 6133 - 1 0.03s 0.19s 41056K 40432K 0K 0K -- - S 18 2% php-fpm 6132 - 1 0.02s 0.20s 37836K 37440K 0K 0K -- - S 11 2% php-fpm 6242 - 1 0.03s 0.19s -12.2M -12.3M 0K 4K -- - S 12 2% php-fpm 6285 - 1 0.02s 0.19s 39516K 39420K 0K 0K -- - S 3 2% php-fpm 6455 - 1 0.05s 0.16s 29008K 28560K 0K 0K -- - S 14 2% php-fpm 在本例中磁盘 sda 已经 100% busy，已经严重达到性能瓶颈。按 \u0026lsquo;d\u0026rsquo; 看下是哪些进程在使用磁盘IO:\nATOP - lemp 2017/01/23 19:42:46 --------- 2s elapsed PRC | sys 0.24s | user 1.99s | #proc 679 | #tslpu 54 | #zombie 0 | #exit 0 | CPU | sys 11% | user 101% | irq 1% | idle 2089% | wait 208% | curscal 63% | CPL | avg1 38.49 | avg5 36.48 | avg15 35.98 | csw 4654 | intr 6876 | numcpu 24 | MEM | tot 31.3G | free 2.2G | cache 7.6G | dirty 48.7M | buff 362.1M | slab 1.2G | SWP | tot 8.0G | free 8.0G | | | vmcom 23.9G | vmlim 23.7G | DSK | sda | busy 100% | read 2 | write 362 | MBw/s 2.28 | avio 5.49 ms | NET | transport | tcpi 1031 | tcpo 968 | udpi 0 | udpo 0 | tcpao 45 | NET | network | ipi 1031 | ipo 968 | ipfrw 0 | deliv 1031 | icmpo 0 | NET | eth0 1% | pcki 558 | pcko 508 | si 762 Kbps | so 1077 Kbps | erro 0 | NET | lo ---- | pcki 406 | pcko 406 | si 2273 Kbps | so 2273 Kbps | erro 0 | PID TID RDDSK WRDSK WCANCL DSK CMD 1/5 9783 - 0K 468K 16K 40% mysqld 1930 - 0K 212K 0K 18% flush-8:0 5896 - 0K 152K 0K 13% nginx 880 - 0K 148K 0K 13% jbd2/sda5-8 5909 - 0K 60K 0K 5% nginx 5906 - 0K 36K 0K 3% nginx 5907 - 16K 8K 0K 2% nginx 5903 - 20K 0K 0K 2% nginx 5901 - 0K 12K 0K 1% nginx 5908 - 0K 8K 0K 1% nginx 5894 - 0K 8K 0K 1% nginx 5911 - 0K 8K 0K 1% nginx 5900 - 0K 4K 4K 0% nginx 5551 - 0K 4K 0K 0% php-fpm 5913 - 0K 4K 0K 0% nginx 5895 - 0K 4K 0K 0% nginx 6133 - 0K 0K 0K 0% php-fpm 5780 - 0K 0K 0K 0% php-fpm 6675 - 0K 0K 0K 0% atop 也可以使用 iotop -oPa 查看哪些进程占用磁盘 IO:\nTotal DISK READ: 15.02 K/s | Total DISK WRITE: 3.82 M/s PID PRIO USER DISK READ DISK WRITE SWAPIN IO\u0026gt; COMMAND 1930 be/4 root 0.00 B 1956.00 K 0.00 % 83.34 % [flush-8:0] 5914 be/4 nginx 0.00 B 0.00 B 0.00 % 36.56 % nginx: cache manager process 880 be/3 root 0.00 B 21.27 M 0.00 % 35.03 % [jbd2/sda5-8] 5913 be/2 nginx 36.00 K 1000.00 K 0.00 % 8.94 % nginx: worker process 5910 be/2 nginx 0.00 B 1048.00 K 0.00 % 8.43 % nginx: worker process 5896 be/2 nginx 56.00 K 452.00 K 0.00 % 6.91 % nginx: worker process 5909 be/2 nginx 20.00 K 1144.00 K 0.00 % 6.24 % nginx: worker process 5890 be/2 nginx 48.00 K 692.00 K 0.00 % 6.07 % nginx: worker process 5892 be/2 nginx 84.00 K 736.00 K 0.00 % 5.71 % nginx: worker process 5901 be/2 nginx 20.00 K 504.00 K 0.00 % 5.46 % nginx: worker process 5899 be/2 nginx 0.00 B 596.00 K 0.00 % 5.14 % nginx: worker process 5897 be/2 nginx 28.00 K 1388.00 K 0.00 % 4.90 % nginx: worker process 5908 be/2 nginx 48.00 K 700.00 K 0.00 % 4.43 % nginx: worker process 5905 be/2 nginx 32.00 K 1140.00 K 0.00 % 4.36 % nginx: worker process 5900 be/2 nginx 0.00 B 1208.00 K 0.00 % 4.31 % nginx: worker process 5904 be/2 nginx 36.00 K 1244.00 K 0.00 % 2.80 % nginx: worker process 5895 be/2 nginx 16.00 K 780.00 K 0.00 % 2.50 % nginx: worker process 5907 be/2 nginx 0.00 B 1548.00 K 0.00 % 2.43 % nginx: worker process 5903 be/2 nginx 36.00 K 1032.00 K 0.00 % 2.34 % nginx: worker process 6130 be/4 nginx 0.00 B 72.00 K 0.00 % 2.18 % php-fpm: pool www 5906 be/2 nginx 12.00 K 844.00 K 0.00 % 2.10 % nginx: worker process 5889 be/2 nginx 40.00 K 1164.00 K 0.00 % 2.00 % nginx: worker process 5894 be/2 nginx 44.00 K 760.00 K 0.00 % 1.61 % nginx: worker process 5902 be/2 nginx 52.00 K 992.00 K 0.00 % 1.55 % nginx: worker process 5893 be/2 nginx 64.00 K 972.00 K 0.00 % 1.22 % nginx: worker process 5814 be/4 nginx 36.00 K 44.00 K 0.00 % 1.06 % php-fpm: pool www 6159 be/4 nginx 4.00 K 4.00 K 0.00 % 1.00 % php-fpm: pool www 5693 be/4 nginx 0.00 B 4.00 K 0.00 % 0.86 % php-fpm: pool www 5912 be/2 nginx 68.00 K 300.00 K 0.00 % 0.72 % nginx: worker process 5911 be/2 nginx 20.00 K 788.00 K 0.00 % 0.72 % nginx: worker process 通过 man iotop 可以看下这几个参数的含义：\n-o, --only Only show processes or threads actually doing I/O, instead of showing all processes or threads. This can be dynamically toggled by pressing o. -P, --processes Only show processes. Normally iotop shows all threads. -a, --accumulated Show accumulated I/O instead of bandwidth. In this mode, iotop shows the amount of I/O processes have done since iotop started. 节点上部署了其它非 K8S 管理的服务 TODO 优化\n比如在节点上装了数据库，但不被 K8S 所管理，这是用法不正确，不建议在 K8S 节点上部署其它进程。\n参考资料  Linux server performance: Is disk I/O slowing your application: https://haydenjames.io/linux-server-performance-disk-io-slowing-application/  "
}]